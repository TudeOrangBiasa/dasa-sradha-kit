# Domain 02: Há»‡ Thá»‘ng PhÃ¢n TÃ¡n (Distributed Systems)

| TrÆ°á»ng thÃ´ng tin | GiÃ¡ trá»‹ |
|-----------------|---------|
| **TÃªn miá»n** | Há»‡ Thá»‘ng PhÃ¢n TÃ¡n (Distributed Systems) |
| **LÄ©nh vá»±c** | Node.js / Distributed Architecture |
| **Sá»‘ lÆ°á»£ng pattern** | 12 |
| **NgÃ´n ngá»¯** | TypeScript |
| **Cáº­p nháº­t** | 2026-02-18 |

---

## Tá»•ng quan Há»‡ Thá»‘ng PhÃ¢n TÃ¡n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DISTRIBUTED SYSTEM FAILURE MAP                    â”‚
â”‚                                                                    â”‚
â”‚   Client â”€â”€â–¶ [ Load Balancer ] â”€â”€â–¶ [ Service A ] â”€â”€â–¶ [ Cache ]   â”‚
â”‚                     â”‚                    â”‚               â”‚         â”‚
â”‚                     â”‚                    â–¼               â–¼         â”‚
â”‚                     â”‚             [ Service B ] â”€â”€â–¶ [ DB Master ] â”‚
â”‚                     â”‚                    â”‚               â”‚         â”‚
â”‚                     â”‚                    â–¼               â–¼         â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  [ Message Queue ] [ DB Replica]  â”‚
â”‚                                         â”‚                          â”‚
â”‚                                         â–¼                          â”‚
â”‚                                  [ Worker Pool ]                   â”‚
â”‚                                                                    â”‚
â”‚  Failure Zones:                                                    â”‚
â”‚  [1] Cache Stampede  [4] Lock Race    [7] Missing Ack             â”‚
â”‚  [2] Retry Storm     [5] Idempotency  [8] Pub/Sub Loss            â”‚
â”‚  [3] No Circuit Brkr [6] WS Reconnect [9] Rate Limit             â”‚
â”‚  [10] Sticky Session [11] Timeout Chain [12] Event Order          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pattern 01: Báº§y ÄÃ n á»’ áº t (Thundering Herd / Cache Stampede)

### 1. TÃªn
**Báº§y ÄÃ n á»’ áº t** (Thundering Herd / Cache Stampede)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Caching
- **Subcategory:** Cache Invalidation, Race Condition

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - GÃ¢y quÃ¡ táº£i database Ä‘á»™t ngá»™t, cÃ³ thá»ƒ dáº«n Ä‘áº¿n cascading failure

### 4. Váº¥n Ä‘á»

Khi má»™t cache key háº¿t háº¡n, hÃ ng nghÃ¬n request Ä‘á»“ng thá»i Ä‘á»• vÃ o database Ä‘á»ƒ tÃ¡i táº¡o cÃ¹ng má»™t giÃ¡ trá»‹. Má»—i request tháº¥y cache miss, táº¥t cáº£ cÃ¹ng query DB, káº¿t quáº£ lÃ  DB bá»‹ quÃ¡ táº£i.

**VÃ­ dá»¥ thá»±c táº¿:** Flash sale báº¯t Ä‘áº§u, cache product list háº¿t háº¡n, 10.000 user cÃ¹ng lÃºc request, 10.000 query Ä‘áº¿n DB.

```
CACHE STAMPEDE:

t=0: Cache key "hot_products" háº¿t háº¡n
     â”‚
     â”œâ”€â”€ Request 1 â”€â”€â–¶ Cache MISS â”€â”€â–¶ DB Query â”€â”€â”€â”€â”€â–¶ (xá»­ lÃ½ 500ms)
     â”œâ”€â”€ Request 2 â”€â”€â–¶ Cache MISS â”€â”€â–¶ DB Query â”€â”€â”€â”€â”€â–¶ (xá»­ lÃ½ 500ms)
     â”œâ”€â”€ Request 3 â”€â”€â–¶ Cache MISS â”€â”€â–¶ DB Query â”€â”€â”€â”€â”€â–¶ (xá»­ lÃ½ 500ms)
     â”œâ”€â”€ ...          ...              ...
     â””â”€â”€ Request N â”€â”€â–¶ Cache MISS â”€â”€â–¶ DB Query â”€â”€â”€â”€â”€â–¶ DB OVERLOAD!

GIáº¢I PHÃP (Mutex / Probabilistic Early Expiry):

t=0: Cache key sáº¯p háº¿t háº¡n
     â”‚
     â”œâ”€â”€ Request 1 â”€â”€â–¶ Cache MISS â”€â”€â–¶ Acquire Lock â”€â”€â–¶ DB Query â”€â”€â–¶ Set Cache
     â”œâ”€â”€ Request 2 â”€â”€â–¶ Cache MISS â”€â”€â–¶ Wait Lock â”€â”€â”€â”€â”€â”€â–¶ Cache HIT (stale data)
     â”œâ”€â”€ Request 3 â”€â”€â–¶ Cache MISS â”€â”€â–¶ Wait Lock â”€â”€â”€â”€â”€â”€â–¶ Cache HIT (fresh data)
     â””â”€â”€ Request N â”€â”€â–¶ Cache HIT  â”€â”€â–¶ Return immediately
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `cache.get()` khÃ´ng cÃ³ lock/mutex protection trÆ°á»›c khi gá»i DB
- TTL cá»‘ Ä‘á»‹nh khÃ´ng cÃ³ jitter (má»i key háº¿t háº¡n cÃ¹ng lÃºc)
- KhÃ´ng cÃ³ stale-while-revalidate pattern
- Cache.get + DB query + Cache.set mÃ  khÃ´ng dÃ¹ng lock

**Regex patterns (ripgrep):**
```bash
# TÃ¬m cache get khÃ´ng cÃ³ lock protection
rg "cache\.get|redis\.get" --type ts -A 3 | grep -v "lock\|mutex\|setnx"

# TÃ¬m TTL cá»‘ Ä‘á»‹nh (khÃ´ng cÃ³ jitter)
rg "EX\s+\d+|expire\s*\(\s*\d+|ttl:\s*\d+" --type ts

# TÃ¬m pattern cache miss -> DB query khÃ´ng cÃ³ lock
rg "if\s*\(!cached\|if\s*\(result\s*===\s*null" --type ts -A 5

# TÃ¬m Redis SETNX patterns (Ä‘Ã£ dÃ¹ng lock)
rg "setnx|set.*NX|redlock|Redlock" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Cache miss | Táº¥t cáº£ query DB cÃ¹ng lÃºc | DÃ¹ng Redis SETNX lock |
| TTL | Cá»‘ Ä‘á»‹nh (stampede cÃ¹ng lÃºc) | TTL + random jitter |
| Stale data | Reject request | Serve stale, revalidate async |
| Lock timeout | KhÃ´ng cÃ³ | CÃ³ timeout + fallback |

```typescript
import { Redis } from 'ioredis'

const redis = new Redis()

// âŒ SAI: KhÃ´ng cÃ³ lock, thundering herd xáº£y ra
async function getHotProductsBad(): Promise<Product[]> {
  const cached = await redis.get('hot_products')
  if (cached) return JSON.parse(cached)

  // HÃ ng nghÃ¬n request Ä‘á»“ng thá»i Ä‘áº¿n Ä‘Ã¢y!
  const products = await db.query('SELECT * FROM products WHERE hot = true')
  await redis.set('hot_products', JSON.stringify(products), 'EX', 300)
  return products
}

// âœ… ÄÃšNG: DÃ¹ng mutex lock + stale-while-revalidate
const LOCK_TTL = 5 // seconds
const CACHE_TTL = 300 // seconds
const JITTER_MAX = 30 // seconds

function getTTLWithJitter(base: number): number {
  return base + Math.floor(Math.random() * JITTER_MAX)
}

async function getHotProductsGood(): Promise<Product[]> {
  const cacheKey = 'hot_products'
  const lockKey = `lock:${cacheKey}`

  // 1. Thá»­ Ä‘á»c cache trÆ°á»›c
  const cached = await redis.get(cacheKey)
  if (cached) return JSON.parse(cached)

  // 2. Thá»­ acquire lock (Redis SETNX)
  const lockAcquired = await redis.set(lockKey, '1', 'EX', LOCK_TTL, 'NX')

  if (!lockAcquired) {
    // 3a. KhÃ´ng cÃ³ lock â†’ chá» vÃ  retry (hoáº·c tráº£ stale data)
    await new Promise(resolve => setTimeout(resolve, 100))
    const retryCache = await redis.get(cacheKey)
    if (retryCache) return JSON.parse(retryCache)
    // Fallback: tráº£ empty hoáº·c stale data tá»« secondary cache
    return []
  }

  try {
    // 3b. CÃ³ lock â†’ query DB vÃ  set cache
    const products = await db.query('SELECT * FROM products WHERE hot = true')
    const ttl = getTTLWithJitter(CACHE_TTL)
    await redis.set(cacheKey, JSON.stringify(products), 'EX', ttl)
    return products
  } finally {
    // 4. LuÃ´n release lock
    await redis.del(lockKey)
  }
}

// âœ… NÃ‚NG CAO: Probabilistic Early Expiry (PER)
// TÃ¡i táº¡o cache trÆ°á»›c khi háº¿t háº¡n, dá»±a trÃªn xÃ¡c suáº¥t
async function getWithPER<T>(
  key: string,
  fetcher: () => Promise<T>,
  ttl: number,
  beta: number = 1
): Promise<T> {
  const raw = await redis.get(key)

  if (raw) {
    const { value, expiry } = JSON.parse(raw) as { value: T; expiry: number }
    const remainingTTL = expiry - Date.now() / 1000
    const delta = -Math.log(Math.random()) * beta

    // TÃ¡i táº¡o sá»›m náº¿u xÃ¡c suáº¥t Ä‘á»§ cao
    if (delta < remainingTTL) {
      return value
    }
  }

  // Cache miss hoáº·c cáº§n tÃ¡i táº¡o
  const value = await fetcher()
  const expiry = Date.now() / 1000 + ttl
  await redis.set(key, JSON.stringify({ value, expiry }), 'EX', ttl + 1)
  return value
}
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n dÃ¹ng distributed lock (Redis SETNX / Redlock) cho cache miss handler
- [ ] ThÃªm random jitter vÃ o TTL Ä‘á»ƒ trÃ¡nh mass expiry cÃ¹ng lÃºc
- [ ] Implement stale-while-revalidate: serve data cÅ© trong khi tÃ¡i táº¡o
- [ ] Monitor cache hit rate; alert khi hit rate giáº£m Ä‘á»™t ngá»™t
- [ ] DÃ¹ng background job Ä‘á»ƒ warm up cache trÆ°á»›c khi háº¿t háº¡n

```javascript
// ESLint rule gá»£i Ã½ (custom rule)
// Cáº£nh bÃ¡o khi dÃ¹ng redis.get mÃ  khÃ´ng cÃ³ lock pattern trong cÃ¹ng function
// CÃ³ thá»ƒ dÃ¹ng eslint-plugin-custom hoáº·c comment lint
// eslint-disable-next-line no-cache-without-lock
```

---

## Pattern 02: Retry Storm

### 1. TÃªn
**BÃ£o Thá»­ Láº¡i** (Retry Storm)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Resilience
- **Subcategory:** Retry Logic, Cascading Failure

### 3. Má»©c nghiÃªm trá»ng
ğŸ”´ **CRITICAL** - Khuáº¿ch Ä‘áº¡i lÆ°u lÆ°á»£ng lÃªn hÃ ng nghÃ¬n láº§n, lÃ m sá»¥p Ä‘á»• service Ä‘ang recover

### 4. Váº¥n Ä‘á»

Khi má»™t service cháº­m hoáº·c lá»—i, táº¥t cáº£ client retry ngay láº­p tá»©c vÃ  Ä‘á»“ng bá»™. LÆ°u lÆ°á»£ng nhÃ¢n lÃªn `N_clients Ã— max_retries` láº§n Ä‘Ãºng lÃºc service Ä‘ang cá»‘ recover, khiáº¿n nÃ³ khÃ´ng bao giá» recover Ä‘Æ°á»£c.

**VÃ­ dá»¥ thá»±c táº¿:** Payment service bá»‹ slow 2 giÃ¢y, 1000 client retry 3 láº§n â†’ 3000 request Ä‘á»• vÃ o, service cÃ ng cháº­m hÆ¡n, client retry thÃªm â†’ vÃ²ng láº·p vÃ´ táº­n.

```
RETRY STORM:

t=0: Payment service slow (latency 2s)
     â”‚
     â”œâ”€â”€ 1000 clients gá»­i request
     â”‚        â”‚
     â”‚        â–¼ timeout sau 1s
     â”‚   1000 clients RETRY immediately
     â”‚        â”‚
     â”‚        â–¼ (1000 + 1000 = 2000 concurrent requests)
     â”‚   Service cÃ ng cháº­m hÆ¡n
     â”‚        â”‚
     â”‚        â–¼ timeout sau 1s
     â”‚   2000 clients RETRY immediately
     â”‚        â”‚
     â”‚        â–¼ (2000 + 2000 = 4000 concurrent requests)
     â”‚   SERVICE CRASH!
     â”‚
     â””â”€â”€ KhÃ´ng bao giá» recover Ä‘Æ°á»£c!

EXPONENTIAL BACKOFF + JITTER:

     Client 1: retry sau 1s, 2s, 4s, 8s (+ random 0-1s)
     Client 2: retry sau 1.3s, 2.7s, 5.1s (distributed)
     Client 3: retry sau 0.8s, 1.9s, 4.3s (staggered)
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
     Service load giáº£m dáº§n, cÃ³ thá»i gian recover
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Retry loop vá»›i `delay` cá»‘ Ä‘á»‹nh (hoáº·c khÃ´ng cÃ³ delay)
- `for` / `while` retry khÃ´ng cÃ³ exponential backoff
- Axios/fetch retry config khÃ´ng cÃ³ jitter
- `retryDelay: 1000` (cá»‘ Ä‘á»‹nh) thay vÃ¬ hÃ m tÃ­nh toÃ¡n

**Regex patterns (ripgrep):**
```bash
# TÃ¬m retry vá»›i delay cá»‘ Ä‘á»‹nh
rg "retryDelay:\s*\d+|retry.*delay.*\d+" --type ts

# TÃ¬m retry loop khÃ´ng cÃ³ backoff
rg "for.*retry|while.*retry|attempt.*retry" --type ts -A 5 | grep -v "backoff\|exponential"

# TÃ¬m setTimeout cá»‘ Ä‘á»‹nh trong retry context
rg "setTimeout.*retry|retry.*setTimeout" --type ts -B 2 -A 2

# TÃ¬m axios-retry hoáº·c p-retry config
rg "retries:\s*\d|axios-retry|p-retry" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Delay | Cá»‘ Ä‘á»‹nh (1s) | Exponential (1s, 2s, 4s, 8s) |
| Jitter | KhÃ´ng cÃ³ | Full jitter hoáº·c decorrelated |
| Max retries | VÃ´ háº¡n | 3-5 láº§n tá»‘i Ä‘a |
| Retry Ä‘iá»u kiá»‡n | Táº¥t cáº£ lá»—i | Chá»‰ lá»—i transient (5xx, network) |
| Max delay | KhÃ´ng giá»›i háº¡n | Cap táº¡i 30-60s |

```typescript
// âŒ SAI: Retry ngay láº­p tá»©c, khÃ´ng cÃ³ backoff, khÃ´ng cÃ³ jitter
async function callPaymentServiceBad(payload: PaymentPayload): Promise<void> {
  const MAX_RETRIES = 5
  for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
    try {
      await axios.post('/payment', payload)
      return
    } catch (err) {
      if (attempt < MAX_RETRIES - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000)) // Fixed 1s!
      }
    }
  }
  throw new Error('Payment failed after retries')
}

// âœ… ÄÃšNG: Exponential backoff vá»›i full jitter
interface RetryConfig {
  maxRetries: number
  baseDelayMs: number
  maxDelayMs: number
  retryableStatuses: number[]
}

function calculateBackoffDelay(attempt: number, config: RetryConfig): number {
  // Exponential backoff: baseDelay * 2^attempt
  const exponential = config.baseDelayMs * Math.pow(2, attempt)
  // Cap táº¡i maxDelay
  const capped = Math.min(exponential, config.maxDelayMs)
  // Full jitter: random trong [0, capped]
  return Math.random() * capped
}

function isRetryableError(error: unknown): boolean {
  if (axios.isAxiosError(error)) {
    const status = error.response?.status
    // Retry 5xx (server errors) vÃ  network errors, khÃ´ng retry 4xx (client errors)
    return !status || status >= 500
  }
  return true // Network error â†’ retry
}

async function callPaymentServiceGood(payload: PaymentPayload): Promise<PaymentResult> {
  const config: RetryConfig = {
    maxRetries: 3,
    baseDelayMs: 500,
    maxDelayMs: 30_000,
    retryableStatuses: [500, 502, 503, 504]
  }

  let lastError: unknown

  for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
    try {
      const response = await axios.post<PaymentResult>('/payment', payload, {
        timeout: 5000
      })
      return response.data
    } catch (err) {
      lastError = err

      if (!isRetryableError(err) || attempt === config.maxRetries) {
        break
      }

      const delay = calculateBackoffDelay(attempt, config)
      console.warn(`Payment attempt ${attempt + 1} failed, retrying in ${delay.toFixed(0)}ms`)
      await new Promise(resolve => setTimeout(resolve, delay))
    }
  }

  throw new Error(`Payment failed after ${config.maxRetries} retries: ${lastError}`)
}

// âœ… NÃ‚NG CAO: DÃ¹ng p-retry library vá»›i decorrelated jitter
import pRetry from 'p-retry'

async function callPaymentServiceAdvanced(payload: PaymentPayload): Promise<PaymentResult> {
  return pRetry(
    async (attempt) => {
      const response = await axios.post<PaymentResult>('/payment', payload)
      return response.data
    },
    {
      retries: 3,
      factor: 2,
      minTimeout: 500,
      maxTimeout: 30_000,
      randomize: true, // Adds jitter automatically
      onFailedAttempt: (error) => {
        console.warn(`Attempt ${error.attemptNumber} failed. Retries left: ${error.retriesLeft}`)
      }
    }
  )
}
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n dÃ¹ng exponential backoff, KHÃ”NG dÃ¹ng fixed delay
- [ ] ThÃªm jitter (random) vÃ o delay Ä‘á»ƒ trÃ¡nh synchronized retries
- [ ] Giá»›i háº¡n max retries (3-5) vÃ  max delay (30-60s)
- [ ] Chá»‰ retry lá»—i transient (5xx, timeout), khÃ´ng retry 4xx
- [ ] Káº¿t há»£p vá»›i Circuit Breaker Ä‘á»ƒ dá»«ng retry khi service down hoÃ n toÃ n
- [ ] Monitor retry rate; alert khi retry rate > threshold

```javascript
// ESLint: cáº£nh bÃ¡o khi dÃ¹ng setTimeout vá»›i giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh trong retry context
// eslint-disable-next-line no-fixed-retry-delay
```

---

## Pattern 03: Circuit Breaker Thiáº¿u

### 1. TÃªn
**Thiáº¿u Cáº§u Dao Ngáº¯t Máº¡ch** (Missing Circuit Breaker)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Resilience
- **Subcategory:** Fault Tolerance, Cascading Failure Prevention

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Lá»—i má»™t service lan rá»™ng sang toÃ n bá»™ há»‡ thá»‘ng, gÃ¢y cascading failure

### 4. Váº¥n Ä‘á»

Khi service phá»¥ thuá»™c (downstream) bá»‹ lá»—i, service gá»i nÃ³ váº«n tiáº¿p tá»¥c chá» timeout trÃªn má»—i request. Äiá»u nÃ y tiÃªu thá»¥ thread/connection pool vÃ  lÃ m ngháº½n toÃ n bá»™ service, dÃ¹ downstream Ä‘Ã£ down hoÃ n toÃ n.

**VÃ­ dá»¥ thá»±c táº¿:** SMS service down, má»i API request váº«n chá» 30s timeout trÆ°á»›c khi tráº£ lá»—i. 100 concurrent request Ã— 30s = connection pool cáº¡n kiá»‡t.

```
KHÃ”NG CÃ“ CIRCUIT BREAKER:

Service A â”€â”€â–¶ SMS Service (DOWN)
     â”‚              â”‚
     â”œâ”€â”€ Req 1 â”€â”€â–¶ timeout 30s â”€â”€â–¶ Error (30s wasted)
     â”œâ”€â”€ Req 2 â”€â”€â–¶ timeout 30s â”€â”€â–¶ Error (30s wasted)
     â”œâ”€â”€ Req 3 â”€â”€â–¶ timeout 30s â”€â”€â–¶ Error (30s wasted)
     â””â”€â”€ ... (connection pool exhausted, Service A also fails)

CÃ“ CIRCUIT BREAKER (States: CLOSED â†’ OPEN â†’ HALF-OPEN):

CLOSED (bÃ¬nh thÆ°á»ng):   req â”€â”€â–¶ SMS â”€â”€â–¶ response
  error rate > 50% â”€â”€â–¶ OPEN

OPEN (Ä‘Ã£ ngáº¯t):         req â”€â”€â–¶ [CIRCUIT OPEN] â”€â”€â–¶ fail fast (0ms!)
  sau 30s â”€â”€â–¶ HALF-OPEN

HALF-OPEN (thá»­ láº¡i):    1 req â”€â”€â–¶ SMS
  success â”€â”€â–¶ CLOSED
  failure â”€â”€â–¶ OPEN
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- HTTP calls Ä‘áº¿n external service khÃ´ng cÃ³ circuit breaker wrapper
- Timeout dÃ i (>10s) mÃ  khÃ´ng cÃ³ fallback
- KhÃ´ng cÃ³ `opossum`, `cockatiel`, hoáº·c custom circuit breaker
- KhÃ´ng cÃ³ health check / readiness probe cho dependencies

**Regex patterns (ripgrep):**
```bash
# TÃ¬m HTTP calls khÃ´ng cÃ³ circuit breaker
rg "axios\.(get|post|put|delete)|fetch\(" --type ts | grep -v "circuit\|breaker\|opossum"

# TÃ¬m timeout dÃ i khÃ´ng cÃ³ fallback
rg "timeout:\s*[0-9]{5,}" --type ts

# TÃ¬m opossum/circuit breaker Ä‘Ã£ Ä‘Æ°á»£c dÃ¹ng
rg "opossum|CircuitBreaker|cockatiel|circuit" --type ts

# TÃ¬m external service calls
rg "https?://|baseURL:" --type ts -A 2
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| External call | Trá»±c tiáº¿p, khÃ´ng cÃ³ báº£o vá»‡ | Wrap báº±ng Circuit Breaker |
| Failure detection | Chá» tá»«ng timeout | Äáº¿m lá»—i, má»Ÿ circuit |
| Recovery | Manual | Tá»± Ä‘á»™ng sau cooldown |
| Fallback | KhÃ´ng cÃ³ | CÃ³ fallback response |

```typescript
import CircuitBreaker from 'opossum'

// âŒ SAI: Gá»i trá»±c tiáº¿p khÃ´ng cÃ³ circuit breaker
async function sendSmsBad(to: string, message: string): Promise<void> {
  // Náº¿u SMS service down, má»—i call chá» 30s!
  await axios.post('https://sms-provider.com/send', { to, message }, {
    timeout: 30_000
  })
}

// âœ… ÄÃšNG: Wrap báº±ng Circuit Breaker (opossum)
async function sendSmsCore(to: string, message: string): Promise<void> {
  await axios.post('https://sms-provider.com/send', { to, message }, {
    timeout: 3_000 // Timeout ngáº¯n hÆ¡n
  })
}

const smsBreaker = new CircuitBreaker(sendSmsCore, {
  timeout: 3000,           // Fail náº¿u > 3s
  errorThresholdPercentage: 50, // Má»Ÿ circuit náº¿u 50% lá»—i
  resetTimeout: 30_000,    // Thá»­ láº¡i sau 30s
  volumeThreshold: 5       // Cáº§n Ã­t nháº¥t 5 request Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
})

// Fallback khi circuit má»Ÿ
smsBreaker.fallback(async (to: string, message: string) => {
  console.warn(`Circuit OPEN: SMS queued for later delivery to ${to}`)
  await smsQueue.add({ to, message, retryAt: Date.now() + 60_000 })
})

// Monitor circuit state
smsBreaker.on('open', () => console.error('SMS Circuit OPENED - service degraded'))
smsBreaker.on('halfOpen', () => console.info('SMS Circuit HALF-OPEN - testing recovery'))
smsBreaker.on('close', () => console.info('SMS Circuit CLOSED - service recovered'))

async function sendSmsGood(to: string, message: string): Promise<void> {
  await smsBreaker.fire(to, message)
}

// âœ… NÃ‚NG CAO: Circuit Breaker tá»± triá»ƒn khai vá»›i metrics
type CircuitState = 'CLOSED' | 'OPEN' | 'HALF_OPEN'

class SimpleCircuitBreaker {
  private state: CircuitState = 'CLOSED'
  private failureCount = 0
  private lastFailureTime = 0
  private successCount = 0

  constructor(
    private readonly fn: (...args: unknown[]) => Promise<unknown>,
    private readonly options: {
      failureThreshold: number
      resetTimeout: number
      successThreshold: number
    }
  ) {}

  async fire(...args: unknown[]): Promise<unknown> {
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.options.resetTimeout) {
        this.state = 'HALF_OPEN'
        this.successCount = 0
      } else {
        throw new Error('Circuit breaker is OPEN')
      }
    }

    try {
      const result = await this.fn(...args)
      this.onSuccess()
      return result
    } catch (err) {
      this.onFailure()
      throw err
    }
  }

  private onSuccess(): void {
    this.failureCount = 0
    if (this.state === 'HALF_OPEN') {
      this.successCount++
      if (this.successCount >= this.options.successThreshold) {
        this.state = 'CLOSED'
      }
    }
  }

  private onFailure(): void {
    this.failureCount++
    this.lastFailureTime = Date.now()
    if (this.failureCount >= this.options.failureThreshold) {
      this.state = 'OPEN'
    }
  }

  getState(): CircuitState {
    return this.state
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] Wrap táº¥t cáº£ external service calls báº±ng Circuit Breaker
- [ ] Cáº¥u hÃ¬nh timeout ngáº¯n (3-5s) cho má»—i external call
- [ ] Implement fallback logic (queue, cache, default response)
- [ ] Monitor circuit state vÃ  alert khi circuit má»Ÿ
- [ ] Test circuit breaker báº±ng chaos engineering (kill downstream service)
- [ ] Document dependency health checks trong runbook

```javascript
// eslint rule gá»£i Ã½: warn khi axios/fetch khÃ´ng Ä‘Æ°á»£c wrap trong known CB pattern
// "no-unprotected-external-call": "warn"
```

---

## Pattern 04: Distributed Lock Sai (Incorrect Redis Lock)

### 1. TÃªn
**KhÃ³a PhÃ¢n TÃ¡n Sai** (Incorrect Distributed Lock / Redis SETNX Misuse)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Concurrency
- **Subcategory:** Race Condition, Distributed Locking

### 3. Má»©c nghiÃªm trá»ng
ğŸ”´ **CRITICAL** - Race condition dáº«n Ä‘áº¿n duplicate processing, data corruption, hoáº·c double payment

### 4. Váº¥n Ä‘á»

Sá»­ dá»¥ng `SETNX` + `EXPIRE` riÃªng láº» (khÃ´ng atomic) táº¡o ra window race condition: náº¿u process crash giá»¯a `SETNX` vÃ  `EXPIRE`, lock sáº½ khÃ´ng bao giá» expire. NgoÃ i ra, khÃ´ng verify lock ownership trÆ°á»›c khi release dáº«n Ä‘áº¿n xÃ³a nháº§m lock cá»§a process khÃ¡c.

**VÃ­ dá»¥ thá»±c táº¿:** Cron job xá»­ lÃ½ payment, hai instance cÃ¹ng acquire lock, cÃ¹ng charge credit card â†’ double charge.

```
RACE CONDITION Vá»šI SETNX + EXPIRE RIÃŠNG Láºº:

Process A: SETNX "lock" "A" â”€â”€â–¶ OK (acquired)
Process A: [CRASH before EXPIRE!]
           "lock" key tá»“n táº¡i mÃ£i mÃ£i â”€â”€â–¶ DEADLOCK!

RACE CONDITION KHI RELEASE:

t=0:  Process A: acquire lock (TTL=5s)
t=4:  Process A: Ä‘ang xá»­ lÃ½ (cháº­m)
t=5:  Lock expire! (TTL háº¿t)
t=5:  Process B: acquire lock (TTL=5s)
t=6:  Process A: DEL "lock" â”€â”€â–¶ XÃ“A LOCK Cá»¦A PROCESS B!
t=6:  Process C: acquire lock â”€â”€â–¶ 2 process Ä‘ang cháº¡y song song!
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `redis.setnx()` + `redis.expire()` á»Ÿ 2 dÃ²ng riÃªng nhau
- `redis.del(lockKey)` khÃ´ng verify giÃ¡ trá»‹ trÆ°á»›c
- KhÃ´ng dÃ¹ng Redlock library cho multi-node Redis
- Lock value lÃ  constant string thay vÃ¬ unique ID

**Regex patterns (ripgrep):**
```bash
# TÃ¬m setnx khÃ´ng kÃ¨m atomic set
rg "setnx\(" --type ts -A 3 | grep -v "set.*NX\|SET.*NX"

# TÃ¬m expire sau setnx (non-atomic pattern)
rg "setnx|SETNX" --type ts -A 5

# TÃ¬m del lock khÃ´ng check ownership
rg "\.del\(.*lock\|\.del\(.*Lock" --type ts -B 3

# TÃ¬m Redlock Ä‘Ã£ dÃ¹ng Ä‘Ãºng
rg "redlock|Redlock|new Redlock" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Acquire | `SETNX` + `EXPIRE` (2 commands) | `SET key value EX ttl NX` (atomic) |
| Lock value | `'1'` (constant) | `uuid()` (unique per holder) |
| Release | `DEL key` trá»±c tiáº¿p | Lua script: check + del atomically |
| Multi-node | Single Redis | Redlock (N/2+1 nodes) |

```typescript
import { Redis } from 'ioredis'
import { v4 as uuidv4 } from 'uuid'

const redis = new Redis()

// âŒ SAI: SETNX + EXPIRE khÃ´ng atomic, khÃ´ng verify ownership
async function acquireLockBad(lockKey: string, ttlMs: number): Promise<boolean> {
  const acquired = await redis.setnx(lockKey, '1') // Non-atomic!
  if (acquired) {
    await redis.expire(lockKey, ttlMs / 1000) // Crash á»Ÿ Ä‘Ã¢y â†’ deadlock!
  }
  return acquired === 1
}

async function releaseLockBad(lockKey: string): Promise<void> {
  await redis.del(lockKey) // CÃ³ thá»ƒ xÃ³a lock cá»§a process khÃ¡c!
}

// âœ… ÄÃšNG: Atomic SET NX + Lua script Ä‘á»ƒ release
const RELEASE_LOCK_SCRIPT = `
  if redis.call("GET", KEYS[1]) == ARGV[1] then
    return redis.call("DEL", KEYS[1])
  else
    return 0
  end
`

async function acquireLockGood(
  lockKey: string,
  ttlMs: number
): Promise<string | null> {
  const lockValue = uuidv4() // Unique ID per lock holder
  // Atomic: SET key value EX ttl NX
  const result = await redis.set(lockKey, lockValue, 'PX', ttlMs, 'NX')
  return result === 'OK' ? lockValue : null
}

async function releaseLockGood(lockKey: string, lockValue: string): Promise<boolean> {
  // Atomic Lua script: check ownership + delete
  const result = await redis.eval(RELEASE_LOCK_SCRIPT, 1, lockKey, lockValue)
  return result === 1
}

// âœ… HELPER: withLock wrapper
async function withLock<T>(
  lockKey: string,
  ttlMs: number,
  fn: () => Promise<T>
): Promise<T> {
  const lockValue = await acquireLockGood(lockKey, ttlMs)
  if (!lockValue) {
    throw new Error(`Failed to acquire lock: ${lockKey}`)
  }

  try {
    return await fn()
  } finally {
    const released = await releaseLockGood(lockKey, lockValue)
    if (!released) {
      console.warn(`Lock ${lockKey} was not released (may have expired or been stolen)`)
    }
  }
}

// Usage
async function processPayment(orderId: string): Promise<void> {
  await withLock(`payment:${orderId}`, 30_000, async () => {
    const order = await db.findOrder(orderId)
    if (order.status === 'PAID') return // Idempotency check
    await chargeCard(order)
    await db.updateOrderStatus(orderId, 'PAID')
  })
}

// âœ… NÃ‚NG CAO: Redlock cho multi-node Redis
import Redlock from 'redlock'

const redlock = new Redlock([redis1, redis2, redis3], {
  retryCount: 3,
  retryDelay: 200,
  retryJitter: 100
})

async function processPaymentMultiNode(orderId: string): Promise<void> {
  const lock = await redlock.acquire([`payment:${orderId}`], 30_000)
  try {
    await chargeCard(orderId)
  } finally {
    await lock.release()
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n dÃ¹ng `SET key value EX ttl NX` (atomic), khÃ´ng dÃ¹ng SETNX + EXPIRE riÃªng
- [ ] Lock value pháº£i lÃ  unique ID (UUID), khÃ´ng pháº£i constant
- [ ] Release lock báº±ng Lua script Ä‘á»ƒ check ownership trÆ°á»›c khi delete
- [ ] DÃ¹ng Redlock cho production vá»›i Redis Cluster
- [ ] Implement lock extension náº¿u task cÃ³ thá»ƒ cháº¡y lÃ¢u hÆ¡n TTL
- [ ] Log vÃ  alert khi lock khÃ´ng release Ä‘Æ°á»£c (process crash)

```javascript
// Custom ESLint rule: cáº£nh bÃ¡o khi dÃ¹ng redis.setnx mÃ  khÃ´ng cÃ³ comment ATOMIC
// "no-nonatomic-lock": "error"
```

---

## Pattern 05: Idempotency Key Thiáº¿u

### 1. TÃªn
**Thiáº¿u KhÃ³a Idempotency** (Missing Idempotency Key)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / API Design
- **Subcategory:** Duplicate Processing, Data Integrity

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Duplicate operations: double charge, double send email, trÃ¹ng record trong DB

### 4. Váº¥n Ä‘á»

Khi client retry request (do timeout, network error), server xá»­ lÃ½ cÃ¹ng má»™t business operation nhiá»u láº§n náº¿u khÃ´ng cÃ³ idempotency key. Äáº·c biá»‡t nguy hiá»ƒm vá»›i payment, email sending, vÃ  táº¡o resource.

**VÃ­ dá»¥ thá»±c táº¿:** Client gá»­i POST /payment, timeout sau 5s, retry â†’ 2 payment Ä‘Æ°á»£c táº¡o, user bá»‹ charge 2 láº§n.

```
KHÃ”NG CÃ“ IDEMPOTENCY:

Client                    Server                    DB
  â”‚                          â”‚                       â”‚
  â”œâ”€â”€â”€â”€ POST /payment â”€â”€â”€â”€â”€â”€â–¶â”‚                       â”‚
  â”‚                          â”œâ”€â”€ INSERT payment â”€â”€â”€â”€â–¶â”‚
  â”‚                          â”‚   (id=1, amount=100)  â”‚
  â”‚                 timeout  â”‚                       â”‚
  â”‚â—€â”€â”€â”€â”€ (no response) â”€â”€â”€â”€â”€â”€â”‚                       â”‚
  â”‚                          â”‚                       â”‚
  â”œâ”€â”€â”€â”€ POST /payment â”€â”€â”€â”€â”€â”€â–¶â”‚ (retry!)              â”‚
  â”‚     (same payload)       â”œâ”€â”€ INSERT payment â”€â”€â”€â”€â–¶â”‚
  â”‚                          â”‚   (id=2, amount=100)  â”‚ â† DUPLICATE!
  â”‚â—€â”€â”€â”€â”€ 200 OK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚

CÃ“ IDEMPOTENCY KEY:

  â”œâ”€â”€â”€â”€ POST /payment â”€â”€â”€â”€â”€â”€â–¶â”‚ (Idempotency-Key: abc)
  â”‚     (Key: abc)           â”œâ”€â”€ Check: key "abc" exists? NO
  â”‚                          â”œâ”€â”€ INSERT payment (id=1)
  â”‚                          â”œâ”€â”€ Store key "abc" â†’ result
  â”‚                 timeout  â”‚
  â”œâ”€â”€â”€â”€ POST /payment â”€â”€â”€â”€â”€â”€â–¶â”‚ (retry, same Key: abc)
  â”‚     (Key: abc)           â”œâ”€â”€ Check: key "abc" exists? YES
  â”‚                          â”œâ”€â”€ Return stored result
  â”‚â—€â”€â”€â”€â”€ 200 OK (same) â”€â”€â”€â”€â”€â”€â”‚ (no duplicate!)
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- POST endpoints táº¡o resource/payment khÃ´ng check idempotency
- KhÃ´ng cÃ³ `Idempotency-Key` header processing
- INSERT vÃ o DB khÃ´ng cÃ³ unique constraint phÃ²ng duplicate
- Email/SMS sending khÃ´ng cÃ³ dedup key

**Regex patterns (ripgrep):**
```bash
# TÃ¬m POST handlers khÃ´ng cÃ³ idempotency check
rg "router\.post|app\.post|@Post" --type ts -A 10 | grep -v "idempotency\|idempotent\|dedup"

# TÃ¬m payment/charge endpoints
rg "payment|charge|invoice|billing" --type ts -i | grep -v "idempotency"

# TÃ¬m email/sms sending khÃ´ng cÃ³ dedup
rg "sendMail|sendSms|sendEmail|notif" --type ts -B 2 -A 2

# TÃ¬m idempotency Ä‘Ã£ implement
rg "Idempotency-Key|idempotencyKey|idempotent" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| POST /payment | KhÃ´ng check duplicate | Check idempotency key trÆ°á»›c |
| Key storage | KhÃ´ng cÃ³ | Redis vá»›i TTL 24h |
| Response | Táº¡o má»›i má»—i láº§n | Return cached response náº¿u key tá»“n táº¡i |
| Error case | KhÃ´ng distinguish | PhÃ¢n biá»‡t "Ä‘ang xá»­ lÃ½" vs "Ä‘Ã£ xong" |

```typescript
import { Redis } from 'ioredis'
import { Request, Response, NextFunction } from 'express'

const redis = new Redis()
const IDEMPOTENCY_TTL = 86_400 // 24 hours

// âŒ SAI: KhÃ´ng cÃ³ idempotency, duplicate payment xáº£y ra
async function createPaymentBad(req: Request, res: Response): Promise<void> {
  const { amount, cardToken, orderId } = req.body
  // Má»—i láº§n gá»i Ä‘á»u táº¡o payment má»›i!
  const payment = await paymentService.charge({ amount, cardToken, orderId })
  res.json({ paymentId: payment.id })
}

// âœ… ÄÃšNG: Idempotency middleware
interface IdempotencyRecord {
  status: 'processing' | 'completed' | 'failed'
  response?: unknown
  createdAt: number
}

async function idempotencyMiddleware(
  req: Request,
  res: Response,
  next: NextFunction
): Promise<void> {
  const idempotencyKey = req.headers['idempotency-key'] as string

  if (!idempotencyKey) {
    res.status(400).json({ error: 'Idempotency-Key header required' })
    return
  }

  const redisKey = `idempotency:${idempotencyKey}`
  const existing = await redis.get(redisKey)

  if (existing) {
    const record = JSON.parse(existing) as IdempotencyRecord

    if (record.status === 'processing') {
      res.status(409).json({ error: 'Request is being processed' })
      return
    }

    if (record.status === 'completed') {
      // Return cached response
      res.json(record.response)
      return
    }
  }

  // Mark as processing
  const record: IdempotencyRecord = { status: 'processing', createdAt: Date.now() }
  await redis.set(redisKey, JSON.stringify(record), 'EX', IDEMPOTENCY_TTL)

  // Intercept response to store it
  const originalJson = res.json.bind(res)
  res.json = (body: unknown) => {
    const completedRecord: IdempotencyRecord = {
      status: 'completed',
      response: body,
      createdAt: Date.now()
    }
    redis.set(redisKey, JSON.stringify(completedRecord), 'EX', IDEMPOTENCY_TTL)
    return originalJson(body)
  }

  next()
}

// Ãp dá»¥ng middleware cho payment routes
app.post('/payment', idempotencyMiddleware, async (req: Request, res: Response) => {
  const { amount, cardToken, orderId } = req.body
  const payment = await paymentService.charge({ amount, cardToken, orderId })
  res.json({ paymentId: payment.id })
})

// âœ… NÃ‚NG CAO: DB-level unique constraint káº¿t há»£p
// Migration SQL:
// ALTER TABLE payments ADD COLUMN idempotency_key VARCHAR(255) UNIQUE;
// CREATE UNIQUE INDEX idx_payments_idempotency ON payments(idempotency_key);

async function createPaymentWithDBGuard(
  idempotencyKey: string,
  payload: PaymentPayload
): Promise<Payment> {
  try {
    return await db.transaction(async (trx) => {
      // Unique constraint sáº½ throw náº¿u duplicate
      return await trx('payments').insert({
        ...payload,
        idempotency_key: idempotencyKey,
        created_at: new Date()
      }).returning('*')
    })
  } catch (err) {
    if (isUniqueConstraintError(err)) {
      // Return existing payment
      return await db('payments').where({ idempotency_key: idempotencyKey }).first()
    }
    throw err
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] Táº¥t cáº£ non-idempotent POST endpoints pháº£i cÃ³ Idempotency-Key support
- [ ] Store idempotency keys trong Redis vá»›i TTL há»£p lÃ½ (24h)
- [ ] ThÃªm unique constraint táº¡i DB layer lÃ m safety net
- [ ] Document idempotency requirement trong API spec (OpenAPI)
- [ ] Client SDK tá»± Ä‘á»™ng táº¡o vÃ  gá»­i idempotency key
- [ ] Alert khi phÃ¡t hiá»‡n duplicate processing (log mining)

```javascript
// ESLint rule: warn khi POST handler khÃ´ng import/use idempotency middleware
// "require-idempotency-middleware": "warn"
```

---

## Pattern 06: WebSocket Reconnection

### 1. TÃªn
**Káº¿t Ná»‘i Láº¡i WebSocket KhÃ´ng ÄÃºng** (WebSocket Reconnection Mishandling)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Real-time Communication
- **Subcategory:** Connection Management, State Synchronization

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Máº¥t tin nháº¯n, state khÃ´ng Ä‘á»“ng bá»™, memory leak tá»« zombie connections

### 4. Váº¥n Ä‘á»

WebSocket connections cÃ³ thá»ƒ bá»‹ ngáº¯t báº¥t ngá». Náº¿u client khÃ´ng reconnect Ä‘Ãºng cÃ¡ch hoáº·c server khÃ´ng handle disconnect/reconnect, client sáº½ miss events, cÃ³ state lá»—i thá»i, hoáº·c accumulate event listeners gÃ¢y memory leak.

**VÃ­ dá»¥ thá»±c táº¿:** Chat app, user máº¥t máº¡ng 10 giÃ¢y, khi reconnect khÃ´ng nháº­n Ä‘Æ°á»£c tin nháº¯n Ä‘Ã£ gá»­i trong lÃºc offline.

```
RECONNECT SAI (táº¡o listener má»›i má»—i láº§n):

connect() â”€â”€â–¶ addEventListener('message', handler)  [1 listener]
disconnect
connect() â”€â”€â–¶ addEventListener('message', handler)  [2 listeners!]
disconnect
connect() â”€â”€â–¶ addEventListener('message', handler)  [3 listeners!]
             ... má»—i message Ä‘Æ°á»£c xá»­ lÃ½ N láº§n! MEMORY LEAK!

RECONNECT ÄÃšNG:

connect() â”€â”€â–¶ addEventListener('message', handler)  [1 listener]
disconnect â”€â”€â–¶ cleanup listeners
connect() â”€â”€â–¶ addEventListener('message', handler)  [1 listener]
             + fetch missed messages (sequence number)
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `addEventListener` trong hÃ m connect khÃ´ng remove listener khi disconnect
- KhÃ´ng cÃ³ sequence number / last-event-id Ä‘á»ƒ fetch missed events
- Reconnect interval cá»‘ Ä‘á»‹nh (khÃ´ng exponential backoff)
- KhÃ´ng handle `onclose` event hoáº·c ping/pong heartbeat

**Regex patterns (ripgrep):**
```bash
# TÃ¬m WebSocket khÃ´ng cÃ³ cleanup
rg "new WebSocket|new ws\." --type ts -A 10 | grep -v "removeEventListener\|close()"

# TÃ¬m addEventListener trong connect function
rg "addEventListener\('message'" --type ts -B 5

# TÃ¬m reconnect logic
rg "onclose|on\('close'\)|reconnect" --type ts -A 5

# TÃ¬m heartbeat/ping implementation
rg "ping|heartbeat|setInterval.*ws\|ws.*setInterval" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Listener cleanup | KhÃ´ng remove | Remove trÆ°á»›c reconnect |
| Reconnect delay | Cá»‘ Ä‘á»‹nh | Exponential backoff |
| Missed messages | Bá» qua | Fetch vá»›i sequence number |
| Heartbeat | KhÃ´ng cÃ³ | Ping/pong interval |
| Max reconnects | VÃ´ háº¡n | Giá»›i háº¡n + notify user |

```typescript
// âŒ SAI: Memory leak, khÃ´ng cleanup, khÃ´ng fetch missed events
class BadWebSocketClient {
  private ws: WebSocket | null = null

  connect(url: string): void {
    this.ws = new WebSocket(url)

    // PROBLEM: Má»—i láº§n connect thÃªm 1 listener, khÃ´ng cleanup!
    this.ws.addEventListener('message', (event) => {
      this.handleMessage(JSON.parse(event.data))
    })

    this.ws.onclose = () => {
      // Reconnect ngay láº­p tá»©c, khÃ´ng cÃ³ backoff!
      setTimeout(() => this.connect(url), 1000)
    }
  }

  private handleMessage(data: unknown): void {
    console.log('message:', data)
  }
}

// âœ… ÄÃšNG: Proper cleanup, exponential backoff, sequence tracking
interface WebSocketMessage {
  seq: number
  type: string
  data: unknown
}

class RobustWebSocketClient {
  private ws: WebSocket | null = null
  private reconnectAttempt = 0
  private lastSeq = 0
  private heartbeatInterval: NodeJS.Timeout | null = null
  private readonly maxReconnectAttempts = 10
  private readonly baseReconnectDelay = 1000

  constructor(
    private readonly url: string,
    private readonly onMessage: (msg: WebSocketMessage) => void,
    private readonly onStatusChange: (status: 'connected' | 'disconnected' | 'failed') => void
  ) {}

  connect(): void {
    this.cleanup() // Cleanup trÆ°á»›c khi táº¡o connection má»›i

    this.ws = new WebSocket(`${this.url}?lastSeq=${this.lastSeq}`)

    // Bind handlers má»™t láº§n, cleanup trong disconnect
    const messageHandler = (event: MessageEvent): void => {
      const msg = JSON.parse(event.data) as WebSocketMessage
      // Bá» qua duplicate messages
      if (msg.seq <= this.lastSeq) return
      this.lastSeq = msg.seq
      this.onMessage(msg)
    }

    const openHandler = (): void => {
      this.reconnectAttempt = 0
      this.onStatusChange('connected')
      this.startHeartbeat()
    }

    const closeHandler = (event: CloseEvent): void => {
      this.cleanup()
      this.onStatusChange('disconnected')
      if (event.code !== 1000) { // 1000 = normal close
        this.scheduleReconnect()
      }
    }

    const errorHandler = (): void => {
      this.cleanup()
    }

    this.ws.addEventListener('message', messageHandler)
    this.ws.addEventListener('open', openHandler)
    this.ws.addEventListener('close', closeHandler)
    this.ws.addEventListener('error', errorHandler)

    // Store handlers Ä‘á»ƒ cleanup sau
    ;(this.ws as unknown as Record<string, unknown>).__handlers = {
      message: messageHandler,
      open: openHandler,
      close: closeHandler,
      error: errorHandler
    }
  }

  private cleanup(): void {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval)
      this.heartbeatInterval = null
    }

    if (this.ws) {
      const handlers = (this.ws as unknown as Record<string, unknown>).__handlers as Record<string, EventListener>
      if (handlers) {
        this.ws.removeEventListener('message', handlers.message)
        this.ws.removeEventListener('open', handlers.open)
        this.ws.removeEventListener('close', handlers.close)
        this.ws.removeEventListener('error', handlers.error)
      }
      if (this.ws.readyState !== WebSocket.CLOSED) {
        this.ws.close(1000)
      }
      this.ws = null
    }
  }

  private scheduleReconnect(): void {
    if (this.reconnectAttempt >= this.maxReconnectAttempts) {
      this.onStatusChange('failed')
      return
    }

    const delay = Math.min(
      this.baseReconnectDelay * Math.pow(2, this.reconnectAttempt),
      30_000
    ) * (0.5 + Math.random() * 0.5) // Add jitter

    this.reconnectAttempt++
    setTimeout(() => this.connect(), delay)
  }

  private startHeartbeat(): void {
    this.heartbeatInterval = setInterval(() => {
      if (this.ws?.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({ type: 'ping' }))
      }
    }, 30_000)
  }

  disconnect(): void {
    this.reconnectAttempt = this.maxReconnectAttempts // Prevent reconnect
    this.cleanup()
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n cleanup event listeners trÆ°á»›c khi táº¡o connection má»›i
- [ ] Implement exponential backoff cho reconnect
- [ ] Track sequence number Ä‘á»ƒ fetch missed messages khi reconnect
- [ ] Implement heartbeat (ping/pong) Ä‘á»ƒ detect zombie connections
- [ ] Giá»›i háº¡n sá»‘ láº§n reconnect vÃ  notify user khi tháº¥t báº¡i
- [ ] Server pháº£i buffer messages trong thá»i gian disconnect ngáº¯n

```javascript
// ESLint: cáº£nh bÃ¡o khi addEventListener trong function khÃ´ng cÃ³ tÆ°Æ¡ng á»©ng removeEventListener
// "paired-add-remove-event-listener": "warn"
```

---

## Pattern 07: Queue Consumer Thiáº¿u Ack (Missing Message Ack)

### 1. TÃªn
**Thiáº¿u XÃ¡c Nháº­n Tin Nháº¯n** (Missing Message Acknowledgment)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Message Queue
- **Subcategory:** Message Reliability, At-least-once Delivery

### 3. Má»©c nghiÃªm trá»ng
ğŸ”´ **CRITICAL** - Máº¥t message hoÃ n toÃ n hoáº·c xá»­ lÃ½ vÃ´ háº¡n, business logic khÃ´ng Ä‘Æ°á»£c thá»±c thi

### 4. Váº¥n Ä‘á»

Vá»›i RabbitMQ/SQS, khi consumer nháº­n message nhÆ°ng khÃ´ng ack (xÃ¡c nháº­n), message bá»‹ requeue sau timeout. Náº¿u consumer ack ngay khi nháº­n (trÆ°á»›c khi xá»­ lÃ½ xong), message bá»‹ máº¥t khi process crash giá»¯a chá»«ng. Náº¿u khÃ´ng ack sau khi xá»­ lÃ½ xong, message bá»‹ requeue vÃ´ háº¡n.

**VÃ­ dá»¥ thá»±c táº¿:** Order processing worker nháº­n message, ack ngay, crash khi Ä‘ang gá»i inventory API â†’ order tá»“n táº¡i trong DB nhÆ°ng inventory khÃ´ng Ä‘Æ°á»£c trá»«.

```
ACK NGAY (message loss khi crash):

Consumer â”€â”€â–¶ Receive msg â”€â”€â–¶ ACK â”€â”€â–¶ [CRASH] â”€â”€â–¶ msg máº¥t hoÃ n toÃ n!
                  â†‘
           Queue Ä‘Ã£ xÃ³a msg

KHÃ”NG ACK (infinite requeue):

Consumer â”€â”€â–¶ Receive msg â”€â”€â–¶ Process... â”€â”€â–¶ [No ACK] â”€â”€â–¶ Requeue after timeout
Consumer â”€â”€â–¶ Receive msg â”€â”€â–¶ Process... â”€â”€â–¶ [No ACK] â”€â”€â–¶ Requeue after timeout
                                                          (vÃ²ng láº·p vÃ´ táº­n!)

ÄÃšNG (ack sau khi xá»­ lÃ½ thÃ nh cÃ´ng):

Consumer â”€â”€â–¶ Receive msg â”€â”€â–¶ Process... â”€â”€â–¶ SUCCESS â”€â”€â–¶ ACK â”€â”€â–¶ msg removed
                                        â”€â”€â–¶ FAILURE â”€â”€â–¶ NACK (requeue with limit)
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `channel.ack(msg)` trÆ°á»›c khi processing logic hoÃ n thÃ nh
- Consumer khÃ´ng cÃ³ try/catch vá»›i `channel.nack()`
- `noAck: true` trong consume options (auto-ack)
- KhÃ´ng cÃ³ dead letter queue (DLQ) configuration

**Regex patterns (ripgrep):**
```bash
# TÃ¬m noAck: true (auto-acknowledge, dangerous)
rg "noAck:\s*true|{ noAck" --type ts

# TÃ¬m ack trÆ°á»›c processing (ack khÃ´ng náº±m trong try block sau xá»­ lÃ½)
rg "channel\.ack\|msg\.ack\|message\.ack" --type ts -B 5

# TÃ¬m consumer khÃ´ng cÃ³ nack
rg "channel\.consume|\.subscribe\(" --type ts -A 20 | grep -v "nack\|reject"

# TÃ¬m dead letter queue config
rg "deadLetterExchange|DLQ|dead.letter|dlq" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Ack timing | Ack ngay khi nháº­n | Ack SAU khi xá»­ lÃ½ thÃ nh cÃ´ng |
| Error handling | KhÃ´ng nack | Nack vá»›i requeue=false sau max retries |
| noAck | true | false (manual ack) |
| DLQ | KhÃ´ng cÃ³ | CÃ³ Dead Letter Queue |

```typescript
import amqp, { Channel, ConsumeMessage } from 'amqplib'

// âŒ SAI: Ack ngay, máº¥t message khi crash
async function startConsumerBad(): Promise<void> {
  const conn = await amqp.connect('amqp://localhost')
  const channel = await conn.createChannel()

  await channel.consume('orders', async (msg) => {
    if (!msg) return

    // ACK NGAY â†’ náº¿u crash á»Ÿ dÆ°á»›i, message máº¥t!
    channel.ack(msg)

    const order = JSON.parse(msg.content.toString())
    await processOrder(order) // Náº¿u lá»—i á»Ÿ Ä‘Ã¢y â†’ data inconsistency!
  })
}

// âŒ SAI: noAck: true (auto-acknowledge)
async function startConsumerAutoAck(): Promise<void> {
  const channel = await conn.createChannel()
  // Má»i message tá»± Ä‘á»™ng ack khi deliver, khÃ´ng thá»ƒ nack!
  await channel.consume('orders', handler, { noAck: true })
}

// âœ… ÄÃšNG: Ack sau khi xá»­ lÃ½ thÃ nh cÃ´ng, nack khi lá»—i
const MAX_RETRIES = 3

async function startConsumerGood(): Promise<void> {
  const conn = await amqp.connect('amqp://localhost')
  const channel = await conn.createChannel()

  // Setup Dead Letter Queue
  await channel.assertExchange('orders.dlx', 'direct')
  await channel.assertQueue('orders.dlq', { durable: true })
  await channel.bindQueue('orders.dlq', 'orders.dlx', 'dead')

  // Main queue vá»›i DLX config
  await channel.assertQueue('orders', {
    durable: true,
    arguments: {
      'x-dead-letter-exchange': 'orders.dlx',
      'x-dead-letter-routing-key': 'dead',
      'x-message-ttl': 60_000 // 1 minute per retry
    }
  })

  // Prefetch: chá»‰ nháº­n 1 message táº¡i má»™t thá»i Ä‘iá»ƒm
  await channel.prefetch(1)

  await channel.consume('orders', async (msg: ConsumeMessage | null) => {
    if (!msg) return

    const retryCount = (msg.properties.headers?.['x-retry-count'] as number) || 0

    try {
      const order = JSON.parse(msg.content.toString()) as Order
      await processOrder(order) // Xá»­ lÃ½ trÆ°á»›c

      // ACK chá»‰ sau khi thÃ nh cÃ´ng
      channel.ack(msg)
    } catch (err) {
      console.error('Order processing failed:', err)

      if (retryCount < MAX_RETRIES) {
        // NACK + requeue vá»›i retry count tÄƒng lÃªn
        channel.nack(msg, false, false) // false, false = khÃ´ng requeue vÃ o main queue
        // Republish vá»›i retry count header
        await channel.publish('', 'orders', msg.content, {
          persistent: true,
          headers: { 'x-retry-count': retryCount + 1 }
        })
      } else {
        // Max retries exceeded â†’ send to DLQ (no requeue)
        console.error(`Message sent to DLQ after ${MAX_RETRIES} retries`)
        channel.nack(msg, false, false)
      }
    }
  }, { noAck: false }) // Manual acknowledgment!
}

// âœ… SQS equivalent
import { SQSClient, DeleteMessageCommand, ChangeMessageVisibilityCommand } from '@aws-sdk/client-sqs'

async function processSQSMessage(
  message: SQSMessage,
  queueUrl: string
): Promise<void> {
  const sqs = new SQSClient({})

  try {
    await processOrder(JSON.parse(message.Body!))

    // Delete message (= ACK in SQS)
    await sqs.send(new DeleteMessageCommand({
      QueueUrl: queueUrl,
      ReceiptHandle: message.ReceiptHandle!
    }))
  } catch (err) {
    // Extend visibility timeout Ä‘á»ƒ retry sau
    await sqs.send(new ChangeMessageVisibilityCommand({
      QueueUrl: queueUrl,
      ReceiptHandle: message.ReceiptHandle!,
      VisibilityTimeout: 60 // Sáº½ reappear sau 60s
    }))
    throw err
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n dÃ¹ng manual ack (`noAck: false`), ACK chá»‰ sau khi xá»­ lÃ½ thÃ nh cÃ´ng
- [ ] Implement NACK vá»›i Dead Letter Queue cho failed messages
- [ ] Set `prefetch(1)` Ä‘á»ƒ khÃ´ng nháº­n quÃ¡ nhiá»u message cÃ¹ng lÃºc
- [ ] Monitor DLQ size; alert khi DLQ cÃ³ messages
- [ ] Implement idempotency trong consumer (handle duplicate delivery)
- [ ] Test consumer crash scenario (kill process giá»¯a chá»«ng)

```javascript
// ESLint: cáº£nh bÃ¡o khi channel.ack() khÃ´ng náº±m trong try block sau processing logic
// "ack-after-processing": "error"
```

---

## Pattern 08: Pub/Sub Message Loss

### 1. TÃªn
**Máº¥t Tin Nháº¯n Pub/Sub** (Pub/Sub Message Loss)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Messaging
- **Subcategory:** Event-driven Architecture, Message Durability

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Events bá»‹ máº¥t, downstream services bá»‹ thiáº¿u thÃ´ng tin, data inconsistency

### 4. Váº¥n Ä‘á»

Redis Pub/Sub khÃ´ng lÆ°u trá»¯ message: subscriber pháº£i online khi message Ä‘Æ°á»£c publish, náº¿u offline sáº½ miss táº¥t cáº£. NgoÃ i ra, náº¿u khÃ´ng cÃ³ acknowledgment, publisher khÃ´ng biáº¿t subscriber cÃ³ nháº­n Ä‘Æ°á»£c khÃ´ng.

**VÃ­ dá»¥ thá»±c táº¿:** User service publish "user.created" event, email service Ä‘ang restart â†’ email chÃ o má»«ng khÃ´ng bao giá» Ä‘Æ°á»£c gá»­i.

```
REDIS PUB/SUB (Fire-and-forget, message loss):

Publisher â”€â”€â–¶ PUBLISH "user.created" {userId: 123}
                â”‚
                â”œâ”€â”€ Email Service (ONLINE)   â”€â”€â–¶ Nháº­n Ä‘Æ°á»£c
                â”œâ”€â”€ Audit Service (RESTARTING) â”€â”€â–¶ Máº¤T!
                â””â”€â”€ Analytics (OFFLINE)        â”€â”€â–¶ Máº¤T!

PERSISTENT EVENT STREAM (Redis Streams / Kafka):

Publisher â”€â”€â–¶ XADD stream "user.created" {userId: 123}
              (Message lÆ°u trong stream)
                â”‚
                â”œâ”€â”€ Email Service (ONLINE)    â”€â”€â–¶ Äá»c tá»« stream, ACK
                â”œâ”€â”€ Audit Service (sau restart) â”€â”€â–¶ Äá»c tá»« lastId, khÃ´ng máº¥t!
                â””â”€â”€ Analytics (sau khi online)  â”€â”€â–¶ Äá»c tá»« checkpoint, khÃ´ng máº¥t!
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- DÃ¹ng `redis.publish()` / `redis.subscribe()` cho critical events
- KhÃ´ng cÃ³ message persistence (Redis Streams, Kafka, RabbitMQ)
- KhÃ´ng track consumer position / offset
- KhÃ´ng cÃ³ replay mechanism cho missed events

**Regex patterns (ripgrep):**
```bash
# TÃ¬m Redis Pub/Sub usage
rg "redis\.publish|redis\.subscribe|\.publish\(|\.subscribe\(" --type ts

# TÃ¬m Redis Streams (Ä‘Ãºng cÃ¡ch)
rg "xadd|xread|xreadgroup|XADD|XREAD" --type ts

# TÃ¬m Kafka consumer vá»›i offset tracking
rg "commitOffsets|consumer\.commit|offset" --type ts

# TÃ¬m event emitter khÃ´ng persistent
rg "EventEmitter|eventEmitter\.emit" --type ts -A 3
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Storage | Redis Pub/Sub (volatile) | Redis Streams / Kafka / RabbitMQ |
| Delivery | Fire-and-forget | At-least-once vá»›i ACK |
| Subscriber state | KhÃ´ng track | Consumer group + offset |
| Missed events | Máº¥t vÄ©nh viá»…n | Replay tá»« checkpoint |

```typescript
import { Redis } from 'ioredis'

const redis = new Redis()

// âŒ SAI: Redis Pub/Sub - message bá»‹ máº¥t khi subscriber offline
async function publishUserCreatedBad(userId: string): Promise<void> {
  // Náº¿u khÃ´ng cÃ³ subscriber nÃ o Ä‘ang listen â†’ message biáº¿n máº¥t!
  await redis.publish('user:events', JSON.stringify({
    type: 'user.created',
    userId,
    timestamp: Date.now()
  }))
}

// âŒ SAI: Subscriber cÃ³ thá»ƒ miss events
async function subscribeUserEventsBad(): Promise<void> {
  await redis.subscribe('user:events')
  redis.on('message', (channel, message) => {
    // KhÃ´ng cÃ³ ACK, khÃ´ng biáº¿t Ä‘Ã£ xá»­ lÃ½ chÆ°a
    processUserEvent(JSON.parse(message))
  })
}

// âœ… ÄÃšNG: Redis Streams vá»›i Consumer Groups
const STREAM_NAME = 'user:events'
const GROUP_NAME = 'email-service'
const CONSUMER_NAME = `consumer-${process.pid}`

async function publishUserCreatedGood(userId: string): Promise<void> {
  // XADD: message Ä‘Æ°á»£c lÆ°u trong stream, durable
  const messageId = await redis.xadd(
    STREAM_NAME,
    '*', // Auto-generate ID
    'type', 'user.created',
    'userId', userId,
    'timestamp', Date.now().toString()
  )
  console.log(`Published event ${messageId}`)
}

async function setupConsumerGroup(): Promise<void> {
  try {
    // Táº¡o consumer group, Ä‘á»c tá»« Ä‘áº§u stream ('0') hoáº·c chá»‰ má»›i ('$')
    await redis.xgroup('CREATE', STREAM_NAME, GROUP_NAME, '0', 'MKSTREAM')
  } catch (err) {
    if ((err as Error).message.includes('BUSYGROUP')) {
      console.log('Consumer group already exists')
    } else {
      throw err
    }
  }
}

async function consumeUserEventsGood(): Promise<void> {
  await setupConsumerGroup()

  while (true) {
    // Äá»c messages chÆ°a Ä‘Æ°á»£c xá»­ lÃ½ (pending)
    const results = await redis.xreadgroup(
      'GROUP', GROUP_NAME, CONSUMER_NAME,
      'COUNT', 10,
      'BLOCK', 5000, // Wait 5s náº¿u khÃ´ng cÃ³ message
      'STREAMS', STREAM_NAME, '>' // '>' = chá»‰ messages chÆ°a deliver
    ) as Array<[string, Array<[string, string[]]>]> | null

    if (!results) continue

    for (const [, messages] of results) {
      for (const [messageId, fields] of messages) {
        const event: Record<string, string> = {}
        for (let i = 0; i < fields.length; i += 2) {
          event[fields[i]] = fields[i + 1]
        }

        try {
          await processUserEvent(event)
          // ACK message sau khi xá»­ lÃ½ thÃ nh cÃ´ng
          await redis.xack(STREAM_NAME, GROUP_NAME, messageId)
        } catch (err) {
          console.error(`Failed to process event ${messageId}:`, err)
          // KhÃ´ng ACK â†’ message sáº½ remain pending, cÃ³ thá»ƒ claim láº¡i sau
        }
      }
    }

    // Claim pending messages (from crashed consumers)
    await claimPendingMessages()
  }
}

async function claimPendingMessages(): Promise<void> {
  // Claim messages pending > 5 minutes (probably from dead consumers)
  const pending = await redis.xpending(STREAM_NAME, GROUP_NAME, '-', '+', 10) as Array<[string, string, number, number]>

  for (const [messageId, , idleTime] of pending) {
    if (idleTime > 300_000) { // 5 minutes
      await redis.xclaim(STREAM_NAME, GROUP_NAME, CONSUMER_NAME, 300_000, messageId)
    }
  }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] KhÃ´ng dÃ¹ng Redis Pub/Sub cho critical business events
- [ ] DÃ¹ng Redis Streams, Kafka, hoáº·c RabbitMQ (cÃ³ persistence)
- [ ] Implement consumer groups Ä‘á»ƒ track processing state
- [ ] Handle pending messages tá»« crashed consumers (claim)
- [ ] Monitor consumer lag (messages chÆ°a Ä‘Æ°á»£c xá»­ lÃ½)
- [ ] Implement event replay capability tá»« specific offset

```javascript
// ESLint: cáº£nh bÃ¡o khi dÃ¹ng redis.publish/subscribe thay vÃ¬ streams
// "no-volatile-pubsub": "warn"
```

---

## Pattern 09: Rate Limiting Distributed

### 1. TÃªn
**Rate Limiting PhÃ¢n TÃ¡n KhÃ´ng ÄÃºng** (Distributed Rate Limiting Failure)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / API Security
- **Subcategory:** Throttling, Abuse Prevention

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ¡ **MEDIUM** - API bá»‹ láº¡m dá»¥ng, chi phÃ­ tÄƒng, áº£nh hÆ°á»Ÿng user há»£p lá»‡

### 4. Váº¥n Ä‘á»

Rate limiting chá»‰ dÃ¹ng in-memory (local) sáº½ tháº¥t báº¡i khi scale ngang. Vá»›i 10 instance, má»—i instance cho phÃ©p 100 req/min â†’ tá»•ng 1000 req/min, gáº¥p 10 láº§n giá»›i háº¡n mong muá»‘n.

**VÃ­ dá»¥ thá»±c táº¿:** API limit 100 req/min per user, nhÆ°ng 3 pods â†’ user cÃ³ thá»ƒ gá»­i 300 req/min.

```
IN-MEMORY RATE LIMIT (tháº¥t báº¡i khi scale):

User gá»­i 300 requests:
  â”œâ”€â”€ Pod 1: 100 req â†’ nháº­n cáº£ 100 (limit local = 100)
  â”œâ”€â”€ Pod 2: 100 req â†’ nháº­n cáº£ 100 (limit local = 100)
  â””â”€â”€ Pod 3: 100 req â†’ nháº­n cáº£ 100 (limit local = 100)
  Tá»•ng: 300 requests qua Ä‘Æ°á»£c! (mong muá»‘n: 100)

DISTRIBUTED RATE LIMIT (Redis):

User gá»­i 300 requests:
  â”œâ”€â”€ Pod 1: 100 req â†’ check Redis counter â†’ 100/100 â†’ nháº­n 100
  â”œâ”€â”€ Pod 2: 100 req â†’ check Redis counter â†’ 100/100 â†’ reject táº¥t cáº£
  â””â”€â”€ Pod 3: 100 req â†’ check Redis counter â†’ 100/100 â†’ reject táº¥t cáº£
  Tá»•ng: Ä‘Ãºng 100 requests qua! âœ“
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `Map<string, number>` hoáº·c `rateLimit = {}` trong-memory khÃ´ng dÃ¹ng Redis
- Rate limiter khÃ´ng shared giá»¯a instances
- KhÃ´ng cÃ³ Redis-backed rate limiter library
- `express-rate-limit` khÃ´ng cÃ³ `store` config (dÃ¹ng MemoryStore máº·c Ä‘á»‹nh)

**Regex patterns (ripgrep):**
```bash
# TÃ¬m express-rate-limit khÃ´ng cÃ³ store (dÃ¹ng MemoryStore)
rg "rateLimit\(\|rateLimiter\(" --type ts -A 10 | grep -v "store:\|redis\|Redis"

# TÃ¬m in-memory counter
rg "new Map\(\)|requestCount|hitCount" --type ts -A 3

# TÃ¬m Redis rate limiter Ä‘Ãºng cÃ¡ch
rg "rate-limit-redis|redis-rate-limit|ioredis.*limit" --type ts

# TÃ¬m sliding window hoáº·c token bucket
rg "sliding.*window|token.*bucket|leaky.*bucket" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Storage | In-memory (local) | Redis (shared) |
| Algorithm | Fixed window | Sliding window / Token bucket |
| Scale | KhÃ´ng hoáº¡t Ä‘á»™ng khi scale | ÄÃºng dÃ¹ N instances |
| Key | IP only | userId + IP + endpoint |

```typescript
import { Redis } from 'ioredis'
import { Request, Response, NextFunction } from 'express'

const redis = new Redis()

// âŒ SAI: In-memory rate limit, tháº¥t báº¡i khi scale
const requestCounts = new Map<string, { count: number; resetAt: number }>()

function rateLimitBad(limit: number, windowMs: number) {
  return (req: Request, res: Response, next: NextFunction): void => {
    const key = req.ip!
    const now = Date.now()
    const record = requestCounts.get(key)

    if (!record || now > record.resetAt) {
      requestCounts.set(key, { count: 1, resetAt: now + windowMs })
      next()
      return
    }

    if (record.count >= limit) {
      res.status(429).json({ error: 'Rate limit exceeded' })
      return
    }

    record.count++
    next()
  }
}

// âœ… ÄÃšNG: Redis-backed sliding window rate limiter
const SLIDING_WINDOW_SCRIPT = `
  local key = KEYS[1]
  local now = tonumber(ARGV[1])
  local window = tonumber(ARGV[2])
  local limit = tonumber(ARGV[3])

  -- Remove old entries outside window
  redis.call('ZREMRANGEBYSCORE', key, '-inf', now - window)

  -- Count current entries
  local current = redis.call('ZCARD', key)

  if current < limit then
    -- Add new request
    redis.call('ZADD', key, now, now .. math.random())
    redis.call('EXPIRE', key, math.ceil(window / 1000))
    return 1  -- Allowed
  else
    return 0  -- Rejected
  end
`

function rateLimitGood(limit: number, windowMs: number) {
  return async (req: Request, res: Response, next: NextFunction): Promise<void> => {
    const userId = (req as Request & { user?: { id: string } }).user?.id || req.ip!
    const endpoint = req.path
    const key = `ratelimit:${userId}:${endpoint}`
    const now = Date.now()

    const result = await redis.eval(
      SLIDING_WINDOW_SCRIPT,
      1,
      key,
      now.toString(),
      windowMs.toString(),
      limit.toString()
    ) as number

    if (result === 0) {
      // Add rate limit headers
      res.setHeader('X-RateLimit-Limit', limit)
      res.setHeader('X-RateLimit-Remaining', 0)
      res.setHeader('Retry-After', Math.ceil(windowMs / 1000))
      res.status(429).json({
        error: 'Rate limit exceeded',
        retryAfter: Math.ceil(windowMs / 1000)
      })
      return
    }

    const remaining = await redis.zcard(key)
    res.setHeader('X-RateLimit-Limit', limit)
    res.setHeader('X-RateLimit-Remaining', Math.max(0, limit - remaining))
    next()
  }
}

// âœ… NÃ‚NG CAO: DÃ¹ng rate-limit-redis vá»›i express-rate-limit
import rateLimit from 'express-rate-limit'
import RedisStore from 'rate-limit-redis'

const apiLimiter = rateLimit({
  windowMs: 60_000, // 1 minute
  max: 100,
  standardHeaders: true,
  legacyHeaders: false,
  store: new RedisStore({
    sendCommand: (...args: string[]) => redis.call(...args)
  }),
  keyGenerator: (req) => {
    const userId = (req as Request & { user?: { id: string } }).user?.id || req.ip!
    return `${userId}:${req.path}`
  }
})

app.use('/api/', apiLimiter)
```

### 7. PhÃ²ng ngá»«a

- [ ] LuÃ´n dÃ¹ng Redis-backed store cho rate limiting trong distributed environment
- [ ] DÃ¹ng sliding window algorithm thay vÃ¬ fixed window
- [ ] Rate limit theo userId (authenticated) + IP (unauthenticated)
- [ ] Set appropriate rate limit headers (X-RateLimit-*)
- [ ] Implement tiered limits (per user, per IP, per endpoint)
- [ ] Monitor rate limit hit rate Ä‘á»ƒ tune limits

```javascript
// ESLint: cáº£nh bÃ¡o khi express-rate-limit khÃ´ng cÃ³ store config
// "distributed-rate-limit-required": "warn"
```

---

## Pattern 10: Session Sticky Dependency

### 1. TÃªn
**Phá»¥ Thuá»™c Sticky Session** (Session Sticky Dependency)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Session Management
- **Subcategory:** Stateful Services, Load Balancing

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Session máº¥t khi pod restart, load balancer Ä‘á»•i pod â†’ user bá»‹ logout giá»¯a chá»«ng

### 4. Váº¥n Ä‘á»

LÆ°u session data trong-memory (hoáº·c file cá»¥c bá»™) lÃ m service stateful. Khi load balancer route request Ä‘áº¿n pod khÃ¡c, session khÃ´ng tá»“n táº¡i á»Ÿ Ä‘Ã³ â†’ user bá»‹ logout hoáº·c state bá»‹ máº¥t.

**VÃ­ dá»¥ thá»±c táº¿:** User Ä‘ang Ä‘iá»n form nhiá»u bÆ°á»›c, session lÆ°u in-memory, pod restart/scale â†’ session máº¥t, user pháº£i lÃ m láº¡i tá»« Ä‘áº§u.

```
STICKY SESSION Váº¤N Äá»€:

Request 1 â”€â”€â–¶ Pod A (session: {userId: 1, step: 3})
Request 2 â”€â”€â–¶ Pod B (session: {} â† khÃ´ng cÃ³! Pod B khÃ´ng biáº¿t gÃ¬)
              "Unauthorized" / state lost!

                    LB Route má»›i
                         â”‚
User â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”€â”¼â”€â”€â–¶ Pod A (session ok)
                         â”‚         â†‘ POD CRASH!
                         â””â”€â”€â–¶ Pod B (no session!)

STATELESS SESSION (Redis):

Request 1 â”€â”€â–¶ Pod A â”€â”€â–¶ Redis (save session)
Request 2 â”€â”€â–¶ Pod B â”€â”€â–¶ Redis (load same session) â”€â”€â–¶ OK!
Request 3 â”€â”€â–¶ Pod C â”€â”€â–¶ Redis (load same session) â”€â”€â–¶ OK!
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `express-session` khÃ´ng cÃ³ Redis store (dÃ¹ng MemoryStore)
- Global variables lÆ°u user state (`const sessions = {}`)
- File-based session storage
- Session data khÃ´ng Ä‘Æ°á»£c serialize/deserialize tá»« external store

**Regex patterns (ripgrep):**
```bash
# TÃ¬m express-session khÃ´ng cÃ³ store (MemoryStore)
rg "session\(\{" --type ts -A 10 | grep -v "store:\|redis\|Redis\|connect-redis"

# TÃ¬m in-memory session storage
rg "const sessions|let sessions|sessions\[|sessions\.set" --type ts

# TÃ¬m connect-redis Ä‘Ãºng cÃ¡ch
rg "connect-redis|RedisStore|redis.*session" --type ts

# TÃ¬m JWT (stateless alternative)
rg "jsonwebtoken|jwt\.sign|jwt\.verify" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Storage | MemoryStore (local) | Redis Store (shared) |
| State | Stateful pod | Stateless pod |
| Failover | Session máº¥t khi crash | Session persist |
| Scale | Cáº§n sticky routing | Free to route anywhere |

```typescript
import session from 'express-session'
import { createClient } from 'redis'
import connectRedis from 'connect-redis'
import jwt from 'jsonwebtoken'

// âŒ SAI: MemoryStore (máº·c Ä‘á»‹nh) - khÃ´ng work khi scale
const app = express()

app.use(session({
  secret: 'my-secret',
  resave: false,
  saveUninitialized: false,
  // KhÃ´ng cÃ³ store: â†’ dÃ¹ng MemoryStore, chá»‰ hoáº¡t Ä‘á»™ng trÃªn 1 instance!
  cookie: { secure: true, maxAge: 86_400_000 }
}))

// âœ… ÄÃšNG: Redis Store - shared across all instances
const RedisStore = connectRedis(session)
const redisClient = createClient({ url: process.env.REDIS_URL })

await redisClient.connect()

app.use(session({
  store: new RedisStore({ client: redisClient }),
  secret: process.env.SESSION_SECRET!,
  resave: false,
  saveUninitialized: false,
  cookie: {
    secure: process.env.NODE_ENV === 'production',
    httpOnly: true,
    maxAge: 86_400_000 // 24h
  }
}))

// âœ… NÃ‚NG CAO: JWT (stateless, khÃ´ng cáº§n Redis cho session)
interface JWTPayload {
  userId: string
  role: string
  iat: number
  exp: number
}

const JWT_SECRET = process.env.JWT_SECRET!
const JWT_EXPIRY = '24h'

function signToken(payload: Omit<JWTPayload, 'iat' | 'exp'>): string {
  return jwt.sign(payload, JWT_SECRET, { expiresIn: JWT_EXPIRY })
}

function verifyToken(token: string): JWTPayload {
  return jwt.verify(token, JWT_SECRET) as JWTPayload
}

// JWT Middleware
function jwtMiddleware(req: Request, res: Response, next: NextFunction): void {
  const authHeader = req.headers.authorization
  if (!authHeader?.startsWith('Bearer ')) {
    res.status(401).json({ error: 'No token provided' })
    return
  }

  const token = authHeader.slice(7)
  try {
    const payload = verifyToken(token)
    ;(req as Request & { user: JWTPayload }).user = payload
    next()
  } catch {
    res.status(401).json({ error: 'Invalid or expired token' })
  }
}

// Token rotation (refresh token pattern)
async function refreshToken(refreshToken: string): Promise<{ accessToken: string }> {
  // Verify refresh token (lÆ°u trong Redis Ä‘á»ƒ cÃ³ thá»ƒ revoke)
  const stored = await redis.get(`refresh:${refreshToken}`)
  if (!stored) throw new Error('Invalid refresh token')

  const { userId, role } = JSON.parse(stored) as JWTPayload
  const accessToken = signToken({ userId, role })
  return { accessToken }
}
```

### 7. PhÃ²ng ngá»«a

- [ ] KhÃ´ng bao giá» dÃ¹ng MemoryStore trong production
- [ ] DÃ¹ng Redis Store cho session-based auth, hoáº·c JWT cho stateless
- [ ] Thiáº¿t káº¿ service stateless tá»« Ä‘áº§u
- [ ] Test vá»›i multiple instances (docker-compose scale)
- [ ] Implement token rotation cho JWT (refresh token)
- [ ] Monitor session store availability (Redis down â†’ auth down)

```javascript
// ESLint: cáº£nh bÃ¡o khi express-session khÃ´ng cÃ³ store config
// "no-memory-session-store": "error"
```

---

## Pattern 11: Service Mesh Timeout Chain

### 1. TÃªn
**Chuá»—i Timeout Service Mesh** (Service Mesh Timeout Chain)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Microservices
- **Subcategory:** Timeout Propagation, Cascading Failure

### 3. Má»©c nghiÃªm trá»ng
ğŸ”´ **CRITICAL** - Request bá»‹ kill giá»¯a chá»«ng bá»Ÿi upstream timeout, downstream váº«n tiáº¿p tá»¥c xá»­ lÃ½ gÃ¢y resource waste vÃ  data inconsistency

### 4. Váº¥n Ä‘á»

Trong chuá»—i microservices (A â†’ B â†’ C â†’ D), náº¿u timeout khÃ´ng Ä‘Æ°á»£c set Ä‘Ãºng thá»© tá»± giáº£m dáº§n, upstream cÃ³ thá»ƒ timeout vÃ  cancel request trong khi downstream váº«n Ä‘ang xá»­ lÃ½ (vÃ  commit data). Káº¿t quáº£: A tháº¥y timeout, nhÆ°ng D Ä‘Ã£ commit transaction â†’ inconsistent state.

**VÃ­ dá»¥ thá»±c táº¿:** API Gateway timeout 5s, Service A timeout 10s, Service B xá»­ lÃ½ 7s â†’ Gateway bÃ¡o lá»—i cho client, nhÆ°ng B Ä‘Ã£ táº¡o xong record trong DB.

```
TIMEOUT CHAIN SAI:

API GW (timeout=5s) â”€â”€â–¶ Service A (timeout=10s) â”€â”€â–¶ Service B (timeout=30s)
    â”‚                         â”‚                           â”‚
    â”‚                         â”‚                           â–¼
    â”‚                     t=5s: GW                  (processing... 7s)
    â”‚â—€â”€â”€ 504 timeout â”€â”€â”€â”€  cancel req                     â”‚
    â”‚                                                     â–¼
    â”‚                                              (commit to DB at t=7s)
    â”‚                                              DATA EXISTS in B's DB
    â”‚                                              But client sees ERROR!

TIMEOUT CHAIN ÄÃšNG (decreasing timeout):

API GW (timeout=10s) â”€â”€â–¶ Service A (timeout=8s) â”€â”€â–¶ Service B (timeout=6s)
    â”‚                         â”‚                           â”‚
    â”‚                         â”‚                           â–¼
    â”‚                         â”‚                      t=6s: B times out
    â”‚                         â”‚                      B cleanup + rollback
    â”‚                         â–¼
    â”‚                    t=8s: A times out (if B slow)
    â”‚                    A cleanup + rollback
    â”‚â—€â”€â”€ 504 timeout â”€â”€â”€â”€
    â”‚                    Client sees error, data consistent
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Timeout upstream >= timeout downstream (sai thá»© tá»±)
- KhÃ´ng pass deadline/context qua service calls
- KhÃ´ng cleanup/rollback khi context bá»‹ cancel
- KhÃ´ng truyá»n `x-request-timeout` header

**Regex patterns (ripgrep):**
```bash
# TÃ¬m timeout configs
rg "timeout:\s*\d+|TIMEOUT\s*=\s*\d+" --type ts -n

# TÃ¬m AbortController usage (Ä‘Ãºng cÃ¡ch)
rg "AbortController|AbortSignal|signal:" --type ts

# TÃ¬m context cancellation handling
rg "req\.on\('close'\|signal\.aborted\|abortSignal" --type ts

# TÃ¬m axios timeout config
rg "axios\.create\|axiosInstance" --type ts -A 5 | grep -v "timeout"
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Timeout order | GW(5s) < A(10s) < B(30s) | GW(10s) > A(8s) > B(6s) |
| Context | KhÃ´ng truyá»n | Truyá»n AbortSignal / deadline |
| Cleanup | KhÃ´ng rollback | Rollback khi signal abort |
| Propagation | Hard-coded timeout | Decreasing timeout budget |

```typescript
import axios from 'axios'
import { Request, Response } from 'express'

// âŒ SAI: Timeout khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng thá»© tá»±
const SERVICE_A_TIMEOUT = 10_000 // 10s
const API_GATEWAY_TIMEOUT = 5_000  // 5s < A â†’ gateway timeout trÆ°á»›c A!

async function handleRequestBad(req: Request, res: Response): Promise<void> {
  try {
    const result = await axios.post('http://service-a/process', req.body, {
      timeout: SERVICE_A_TIMEOUT // GW Ä‘Ã£ timeout rá»“i, A váº«n chá»!
    })
    res.json(result.data)
  } catch (err) {
    res.status(504).json({ error: 'Gateway timeout' })
  }
}

// âœ… ÄÃšNG: Decreasing timeout + AbortSignal propagation
interface RequestContext {
  requestId: string
  deadline: number // Unix timestamp
  signal: AbortSignal
}

function createRequestContext(timeoutMs: number): RequestContext & { controller: AbortController } {
  const controller = new AbortController()
  const deadline = Date.now() + timeoutMs

  // Auto-abort when deadline reached
  setTimeout(() => controller.abort(), timeoutMs)

  return {
    requestId: crypto.randomUUID(),
    deadline,
    signal: controller.signal,
    controller
  }
}

function getRemainingTimeout(ctx: RequestContext): number {
  const remaining = ctx.deadline - Date.now()
  return Math.max(0, remaining - 500) // 500ms buffer for network overhead
}

// Gateway layer (outermost - largest timeout)
async function gatewayHandler(req: Request, res: Response): Promise<void> {
  const ctx = createRequestContext(10_000) // 10s total budget

  req.on('close', () => ctx.controller.abort()) // Client disconnected

  try {
    const result = await callServiceA(req.body, ctx)
    res.json(result)
  } catch (err) {
    if ((err as Error).name === 'AbortError' || (err as Error).name === 'CanceledError') {
      res.status(504).json({ error: 'Request timeout' })
    } else {
      res.status(500).json({ error: 'Internal error' })
    }
  }
}

// Service A (middle layer - smaller timeout)
async function callServiceA(payload: unknown, ctx: RequestContext): Promise<unknown> {
  const remainingMs = getRemainingTimeout(ctx)
  if (remainingMs <= 0) throw new Error('Deadline exceeded before calling Service A')

  const response = await axios.post('http://service-a/process', payload, {
    timeout: Math.min(remainingMs, 8_000), // Cap at 8s (less than gateway's 10s)
    signal: ctx.signal, // Propagate abort signal!
    headers: {
      'x-request-id': ctx.requestId,
      'x-deadline': ctx.deadline.toString()
    }
  })

  return response.data
}

// Service B (innermost - smallest timeout)
async function callServiceB(payload: unknown, ctx: RequestContext): Promise<unknown> {
  const remainingMs = getRemainingTimeout(ctx)
  if (remainingMs <= 0) throw new Error('Deadline exceeded before calling Service B')

  // Use remaining time budget, max 6s
  const timeout = Math.min(remainingMs, 6_000)

  const controller = new AbortController()
  ctx.signal.addEventListener('abort', () => controller.abort())
  setTimeout(() => controller.abort(), timeout)

  const response = await fetch('http://service-b/execute', {
    method: 'POST',
    body: JSON.stringify(payload),
    signal: controller.signal
  })

  if (!response.ok) throw new Error(`Service B error: ${response.status}`)
  return response.json()
}

// Express middleware: extract deadline from header (when acting as downstream)
function deadlineMiddleware(req: Request, res: Response, next: NextFunction): void {
  const deadline = parseInt(req.headers['x-deadline'] as string)

  if (deadline) {
    const remainingMs = deadline - Date.now()
    if (remainingMs <= 0) {
      res.status(504).json({ error: 'Deadline already exceeded' })
      return
    }

    const controller = new AbortController()
    setTimeout(() => {
      controller.abort()
      // Cleanup in-flight operations
    }, remainingMs)

    ;(req as Request & { abortSignal: AbortSignal }).abortSignal = controller.signal
  }

  next()
}
```

### 7. PhÃ²ng ngá»«a

- [ ] Document timeout budget: Gateway > A > B > C (decreasing)
- [ ] Truyá»n AbortSignal/deadline qua táº¥t cáº£ service calls
- [ ] Service pháº£i cleanup vÃ  rollback khi nháº­n abort signal
- [ ] Propagate `x-request-id` vÃ  `x-deadline` headers
- [ ] Test timeout scenarios: kill service giá»¯a chá»«ng, verify upstream behavior
- [ ] Monitor p95/p99 latency per service Ä‘á»ƒ tune timeout values

```javascript
// ESLint: cáº£nh bÃ¡o khi axios call khÃ´ng cÃ³ signal option
// "propagate-abort-signal": "warn"
```

---

## Pattern 12: Event Ordering

### 1. TÃªn
**Thá»© Tá»± Sá»± Kiá»‡n Sai** (Event Ordering / Out-of-order Events)

### 2. PhÃ¢n loáº¡i
- **Domain:** Distributed Systems / Event-driven Architecture
- **Subcategory:** Event Ordering, Consistency

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - State khÃ´ng nháº¥t quÃ¡n, business logic sai do xá»­ lÃ½ events khÃ´ng Ä‘Ãºng thá»© tá»±

### 4. Váº¥n Ä‘á»

Trong distributed systems, events cÃ³ thá»ƒ arrive out-of-order do network latency, parallel processing, hoáº·c retry logic. Xá»­ lÃ½ events khÃ´ng Ä‘Ãºng thá»© tá»± dáº«n Ä‘áº¿n state sai: xá»­ lÃ½ "order.cancelled" trÆ°á»›c "order.created" â†’ order khÃ´ng tá»“n táº¡i Ä‘á»ƒ cancel.

**VÃ­ dá»¥ thá»±c táº¿:** User táº¡o vÃ  há»§y order nhanh chÃ³ng. "cancelled" event Ä‘áº¿n trÆ°á»›c "created" event do retry â†’ há»‡ thá»‘ng khÃ´ng tÃ¬m tháº¥y order Ä‘á»ƒ cancel, order cuá»‘i cÃ¹ng váº«n á»Ÿ tráº¡ng thÃ¡i "active".

```
OUT-OF-ORDER EVENTS:

Timeline thá»±c táº¿:      t=1 order.created
                       t=2 order.cancelled

Network delivery:      t=5 order.cancelled  â†â”€â”€ Ä‘áº¿n trÆ°á»›c!
                       t=8 order.created    â†â”€â”€ Ä‘áº¿n sau

Consumer xá»­ lÃ½:
  t=5: Process "cancelled" â†’ Order not found! (skip)
  t=8: Process "created"   â†’ Order created with status ACTIVE
                             â† BUG: Ä‘Ã¡ng láº½ pháº£i CANCELLED!

GIáº¢I PHÃP (Sequence Number + Out-of-order Buffer):

  t=5: Nháº­n "cancelled" (seq=2) â†’ seq=1 chÆ°a xá»­ lÃ½ â†’ buffer
  t=8: Nháº­n "created"   (seq=1) â†’ xá»­ lÃ½ seq=1 (created)
                                â†’ xá»­ lÃ½ seq=2 tá»« buffer (cancelled)
                                â†’ Final state: CANCELLED âœ“
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Event handler khÃ´ng check sequence number / timestamp order
- Consumer khÃ´ng cÃ³ out-of-order buffer
- Multiple consumer instances xá»­ lÃ½ cÃ¹ng partition (Kafka)
- KhÃ´ng cÃ³ idempotency check káº¿t há»£p sequence number

**Regex patterns (ripgrep):**
```bash
# TÃ¬m event handler khÃ´ng check ordering
rg "on\('.*event'\|addEventListener\|\.subscribe" --type ts -A 10 | grep -v "seq\|sequence\|order\|version"

# TÃ¬m event vá»›i timestamp nhÆ°ng khÃ´ng sort
rg "event\.timestamp|createdAt|\.timestamp" --type ts -B 2 -A 5

# TÃ¬m Kafka consumer group config (ordering Ä‘áº£m báº£o per partition)
rg "partitions\|partition\|groupId" --type ts -A 5

# TÃ¬m sequence number tracking
rg "sequence\|lastSeq\|expectedSeq\|version" --type ts
```

### 6. Giáº£i phÃ¡p

| TiÃªu chÃ­ | CÃ¡ch sai | CÃ¡ch Ä‘Ãºng |
|---------|----------|-----------|
| Processing | Xá»­ lÃ½ ngay khi nháº­n | Check sequence, buffer náº¿u out-of-order |
| State update | Overwrite | Version check (optimistic locking) |
| Kafka | Multiple consumer threads per partition | 1 consumer per partition |
| Event design | KhÃ´ng cÃ³ sequence | Sequence number + aggregateId |

```typescript
// âŒ SAI: Xá»­ lÃ½ event ngay, khÃ´ng check ordering
async function processOrderEventBad(event: OrderEvent): Promise<void> {
  if (event.type === 'order.created') {
    await db.insert('orders', { id: event.orderId, status: 'ACTIVE' })
  } else if (event.type === 'order.cancelled') {
    // Náº¿u Ä‘áº¿n trÆ°á»›c order.created â†’ order khÃ´ng tá»“n táº¡i!
    await db.update('orders', event.orderId, { status: 'CANCELLED' })
  }
}

// âœ… ÄÃšNG: Sequence number + out-of-order buffer
interface OrderEvent {
  aggregateId: string  // orderId
  sequence: number     // monotonically increasing per aggregate
  type: 'order.created' | 'order.updated' | 'order.cancelled'
  payload: unknown
  timestamp: number
}

class OrderEventProcessor {
  // Buffer: aggregateId â†’ sorted pending events
  private pendingEvents = new Map<string, OrderEvent[]>()
  // Last processed sequence per aggregate
  private lastProcessed = new Map<string, number>()

  async processEvent(event: OrderEvent): Promise<void> {
    const { aggregateId, sequence } = event
    const lastSeq = this.lastProcessed.get(aggregateId) ?? 0

    if (sequence <= lastSeq) {
      // Duplicate or already processed
      console.warn(`Duplicate event seq=${sequence} for ${aggregateId}, skipping`)
      return
    }

    if (sequence !== lastSeq + 1) {
      // Out-of-order: buffer for later
      console.warn(`Out-of-order event seq=${sequence} (expected ${lastSeq + 1}) for ${aggregateId}`)
      this.bufferEvent(event)
      return
    }

    // Process in-order event
    await this.applyEvent(event)
    this.lastProcessed.set(aggregateId, sequence)

    // Process buffered events that are now in-order
    await this.flushBuffer(aggregateId)
  }

  private bufferEvent(event: OrderEvent): void {
    const buffer = this.pendingEvents.get(event.aggregateId) ?? []
    buffer.push(event)
    buffer.sort((a, b) => a.sequence - b.sequence)
    this.pendingEvents.set(event.aggregateId, buffer)
  }

  private async flushBuffer(aggregateId: string): Promise<void> {
    const buffer = this.pendingEvents.get(aggregateId) ?? []
    const lastSeq = this.lastProcessed.get(aggregateId) ?? 0

    while (buffer.length > 0 && buffer[0].sequence === lastSeq + 1) {
      const nextEvent = buffer.shift()!
      await this.applyEvent(nextEvent)
      this.lastProcessed.set(aggregateId, nextEvent.sequence)
    }

    if (buffer.length === 0) {
      this.pendingEvents.delete(aggregateId)
    } else {
      this.pendingEvents.set(aggregateId, buffer)
    }
  }

  private async applyEvent(event: OrderEvent): Promise<void> {
    switch (event.type) {
      case 'order.created':
        await db.insert('orders', {
          id: event.aggregateId,
          status: 'ACTIVE',
          version: event.sequence
        })
        break

      case 'order.cancelled':
        // Optimistic locking: chá»‰ update náº¿u version Ä‘Ãºng
        const updated = await db.updateWhere('orders',
          { id: event.aggregateId, version: event.sequence - 1 },
          { status: 'CANCELLED', version: event.sequence }
        )
        if (!updated) {
          throw new Error(`Optimistic lock failed for order ${event.aggregateId}`)
        }
        break
    }
  }
}

// âœ… NÃ‚NG CAO: Kafka - Ä‘áº£m báº£o ordering per partition
// DÃ¹ng aggregateId lÃ m partition key â†’ same order luÃ´n Ä‘áº¿n same partition
async function produceOrderEvent(event: OrderEvent): Promise<void> {
  await kafkaProducer.send({
    topic: 'order-events',
    messages: [{
      key: event.aggregateId, // Partition key = orderId
      value: JSON.stringify(event),
      headers: { sequence: event.sequence.toString() }
    }]
  })
}

// Kafka consumer: 1 consumer per partition â†’ ordering guaranteed
const consumer = kafka.consumer({ groupId: 'order-processor' })

await consumer.subscribe({ topic: 'order-events' })
await consumer.run({
  eachMessage: async ({ message }) => {
    const event = JSON.parse(message.value!.toString()) as OrderEvent
    await processor.processEvent(event)
  }
  // eachMessage processes messages sequentially within a partition
})
```

### 7. PhÃ²ng ngá»«a

- [ ] ThÃªm sequence number vÃ o má»i event (per aggregate)
- [ ] Implement out-of-order buffer vá»›i timeout Ä‘á»ƒ release stuck events
- [ ] DÃ¹ng aggregateId lÃ m Kafka partition key Ä‘á»ƒ Ä‘áº£m báº£o ordering
- [ ] Implement optimistic locking (version field) trong DB
- [ ] Monitor buffer size; alert khi events stuck quÃ¡ lÃ¢u
- [ ] Test out-of-order scenarios báº±ng chaos testing

```javascript
// ESLint: cáº£nh bÃ¡o khi event handler khÃ´ng check sequence/version
// "require-event-sequence-check": "warn"
```

---

## Tá»•ng káº¿t Domain 02

| # | Pattern | Má»©c Ä‘á»™ | Giáº£i phÃ¡p chÃ­nh |
|---|---------|--------|-----------------|
| 01 | Thundering Herd | HIGH | Redis mutex + TTL jitter |
| 02 | Retry Storm | CRITICAL | Exponential backoff + jitter |
| 03 | Circuit Breaker Thiáº¿u | HIGH | opossum / custom CB |
| 04 | Distributed Lock Sai | CRITICAL | SET NX atomic + Lua release |
| 05 | Idempotency Thiáº¿u | HIGH | Redis key + DB unique constraint |
| 06 | WebSocket Reconnect | HIGH | Cleanup listeners + backoff |
| 07 | Missing Message Ack | CRITICAL | Manual ack + DLQ |
| 08 | Pub/Sub Message Loss | HIGH | Redis Streams / Kafka |
| 09 | Rate Limit Distributed | MEDIUM | Redis sliding window |
| 10 | Sticky Session | HIGH | Redis store / JWT stateless |
| 11 | Timeout Chain | CRITICAL | Decreasing timeout + AbortSignal |
| 12 | Event Ordering | HIGH | Sequence number + buffer |

```
PRIORITY MATRIX:

CRITICAL (Fix ngay):
  â”œâ”€â”€ Retry Storm         â†’ thÃªm exponential backoff + jitter
  â”œâ”€â”€ Distributed Lock    â†’ dÃ¹ng atomic SET NX + Lua
  â”œâ”€â”€ Missing Ack         â†’ manual ack + DLQ
  â””â”€â”€ Timeout Chain       â†’ decreasing timeout + AbortSignal

HIGH (Fix trong sprint):
  â”œâ”€â”€ Thundering Herd     â†’ Redis mutex
  â”œâ”€â”€ Circuit Breaker     â†’ opossum wrapper
  â”œâ”€â”€ Idempotency         â†’ Redis + DB constraint
  â”œâ”€â”€ WebSocket Reconnect â†’ cleanup + backoff
  â”œâ”€â”€ Pub/Sub Loss        â†’ Redis Streams
  â”œâ”€â”€ Sticky Session      â†’ Redis store
  â””â”€â”€ Event Ordering      â†’ sequence number

MEDIUM (Backlog):
  â””â”€â”€ Rate Limit          â†’ Redis sliding window
```
