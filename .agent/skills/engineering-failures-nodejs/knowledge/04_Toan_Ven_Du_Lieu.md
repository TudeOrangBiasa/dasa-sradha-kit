# Domain 04: ToÃ n Váº¹n Dá»¯ Liá»‡u (Data Integrity)

| TrÆ°á»ng thÃ´ng tin | GiÃ¡ trá»‹ |
|-----------------|---------|
| **TÃªn miá»n** | ToÃ n Váº¹n Dá»¯ Liá»‡u (Data Integrity) |
| **LÄ©nh vá»±c** | Database / ORM / Data Consistency |
| **Sá»‘ lÆ°á»£ng pattern** | 10 |
| **NgÃ´n ngá»¯** | TypeScript / Node.js |
| **Cáº­p nháº­t** | 2026-02-18 |

---

## Tá»•ng quan ToÃ n Váº¹n Dá»¯ Liá»‡u

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA INTEGRITY LAYERS                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Application Layer  (Validation, Type Safety, BigInt)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ORM Layer  (N+1, Transactions, Migrations, Soft Delete) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Database Layer  (Isolation, Indexes, Schema Design)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Runtime Layer  (Race Conditions, Timezone, Encoding)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  Failure Cost:                                                  â”‚
â”‚  Application  â”€â”€â–¶  ORM  â”€â”€â–¶  Database  â”€â”€â–¶  Runtime            â”‚
â”‚     (cheap)                              (expensive to fix)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pattern 01: ORM N+1 Query

### 1. TÃªn
**Truy Váº¥n N+1 Trong ORM** (ORM N+1 Query Problem)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Performance
- **Subcategory:** ORM Misuse, Database Overhead, Prisma / Sequelize / TypeORM

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - LÃ m sáº­p database khi dataset lá»›n, response time tÄƒng theo há»‡ sá»‘ N, dá»… bá»‹ bá» sÃ³t trong code review

### 4. Váº¥n Ä‘á»

N+1 xáº£y ra khi code thá»±c hiá»‡n 1 query láº¥y danh sÃ¡ch N items, sau Ä‘Ã³ thá»±c hiá»‡n thÃªm N query riÃªng láº» Ä‘á»ƒ láº¥y dá»¯ liá»‡u liÃªn quan cá»§a tá»«ng item. Vá»›i N=1000 orders, há»‡ thá»‘ng thá»±c thi 1001 queries thay vÃ¬ 1-2.

```
N+1 QUERY EXECUTION FLOW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Code: orders.forEach(o => db.query(user WHERE id = o.userId))  â”‚
â”‚                                                                 â”‚
â”‚  Query 1: SELECT * FROM orders          â”€â”€â–¶ [o1, o2, ..., oN]  â”‚
â”‚  Query 2: SELECT * FROM users WHERE id = o1.userId             â”‚
â”‚  Query 3: SELECT * FROM users WHERE id = o2.userId             â”‚
â”‚  Query 4: SELECT * FROM users WHERE id = o3.userId             â”‚
â”‚  ...                                                            â”‚
â”‚  Query N+1: SELECT * FROM users WHERE id = oN.userId           â”‚
â”‚                                                                 â”‚
â”‚  Total: 1 + N queries  (N=1000 â†’ 1001 round trips to DB!)      â”‚
â”‚                                                                 â”‚
â”‚  SOLUTION: Eager loading / JOIN / IN clause                     â”‚
â”‚  Query 1: SELECT * FROM orders                                  â”‚
â”‚  Query 2: SELECT * FROM users WHERE id IN (id1, id2, ..., idN) â”‚
â”‚  Total: 2 queries  âœ…                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `forEach` / `map` chá»©a `await db.find()` / `await repository.findOne()`
- KhÃ´ng dÃ¹ng `include` / `relations` / `populate` trong ORM query Ä‘áº§u tiÃªn
- Log database cho tháº¥y nhiá»u query gáº§n giá»‘ng nhau liÃªn tiáº¿p

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m await trong vÃ²ng láº·p (dáº¥u hiá»‡u N+1)
rg --type ts "for.*\{[^}]*await.*find|forEach\(.*async.*await.*find" -n

# TÃ¬m prisma findMany khÃ´ng cÃ³ include
rg --type ts "\.findMany\(\s*\{(?![^}]*include)" -n

# TÃ¬m TypeORM findOne trong loop
rg --type ts "(for|forEach|map).*\n.*findOne\(" -n --multiline

# TÃ¬m Sequelize findAll trong forEach
rg --type ts "forEach.*async|map.*async" -A 5 -n | grep -A 3 "findOne\|findAll\|findByPk"
```

### 6. Giáº£i phÃ¡p

```typescript
// âŒ BAD: N+1 vá»›i Prisma
async function getOrdersWithUsers_BAD(): Promise<OrderWithUser[]> {
  const orders = await prisma.order.findMany(); // Query 1

  const result = [];
  for (const order of orders) {
    // N queries - 1 per order!
    const user = await prisma.user.findUnique({
      where: { id: order.userId }
    });
    result.push({ ...order, user });
  }
  return result;
}

// âœ… GOOD: Eager loading vá»›i Prisma include
async function getOrdersWithUsers_GOOD(): Promise<OrderWithUser[]> {
  // 1 query vá»›i JOIN
  return prisma.order.findMany({
    include: {
      user: true,
      items: {
        include: { product: true }
      }
    }
  });
}

// âŒ BAD: N+1 vá»›i TypeORM
async function getPostsWithAuthors_BAD() {
  const posts = await postRepository.find(); // KhÃ´ng load relations

  return Promise.all(
    posts.map(async (post) => {
      // N queries!
      const author = await userRepository.findOneBy({ id: post.authorId });
      return { ...post, author };
    })
  );
}

// âœ… GOOD: TypeORM vá»›i relations
async function getPostsWithAuthors_GOOD() {
  return postRepository.find({
    relations: {
      author: true,
      comments: {
        author: true
      }
    }
  });
}

// âŒ BAD: N+1 vá»›i Sequelize
async function getProductsWithCategory_BAD() {
  const products = await Product.findAll(); // KhÃ´ng include

  return Promise.all(
    products.map(async (p) => {
      const category = await Category.findByPk(p.categoryId); // N queries
      return { ...p.toJSON(), category: category?.toJSON() };
    })
  );
}

// âœ… GOOD: Sequelize vá»›i include
async function getProductsWithCategory_GOOD() {
  return Product.findAll({
    include: [
      {
        model: Category,
        attributes: ['id', 'name', 'slug']
      }
    ]
  });
}

// âœ… ADVANCED: Khi cáº§n custom logic - dÃ¹ng IN clause thá»§ cÃ´ng
async function getOrdersCustom(orderIds: number[]) {
  const orders = await prisma.order.findMany({
    where: { id: { in: orderIds } }
  });

  // Collect all userIds (deduplicated)
  const userIds = [...new Set(orders.map((o) => o.userId))];

  // 1 query láº¥y táº¥t cáº£ users
  const users = await prisma.user.findMany({
    where: { id: { in: userIds } }
  });

  // Build lookup map O(1)
  const userMap = new Map(users.map((u) => [u.id, u]));

  // Merge in memory
  return orders.map((order) => ({
    ...order,
    user: userMap.get(order.userId)
  }));
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// ESLint rule: eslint-plugin-no-await-in-loop (cáº£nh bÃ¡o await trong vÃ²ng láº·p)
// .eslintrc.js
module.exports = {
  rules: {
    'no-await-in-loop': 'warn', // Cáº£nh bÃ¡o khi await trong for/while
  }
};

// Báº­t Prisma query logging Ä‘á»ƒ phÃ¡t hiá»‡n N+1 trong dev:
// prisma.ts
const prisma = new PrismaClient({
  log: process.env.NODE_ENV === 'development'
    ? [{ level: 'query', emit: 'event' }]
    : []
});

if (process.env.NODE_ENV === 'development') {
  let queryCount = 0;
  prisma.$on('query', (e) => {
    queryCount++;
    if (queryCount > 10) {
      console.warn(`[N+1 Warning] Query #${queryCount}: ${e.query}`);
    }
  });
}
```

---

## Pattern 02: Transaction Isolation Sai

### 1. TÃªn
**Má»©c CÃ´ Láº­p Transaction KhÃ´ng ÄÃºng** (Transaction Isolation Level Mismatch)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Concurrency
- **Subcategory:** ACID Properties, Database Transactions, Race Conditions

### 3. Má»©c nghiÃªm trá»ng
ğŸ”´ **CRITICAL** - GÃ¢y máº¥t dá»¯ liá»‡u, double-spending, phantom reads, inconsistent state trong mÃ´i trÆ°á»ng concurrent

### 4. Váº¥n Ä‘á»

SQL databases cÃ³ 4 má»©c isolation: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE. DÃ¹ng sai má»©c hoáº·c khÃ´ng dÃ¹ng transaction khiáº¿n concurrent operations gÃ¢y ra dirty reads, non-repeatable reads, phantom reads, vÃ  lost updates.

```
ISOLATION PROBLEMS MATRIX:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Isolation Level  â”‚  Dirty    â”‚ Non-repeat  â”‚  Phantom    â”‚ Lost       â”‚
â”‚                  â”‚  Read     â”‚ Read        â”‚  Read       â”‚ Update     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ READ UNCOMMITTED â”‚    YES    â”‚     YES     â”‚     YES     â”‚    YES     â”‚
â”‚ READ COMMITTED   â”‚    NO     â”‚     YES     â”‚     YES     â”‚    YES     â”‚
â”‚ REPEATABLE READ  â”‚    NO     â”‚     NO      â”‚     YES     â”‚    NO      â”‚
â”‚ SERIALIZABLE     â”‚    NO     â”‚     NO      â”‚     NO      â”‚    NO      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LOST UPDATE SCENARIO (race condition khÃ´ng cÃ³ proper isolation):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  T=0: stock = 10                                               â”‚
â”‚                                                                â”‚
â”‚  Transaction A              Transaction B                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  READ stock = 10            READ stock = 10                    â”‚
â”‚  Calculate: 10 - 3 = 7      Calculate: 10 - 8 = 2             â”‚
â”‚  WRITE stock = 7            WRITE stock = 2   â† overwrites A! â”‚
â”‚                                                                â”‚
â”‚  T=end: stock = 2  (should be -1 â†’ out of stock error!)       â”‚
â”‚  Result: OVERSOLD! Data integrity violated                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Read-then-write (select rá»“i update) mÃ  khÃ´ng cÃ³ `FOR UPDATE` hoáº·c optimistic locking
- Multiple DB operations khÃ´ng Ä‘Æ°á»£c bá»c trong transaction
- `prisma.$transaction` / `sequelize.transaction` váº¯ng máº·t trong business-critical flows

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m update sau findFirst/findUnique mÃ  khÃ´ng cÃ³ transaction
rg --type ts "findFirst|findUnique" -A 10 -n | grep -B 5 "update\|save\(\)"

# TÃ¬m stock/balance/quantity update khÃ´ng dÃ¹ng transaction
rg --type ts "(stock|balance|quantity|amount).*update" -n

# TÃ¬m $transaction usage (Ä‘á»ƒ biáº¿t Ä‘Ã¢u CÃ“ dÃ¹ng, Ä‘Ã¢u THIáº¾U)
rg --type ts "\.\$transaction\|sequelize\.transaction\|queryRunner\.startTransaction" -n

# TÃ¬m cÃ¡c hÃ m transferFunds / deductBalance khÃ´ng cÃ³ transaction wrapper
rg --type ts "async.*transfer|async.*deduct|async.*withdraw|async.*charge" -n
```

### 6. Giáº£i phÃ¡p

```typescript
// âŒ BAD: KhÃ´ng dÃ¹ng transaction - race condition
async function purchaseItem_BAD(userId: number, productId: number, qty: number) {
  const product = await prisma.product.findUnique({
    where: { id: productId }
  });

  if (!product || product.stock < qty) {
    throw new Error('Insufficient stock');
  }

  // RACE CONDITION: Another request can change stock between read and write!
  await prisma.product.update({
    where: { id: productId },
    data: { stock: product.stock - qty }
  });

  await prisma.order.create({
    data: { userId, productId, quantity: qty }
  });
}

// âœ… GOOD: Prisma transaction vá»›i pessimistic locking
async function purchaseItem_GOOD(userId: number, productId: number, qty: number) {
  return prisma.$transaction(
    async (tx) => {
      // Raw SQL FOR UPDATE locks the row until transaction ends
      const [product] = await tx.$queryRaw<Product[]>`
        SELECT * FROM products WHERE id = ${productId} FOR UPDATE
      `;

      if (!product || product.stock < qty) {
        throw new Error('Insufficient stock');
      }

      const updatedProduct = await tx.product.update({
        where: { id: productId },
        data: { stock: { decrement: qty } }
      });

      const order = await tx.order.create({
        data: { userId, productId, quantity: qty, totalPrice: product.price * qty }
      });

      return { order, remainingStock: updatedProduct.stock };
    },
    {
      isolationLevel: Prisma.TransactionIsolationLevel.Serializable,
      maxWait: 5000,
      timeout: 10000
    }
  );
}

// âœ… GOOD: Optimistic locking vá»›i version field
interface Product {
  id: number;
  stock: number;
  version: number;
}

async function purchaseOptimistic(userId: number, productId: number, qty: number) {
  const MAX_RETRIES = 3;

  for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
    const product = await prisma.product.findUniqueOrThrow({
      where: { id: productId }
    });

    if (product.stock < qty) throw new Error('Insufficient stock');

    try {
      return await prisma.$transaction(async (tx) => {
        // Update chá»‰ thÃ nh cÃ´ng náº¿u version chÆ°a thay Ä‘á»•i
        const result = await tx.product.updateMany({
          where: {
            id: productId,
            version: product.version // Optimistic lock check
          },
          data: {
            stock: { decrement: qty },
            version: { increment: 1 }
          }
        });

        if (result.count === 0) {
          throw new Error('OPTIMISTIC_LOCK_FAILED'); // Sáº½ Ä‘Æ°á»£c retry
        }

        return tx.order.create({
          data: { userId, productId, quantity: qty }
        });
      });
    } catch (error) {
      if (error instanceof Error && error.message === 'OPTIMISTIC_LOCK_FAILED') {
        if (attempt === MAX_RETRIES - 1) throw new Error('Too many conflicts, try again');
        await new Promise((r) => setTimeout(r, 50 * (attempt + 1))); // Exponential backoff
        continue;
      }
      throw error;
    }
  }
}

// âœ… GOOD: TypeORM vá»›i isolation level
import { DataSource, IsolationLevel } from 'typeorm';

async function transferBalance(
  dataSource: DataSource,
  fromId: number,
  toId: number,
  amount: number
) {
  await dataSource.transaction(
    IsolationLevel.SERIALIZABLE,
    async (manager) => {
      const from = await manager.findOneOrFail(Account, {
        where: { id: fromId },
        lock: { mode: 'pessimistic_write' }
      });

      const to = await manager.findOneOrFail(Account, {
        where: { id: toId },
        lock: { mode: 'pessimistic_write' }
      });

      if (from.balance < amount) throw new Error('Insufficient balance');

      from.balance -= amount;
      to.balance += amount;

      await manager.save([from, to]);
    }
  );
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// Custom ESLint rule Ä‘á»ƒ phÃ¡t hiá»‡n update sau findUnique mÃ  khÃ´ng cÃ³ transaction
// Cáº§n dÃ¹ng eslint-plugin-custom hoáº·c review manual

// Prisma middleware Ä‘á»ƒ log transactions
prisma.$use(async (params, next) => {
  if (['update', 'updateMany', 'delete', 'deleteMany'].includes(params.action)) {
    // Kiá»ƒm tra cÃ³ trong transaction context khÃ´ng
    if (!params.runInTransaction) {
      console.warn(
        `[TX Warning] ${params.model}.${params.action} called outside transaction`
      );
    }
  }
  return next(params);
});
```

---

## Pattern 03: MongoDB Schema Design Sai

### 1. TÃªn
**Thiáº¿t Káº¿ Schema MongoDB KhÃ´ng PhÃ¹ Há»£p** (MongoDB Embedding vs Referencing Mismatch)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Schema Design
- **Subcategory:** NoSQL Design, Document Model, MongoDB

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Document size limit 16MB, query performance degraded, data duplication gÃ¢y inconsistency khÃ³ sá»­a sau khi production

### 4. Váº¥n Ä‘á»

MongoDB cho phÃ©p embed documents hoáº·c reference (nhÆ° foreign key). Chá»n sai strategy dáº«n Ä‘áº¿n: document vÆ°á»£t 16MB limit, unbounded array growth, stale data do duplication, hoáº·c quÃ¡ nhiá»u round-trips do over-referencing.

```
EMBEDDING vs REFERENCING DECISION TREE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Q1: Data cÃ³ unbounded growth khÃ´ng? (comments, events, logs)  â”‚
â”‚       YES â”€â”€â–¶ REFERENCE (embed sáº½ vÆ°á»£t 16MB limit)            â”‚
â”‚       NO  â”€â”€â–¶ Q2                                               â”‚
â”‚                                                                â”‚
â”‚  Q2: Data cÃ³ Ä‘Æ°á»£c query Ä‘á»™c láº­p khÃ´ng?                         â”‚
â”‚       YES â”€â”€â–¶ REFERENCE (náº¿u query riÃªng láº» thÆ°á»ng xuyÃªn)     â”‚
â”‚       NO  â”€â”€â–¶ Q3                                               â”‚
â”‚                                                                â”‚
â”‚  Q3: Tá»· lá»‡ Ä‘á»c vs ghi cá»§a sub-document?                       â”‚
â”‚       LuÃ´n Ä‘á»c cÃ¹ng parent â”€â”€â–¶ EMBED (1 read, tá»‘i Æ°u)         â”‚
â”‚       Äá»c/ghi Ä‘á»™c láº­p      â”€â”€â–¶ REFERENCE                      â”‚
â”‚                                                                â”‚
â”‚  RULE OF THUMB:                                                â”‚
â”‚  Embed: address trong user, items trong invoice (bounded)      â”‚
â”‚  Reference: comments (unbounded), orders cá»§a user (unbounded)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DOCUMENT SIZE GROWTH PROBLEM:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  { _id: "post123",                                             â”‚
â”‚    title: "...",                                               â”‚
â”‚    comments: [                â† EMBEDDED unbounded array       â”‚
â”‚      { text: "..." },         â† Day 1: 10 comments = 5KB      â”‚
â”‚      { text: "..." },         â† Day 30: 1000 comments = 500KB â”‚
â”‚      ...                      â† Day 365: 50000 = 25MB âŒ      â”‚
â”‚    ]                          â† EXCEEDS 16MB LIMIT!            â”‚
â”‚  }                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `$push` vÃ o array field mÃ  khÃ´ng cÃ³ `$slice` giá»›i háº¡n
- Schema cÃ³ `[{ type: Schema.Types.ObjectId }]` nhÆ°ng dá»¯ liá»‡u thá»±c táº¿ lÃ  bounded
- Schema cÃ³ sub-document array nhÆ°ng dá»¯ liá»‡u lÃ  unbounded (comments, logs, events)
- `populate()` trong má»i query thay vÃ¬ embed data thÆ°á»ng xuyÃªn Ä‘á»c cÃ¹ng nhau

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m $push vÃ o array mÃ  khÃ´ng cÃ³ giá»›i háº¡n
rg --type ts "\\\$push.*\\\$slice" -n
rg --type ts "\\\$push" -n  # TÃ¬m táº¥t cáº£ $push Ä‘á»ƒ review

# TÃ¬m schema vá»›i array references (cáº§n review xem bounded hay khÃ´ng)
rg --type ts "type:.*Schema\.Types\.ObjectId.*\]|\[.*ObjectId" -n

# TÃ¬m nested populate sÃ¢u (dáº¥u hiá»‡u over-referencing)
rg --type ts "populate\(.*populate\(" -n

# TÃ¬m schema arrays khÃ´ng cÃ³ maxlength
rg --type ts "type.*\[.*\]" -B 2 -A 2 -n | grep -v "maxlength\|limit\|max"
```

### 6. Giáº£i phÃ¡p

```typescript
import { Schema, model, Types } from 'mongoose';

// âŒ BAD: Embed comments (unbounded growth â†’ vÆ°á»£t 16MB)
const PostSchema_BAD = new Schema({
  title: String,
  content: String,
  // Sáº½ cÃ³ hÃ ng nghÃ¬n comments â†’ document quÃ¡ lá»›n
  comments: [
    {
      author: String,
      text: String,
      createdAt: Date
    }
  ]
});

// âœ… GOOD: Reference comments (unbounded array)
const PostSchema_GOOD = new Schema({
  title: String,
  content: String,
  commentCount: { type: Number, default: 0 } // Denormalize counter (read-friendly)
});

const CommentSchema = new Schema({
  postId: { type: Types.ObjectId, ref: 'Post', index: true }, // Index báº¯t buá»™c
  author: String,
  text: String,
  createdAt: { type: Date, default: Date.now }
});

// âŒ BAD: Reference address (luÃ´n Ä‘á»c cÃ¹ng user, bounded, khÃ´ng query Ä‘á»™c láº­p)
const UserSchema_BAD = new Schema({
  name: String,
  email: String,
  addressId: { type: Types.ObjectId, ref: 'Address' } // Over-referenced
});

// âœ… GOOD: Embed address (bounded, always read with user)
const UserSchema_GOOD = new Schema({
  name: String,
  email: String,
  address: {
    // Embedded - 1 read thay vÃ¬ 2
    street: String,
    city: String,
    country: String,
    zipCode: String
  }
});

// âœ… GOOD: Hybrid pattern - embed recent + reference all
const ArticleSchema = new Schema({
  title: String,
  content: String,
  // Chá»‰ embed 5 comments gáº§n nháº¥t (bounded, for display)
  recentComments: {
    type: [
      {
        author: String,
        text: String,
        createdAt: Date
      }
    ],
    validate: {
      validator: (v: unknown[]) => v.length <= 5,
      message: 'recentComments cannot exceed 5 items'
    }
  },
  commentCount: { type: Number, default: 0 }
});

// Service: thÃªm comment vÃ  cáº­p nháº­t recentComments
async function addComment(articleId: string, comment: { author: string; text: string }) {
  const session = await mongoose.startSession();
  session.startTransaction();

  try {
    // Táº¡o comment trong collection riÃªng
    const newComment = await Comment.create([{ articleId, ...comment }], { session });

    // Cáº­p nháº­t article: push vÃ o recent (giá»¯ tá»‘i Ä‘a 5), tÄƒng counter
    await Article.findByIdAndUpdate(
      articleId,
      {
        $push: {
          recentComments: {
            $each: [{ ...comment, createdAt: new Date() }],
            $sort: { createdAt: -1 },
            $slice: 5 // Chá»‰ giá»¯ 5 gáº§n nháº¥t
          }
        },
        $inc: { commentCount: 1 }
      },
      { session }
    );

    await session.commitTransaction();
    return newComment[0];
  } catch (error) {
    await session.abortTransaction();
    throw error;
  } finally {
    session.endSession();
  }
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// Mongoose plugin Ä‘á»ƒ giá»›i háº¡n array size
const boundedArrayPlugin = (schema, { fields = [], maxSize = 100 } = {}) => {
  schema.pre('save', function (next) {
    for (const field of fields) {
      if (Array.isArray(this[field]) && this[field].length > maxSize) {
        next(new Error(`Array field "${field}" exceeds max size of ${maxSize}`));
        return;
      }
    }
    next();
  });
};

// Ãp dá»¥ng:
PostSchema.plugin(boundedArrayPlugin, {
  fields: ['tags', 'attachments'],
  maxSize: 20
});
```

---

## Pattern 04: JSON BigInt Loss

### 1. TÃªn
**Máº¥t Äá»™ ChÃ­nh XÃ¡c BigInt Qua JSON** (JSON BigInt Precision Loss)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Type Safety
- **Subcategory:** JavaScript Number Limits, Serialization, API Response

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - ID bá»‹ sai Ã¢m tháº§m, khÃ´ng cÃ³ lá»—i nÃ o Ä‘Æ°á»£c throw, gÃ¢y bug khÃ³ debug á»Ÿ production

### 4. Váº¥n Ä‘á»

`Number.MAX_SAFE_INTEGER = 2^53 - 1 = 9007199254740991`. Má»i integer lá»›n hÆ¡n giÃ¡ trá»‹ nÃ y khÃ´ng thá»ƒ biá»ƒu diá»…n chÃ­nh xÃ¡c báº±ng JavaScript `number`. Database IDs (PostgreSQL bigint, Twitter Snowflake IDs, MongoDB ObjectId dáº¡ng sá»‘) thÆ°á»ng vÆ°á»£t giá»›i háº¡n nÃ y.

```
BIGINT PRECISION LOSS FLOW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database: id = 9007199254740993 (2^53 + 1)                     â”‚
â”‚                     â”‚                                           â”‚
â”‚  Prisma / Driver    â–¼                                           â”‚
â”‚  JSON.stringify: "9007199254740993"  â”€â”€â–¶  "9007199254740992"   â”‚
â”‚                                          ^^^^^^^^^^^^^^^^        â”‚
â”‚                                          WRONG! (rounded)        â”‚
â”‚                     â”‚                                           â”‚
â”‚  Frontend receives: 9007199254740992                            â”‚
â”‚  API call: GET /users/9007199254740992  â”€â”€â–¶  404 Not Found!    â”‚
â”‚                                                                 â”‚
â”‚  Sá»‘ bá»‹ affected:                                               â”‚
â”‚  9007199254740993 â”€â”€â–¶ 9007199254740992  (off by 1!)            â”‚
â”‚  9007199254740995 â”€â”€â–¶ 9007199254740996  (off by 1!)            â”‚
â”‚  9007199254740997 â”€â”€â–¶ 9007199254740996  (off by 1!)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Database dÃ¹ng `bigint` / `bigserial` cho ID nhÆ°ng TypeScript dÃ¹ng `number`
- `JSON.parse()` / `JSON.stringify()` trá»±c tiáº¿p vá»›i response tá»« DB cÃ³ bigint
- Prisma schema dÃ¹ng `BigInt` nhÆ°ng DTO serialize sang `number`

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m BigInt trong Prisma schema
rg "BigInt|bigint" prisma/schema.prisma -n

# TÃ¬m nÆ¡i convert BigInt sang Number (nguy hiá»ƒm)
rg --type ts "Number\(.*[Bb]ig[Ii]nt\|parseInt.*[Bb]ig[Ii]nt\|as number" -n

# TÃ¬m JSON.stringify vá»›i potential BigInt fields
rg --type ts "JSON\.stringify" -n -A 2

# TÃ¬m id fields typed as number thay vÃ¬ string/bigint
rg --type ts "id\s*:\s*number" -n

# TÃ¬m Snowflake ID / Twitter ID patterns
rg --type ts "snowflake|twitterId|discordId" -n
```

### 6. Giáº£i phÃ¡p

```typescript
// âŒ BAD: BigInt ID bá»‹ máº¥t precision qua JSON
interface User {
  id: number; // WRONG: sáº½ máº¥t precision náº¿u id > 2^53
  name: string;
}

async function getUser_BAD(id: number): Promise<User> {
  const user = await prisma.user.findUnique({ where: { id } });
  // Prisma tráº£ vá» BigInt, implicit convert sang number â†’ máº¥t precision!
  return user as User;
}

// API response
app.get('/users/:id', async (req, res) => {
  const user = await prisma.user.findUnique({
    where: { id: BigInt(req.params.id) }
  });
  // JSON.stringify khÃ´ng handle BigInt â†’ TypeError!
  res.json(user); // âŒ Throws: "Do not know how to serialize a BigInt"
});

// âœ… GOOD: Serialize BigInt thÃ nh String
interface UserDTO {
  id: string; // String Ä‘á»ƒ giá»¯ full precision
  name: string;
  createdAt: string;
}

function serializeUser(user: { id: bigint; name: string; createdAt: Date }): UserDTO {
  return {
    id: user.id.toString(), // BigInt â†’ String (khÃ´ng máº¥t precision)
    name: user.name,
    createdAt: user.createdAt.toISOString()
  };
}

// âœ… GOOD: Global BigInt JSON serializer (Express middleware)
function bigIntJsonMiddleware(
  _req: Request,
  res: Response,
  next: NextFunction
): void {
  const originalJson = res.json.bind(res);

  res.json = (body: unknown) => {
    const serialized = JSON.stringify(body, (_key, value) =>
      typeof value === 'bigint' ? value.toString() : value
    );
    res.setHeader('Content-Type', 'application/json');
    return res.send(serialized);
  };

  next();
}

// âœ… GOOD: Prisma - configure BigInt serialization globally
// prisma/client.ts
import Prisma from '@prisma/client';

// Override BigInt prototype Ä‘á»ƒ JSON.stringify hoáº¡t Ä‘á»™ng
(BigInt.prototype as unknown as { toJSON: () => string }).toJSON = function () {
  return this.toString();
};

// âœ… GOOD: Zod schema vá»›i string-coerced BigInt
import { z } from 'zod';

const BigIntString = z.string().refine(
  (val) => {
    try {
      BigInt(val);
      return true;
    } catch {
      return false;
    }
  },
  { message: 'Must be a valid BigInt string' }
);

const UserIdSchema = z.object({
  id: BigIntString
});

// âœ… GOOD: Nháº­n ID tá»« request params an toÃ n
app.get('/users/:id', async (req, res) => {
  const { id } = UserIdSchema.parse(req.params);

  const user = await prisma.user.findUnique({
    where: { id: BigInt(id) }
  });

  if (!user) return res.status(404).json({ error: 'User not found' });

  res.json(serializeUser(user));
});
```

### 7. PhÃ²ng ngá»«a

```javascript
// ESLint: khÃ´ng cho phÃ©p implicit any trÃªn BigInt fields
// .eslintrc.js
module.exports = {
  rules: {
    '@typescript-eslint/no-loss-of-precision': 'error',
    // Báº¯t buá»™c explicit type annotation
    '@typescript-eslint/no-explicit-any': 'error',
  }
};

// tsconfig.json - báº­t strict Ä‘á»ƒ phÃ¡t hiá»‡n type mismatch
{
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true
  }
}
```

---

## Pattern 05: Date Timezone Pitfalls

### 1. TÃªn
**Báº«y MÃºi Giá» Vá»›i Date** (Date Timezone Pitfalls)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Localization
- **Subcategory:** Date Handling, UTC, Timezone Conversion

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Appointment bá»‹ sai giá», bÃ¡o cÃ¡o tÃ i chÃ­nh sai ngÃ y, dá»¯ liá»‡u bá»‹ group sai do offset timezone server/client khÃ¡c nhau

### 4. Váº¥n Ä‘á»

JavaScript `Date` khÃ´ng lÆ°u timezone info, chá»‰ lÆ°u UTC milliseconds. `new Date()` dÃ¹ng timezone cá»§a process. Server cháº¡y UTC, client cháº¡y Asia/Tokyo (+9), database lÆ°u timestamp without timezone â†’ má»i táº§ng interpret khÃ¡c nhau.

```
TIMEZONE CHAOS SCENARIO:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Ä‘áº·t lá»‹ch háº¹n: "2026-02-18 09:00" (Asia/Tokyo, +9)       â”‚
â”‚                                                                â”‚
â”‚  Frontend (Tokyo, +9):                                         â”‚
â”‚    new Date('2026-02-18 09:00')  â†’  2026-02-18T00:00:00Z (UTC)â”‚
â”‚                    â”‚                                           â”‚
â”‚  Server (UTC, +0): â”‚                                           â”‚
â”‚    Receives UTC    â†’  Saves "2026-02-18 00:00:00"             â”‚
â”‚                    â”‚                                           â”‚
â”‚  Database (no tz): â”‚                                           â”‚
â”‚    Stores literally: 2026-02-18 00:00:00                      â”‚
â”‚                    â”‚                                           â”‚
â”‚  Other server (US/New York, -5):                              â”‚
â”‚    Reads: "2026-02-18 00:00:00"                               â”‚
â”‚    Interprets as local: 2026-02-18T05:00:00Z (UTC)            â”‚
â”‚                                                                â”‚
â”‚  Result: Appointment appears 5 hours late for NY server! âŒ   â”‚
â”‚                                                                â”‚
â”‚  FIX: ALWAYS store UTC, always send ISO 8601 with timezone    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `new Date(dateString)` vá»›i string khÃ´ng cÃ³ timezone info
- `date.toLocaleDateString()` / `date.toLocaleTimeString()` trong backend
- Prisma/TypeORM column `timestamp` (without timezone) thay vÃ¬ `timestamptz`
- `moment()` hoáº·c `new Date()` khÃ´ng specify timezone

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m new Date vá»›i string khÃ´ng cÃ³ Z hoáº·c offset
rg --type ts "new Date\(['\"][\d-]+['\"]" -n

# TÃ¬m toLocaleDateString/toLocaleString trong backend code
rg --type ts "toLocaleDateString\|toLocaleString\|toLocaleTimeString" -n

# TÃ¬m timestamp column type trong TypeORM (cáº§n kiá»ƒm tra cÃ³ timezone khÃ´ng)
rg --type ts "type.*timestamp\b" -n

# TÃ¬m Prisma DateTime mÃ  khÃ´ng cÃ³ @db.Timestamptz
rg "DateTime" prisma/schema.prisma -n | grep -v "Timestamptz\|updatedAt\|createdAt"

# TÃ¬m date comparison trá»±c tiáº¿p (sai khi cÃ³ timezone)
rg --type ts "\.getDate\(\)\|\.getMonth\(\)\|\.getFullYear\(\)" -n
```

### 6. Giáº£i phÃ¡p

```typescript
// âŒ BAD: Táº¡o Date tá»« string khÃ´ng rÃµ timezone
const appointmentDate = new Date('2026-02-18 09:00'); // Timezone phá»¥ thuá»™c server!
const startOfDay = new Date('2026-02-18');             // CÅ©ng khÃ´ng rÃµ timezone

// âŒ BAD: So sÃ¡nh date string trá»±c tiáº¿p
function isToday_BAD(dateStr: string): boolean {
  const today = new Date().toLocaleDateString(); // Server timezone!
  return new Date(dateStr).toLocaleDateString() === today; // Sai khi client â‰  server timezone
}

// âœ… GOOD: LuÃ´n dÃ¹ng UTC, luÃ´n parse ISO 8601 vá»›i timezone
const appointmentDate = new Date('2026-02-18T09:00:00+09:00'); // Explicit JST
const utcTimestamp = appointmentDate.toISOString(); // "2026-02-18T00:00:00.000Z"

// âœ… GOOD: Temporal API (Node.js 18+ vá»›i polyfill, hoáº·c dÃ¹ng date-fns-tz)
import { zonedTimeToUtc, utcToZonedTime, format } from 'date-fns-tz';

const TIMEZONE_JST = 'Asia/Tokyo';

// Convert user input (assumed JST) sang UTC Ä‘á»ƒ lÆ°u DB
function parseUserDateToUtc(localDateStr: string, userTimezone: string): Date {
  return zonedTimeToUtc(localDateStr, userTimezone);
}

// Convert UTC tá»« DB sang timezone cá»§a user Ä‘á»ƒ hiá»ƒn thá»‹
function formatForUser(utcDate: Date, userTimezone: string): string {
  const zonedDate = utcToZonedTime(utcDate, userTimezone);
  return format(zonedDate, 'yyyy-MM-dd HH:mm:ss', { timeZone: userTimezone });
}

// âœ… GOOD: TÃ­nh start/end of day trong timezone cá»¥ thá»ƒ
function getDayBoundsInUtc(
  localDateStr: string, // 'YYYY-MM-DD'
  userTimezone: string
): { start: Date; end: Date } {
  const startOfDay = zonedTimeToUtc(`${localDateStr}T00:00:00`, userTimezone);
  const endOfDay = zonedTimeToUtc(`${localDateStr}T23:59:59.999`, userTimezone);
  return { start: startOfDay, end: endOfDay };
}

// Usage trong API query
async function getAppointmentsByDate(
  localDate: string,   // '2026-02-18' theo timezone user
  userTimezone: string // 'Asia/Tokyo'
) {
  const { start, end } = getDayBoundsInUtc(localDate, userTimezone);

  return prisma.appointment.findMany({
    where: {
      scheduledAt: {
        gte: start, // UTC start of day in user's timezone
        lte: end    // UTC end of day in user's timezone
      }
    }
  });
}

// âœ… GOOD: Prisma schema - dÃ¹ng @db.Timestamptz (PostgreSQL)
// schema.prisma
// model Appointment {
//   id          Int      @id @default(autoincrement())
//   scheduledAt DateTime @db.Timestamptz(6)  â† LÆ°u timezone info
//   createdAt   DateTime @default(now()) @db.Timestamptz(6)
// }

// âœ… GOOD: Express middleware - set process timezone
// Äáº§u file main.ts / app.ts
process.env.TZ = 'UTC'; // Force server luÃ´n dÃ¹ng UTC
```

### 7. PhÃ²ng ngá»«a

```javascript
// ESLint rule: cáº¥m Date constructor vá»›i string khÃ´ng cÃ³ timezone
module.exports = {
  rules: {
    'no-restricted-syntax': [
      'warn',
      {
        selector: "NewExpression[callee.name='Date'][arguments.length=1]",
        message: 'Use explicit UTC strings (ISO 8601 with Z or offset) when creating Date objects'
      }
    ]
  }
};

// Set TZ=UTC trong package.json scripts
// "scripts": {
//   "start": "TZ=UTC node dist/main.js",
//   "test": "TZ=UTC jest"
// }
```

---

## Pattern 06: Buffer Encoding Mismatch

### 1. TÃªn
**KhÃ´ng Khá»›p Encoding Buffer** (Buffer Encoding Mismatch)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Encoding
- **Subcategory:** Binary Data, Character Encoding, File Processing

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ¡ **MEDIUM** - Data corruption Ã¢m tháº§m khi xá»­ lÃ½ file binary, character bá»‹ máº¥t hoáº·c sai khi xá»­ lÃ½ text Ä‘a ngÃ´n ngá»¯

### 4. Váº¥n Ä‘á»

Node.js Buffer khÃ´ng tá»± biáº¿t encoding cá»§a data. DÃ¹ng sai encoding (utf8 vs latin1 vs base64 vs binary) khi read/write dáº«n Ä‘áº¿n data corruption khÃ´ng cÃ³ lá»—i nÃ o bÃ¡o. Äáº·c biá»‡t nguy hiá»ƒm vá»›i: file binary (PDF, image), dá»¯ liá»‡u mÃ£ hÃ³a (base64 token, hash), text tiáº¿ng Nháº­t/Viá»‡t/Arabic.

```
ENCODING MISMATCH CORRUPTION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vietnamese text: "Xin chÃ o"                                   â”‚
â”‚  UTF-8 bytes: [58 69 6E 20 63 68 C3 A0 6F]                    â”‚
â”‚                                  ^^^^^ 2-byte UTF-8 char       â”‚
â”‚                                                                â”‚
â”‚  Read as latin1:                                               â”‚
â”‚  Buffer.from([...]).toString('latin1')                         â”‚
â”‚  Result: "Xin ch\xC3\xA0o"  â† CORRUPTED! Multi-byte split     â”‚
â”‚                                                                â”‚
â”‚  BASE64 TOKEN CORRUPTION:                                      â”‚
â”‚  Original token: "abc+def/ghi=="                               â”‚
â”‚  URL-transmitted: "abc def/ghi==" (+ became space!)            â”‚
â”‚  Decoded wrong: different bytes â†’ auth fails silently          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `Buffer.from(str)` khÃ´ng chá»‰ Ä‘á»‹nh encoding
- `toString('binary')` hoáº·c `toString('ascii')` vá»›i non-ASCII data
- Base64 token trong URL mÃ  khÃ´ng dÃ¹ng base64url encoding
- `fs.readFile` káº¿t quáº£ Ä‘Æ°á»£c xá»­ lÃ½ nhÆ° string mÃ  khÃ´ng detect encoding

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m Buffer.from khÃ´ng chá»‰ Ä‘á»‹nh encoding
rg --type ts "Buffer\.from\([^,)]+\)" -n

# TÃ¬m toString vá»›i encoding khÃ´ng an toÃ n
rg --type ts "\.toString\('binary'\|'ascii'\|'latin1'\)" -n

# TÃ¬m base64 khÃ´ng pháº£i base64url trong JWT/token context
rg --type ts "base64(?!url)" -n

# TÃ¬m btoa/atob (browser API, khÃ´ng an toÃ n cho binary trong Node)
rg --type ts "\bbtoa\b|\batob\b" -n
```

### 6. Giáº£i phÃ¡p

```typescript
import crypto from 'crypto';
import { Buffer } from 'buffer';

// âŒ BAD: Encoding khÃ´ng rÃµ rÃ ng
function encodeToken_BAD(data: string): string {
  return Buffer.from(data).toString('base64'); // Default utf8 nhÆ°ng khÃ´ng rÃµ rÃ ng
}

function decodeToken_BAD(token: string): string {
  return Buffer.from(token, 'base64').toString(); // CÃ³ thá»ƒ bá»‹ corrupted náº¿u token cÃ³ +, /
}

// âœ… GOOD: Explicit encoding, dÃ¹ng base64url cho URL-safe tokens
function encodeTokenUrlSafe_GOOD(data: string): string {
  return Buffer.from(data, 'utf8')
    .toString('base64url'); // URL-safe: khÃ´ng cÃ³ +, /, = characters
}

function decodeTokenUrlSafe_GOOD(token: string): string {
  return Buffer.from(token, 'base64url').toString('utf8');
}

// âœ… GOOD: Hash vá»›i explicit encoding
function hashPassword_GOOD(password: string): string {
  return crypto
    .createHash('sha256')
    .update(password, 'utf8') // Explicit input encoding
    .digest('hex');            // Explicit output encoding
}

// âŒ BAD: Xá»­ lÃ½ file binary nhÆ° text
import fs from 'fs/promises';
async function processFile_BAD(path: string): Promise<string> {
  return fs.readFile(path, 'utf8'); // Sai náº¿u file lÃ  PDF/image!
}

// âœ… GOOD: Detect vÃ  xá»­ lÃ½ Ä‘Ãºng encoding
async function processFile_GOOD(path: string): Promise<Buffer | string> {
  const buffer = await fs.readFile(path); // Äá»c raw Buffer trÆ°á»›c

  // Detect náº¿u lÃ  text file (BOM check)
  const hasBOM = buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF;
  const isUtf8 = hasBOM || isValidUtf8(buffer);

  if (isUtf8) {
    return buffer.toString('utf8').replace(/^\uFEFF/, ''); // Remove BOM náº¿u cÃ³
  }

  return buffer; // Tráº£ vá» raw Buffer cho binary data
}

function isValidUtf8(buffer: Buffer): boolean {
  try {
    const decoder = new TextDecoder('utf-8', { fatal: true });
    decoder.decode(buffer);
    return true;
  } catch {
    return false;
  }
}

// âœ… GOOD: Stream vá»›i encoding Ä‘Ãºng
import { createReadStream, createWriteStream } from 'fs';
function copyTextFile(src: string, dest: string): Promise<void> {
  return new Promise((resolve, reject) => {
    const reader = createReadStream(src, { encoding: 'utf8' });
    const writer = createWriteStream(dest, { encoding: 'utf8' });
    reader.pipe(writer);
    writer.on('finish', resolve);
    writer.on('error', reject);
  });
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// ESLint: warn khi dÃ¹ng Buffer.from khÃ´ng chá»‰ encoding
module.exports = {
  rules: {
    'no-restricted-syntax': [
      'warn',
      {
        selector: "CallExpression[callee.object.name='Buffer'][callee.property.name='from'][arguments.length=1]",
        message: 'Specify encoding explicitly: Buffer.from(str, "utf8")'
      }
    ]
  }
};
```

---

## Pattern 07: Race Condition Read-Modify-Write

### 1. TÃªn
**Race Condition Äá»c-Sá»­a-Ghi** (Read-Modify-Write Race Condition)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Concurrency
- **Subcategory:** Concurrent Operations, Shared State, Atomic Operations

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Inventory sai, coupon dÃ¹ng nhiá»u hÆ¡n giá»›i háº¡n, Ä‘iá»ƒm thÆ°á»Ÿng bá»‹ máº¥t khi concurrent requests hit cÃ¹ng lÃºc

### 4. Váº¥n Ä‘á»

Pattern: (1) Ä‘á»c giÃ¡ trá»‹, (2) tÃ­nh giÃ¡ trá»‹ má»›i trong app, (3) ghi láº¡i â†’ khÃ´ng pháº£i atomic. Khi 2 requests cháº¡y Ä‘á»“ng thá»i, cáº£ 2 Ä‘á»c cÃ¹ng giÃ¡ trá»‹ cÅ©, cáº£ 2 tÃ­nh toÃ¡n Ä‘á»™c láº­p, cáº£ 2 ghi â†’ má»™t write bá»‹ máº¥t.

```
READ-MODIFY-WRITE RACE CONDITION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Coupon "SAVE10" cÃ³ limit = 1 (chá»‰ dÃ¹ng Ä‘Æ°á»£c 1 láº§n)           â”‚
â”‚                                                                â”‚
â”‚  Request A (User 1)         Request B (User 2)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚  READ: usedCount = 0        READ: usedCount = 0               â”‚
â”‚  CHECK: 0 < 1 â†’ OK          CHECK: 0 < 1 â†’ OK                â”‚
â”‚  WRITE: usedCount = 1       WRITE: usedCount = 1              â”‚
â”‚                                                                â”‚
â”‚  Result: BOTH users applied coupon!                            â”‚
â”‚  usedCount = 1 but 2 uses happened â† DATA INTEGRITY VIOLATED  â”‚
â”‚                                                                â”‚
â”‚  FIX: Atomic increment + DB constraint                         â”‚
â”‚  UPDATE coupons SET usedCount = usedCount + 1                  â”‚
â”‚  WHERE id = X AND usedCount < maxUses                          â”‚
â”‚  â”€â”€ Náº¿u UPDATE 0 rows â†’ coupon Ä‘Ã£ háº¿t â†’ reject                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `find` rá»“i `update` vá»›i giÃ¡ trá»‹ tÃ­nh trong app (khÃ´ng dÃ¹ng `$inc` / `increment`)
- Kiá»ƒm tra Ä‘iá»u kiá»‡n trong app code trÆ°á»›c khi update (check-then-act khÃ´ng atomic)
- Counter / balance update khÃ´ng dÃ¹ng atomic DB operation
- KhÃ´ng cÃ³ `WHERE condition` trong UPDATE Ä‘á»ƒ lÃ m guard

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m pattern: findOne rá»“i update (cáº§n kiá»ƒm tra cÃ³ atomic khÃ´ng)
rg --type ts "findOne|findUnique|findFirst" -A 15 -n | grep -B 5 "\.update\|\.save\("

# TÃ¬m counter update khÃ´ng atomic (nguy hiá»ƒm)
rg --type ts "(count|counter|views|likes|stock)\s*[+-]=" -n
rg --type ts "\.count\s*=\s*.*\.count\s*[+-]" -n

# TÃ¬m update vá»›i calculated value (potential race condition)
rg --type ts "update.*data.*:\s*\{[^}]*(balance|stock|count|amount)" -n

# TÃ¬m Redis increment khÃ´ng dÃ¹ng atomic ops
rg --type ts "redis\.get.*\n.*redis\.set\|client\.get.*\n.*client\.set" --multiline -n
```

### 6. Giáº£i phÃ¡p

```typescript
import { Redis } from 'ioredis';

// âŒ BAD: Read-Modify-Write khÃ´ng atomic
async function applyCoupon_BAD(couponCode: string, userId: number) {
  const coupon = await prisma.coupon.findUnique({
    where: { code: couponCode }
  });

  if (!coupon || coupon.usedCount >= coupon.maxUses) {
    throw new Error('Coupon not available');
  }

  // RACE CONDITION: Hai requests cÃ³ thá»ƒ pass check cÃ¹ng lÃºc!
  await prisma.coupon.update({
    where: { id: coupon.id },
    data: { usedCount: coupon.usedCount + 1 } // Non-atomic!
  });

  return applyDiscountToOrder(userId, coupon.discount);
}

// âœ… GOOD: Atomic UPDATE vá»›i WHERE guard
async function applyCoupon_GOOD(couponCode: string, userId: number) {
  // Single atomic operation: update ONLY IF condition met
  const result = await prisma.$executeRaw`
    UPDATE coupons
    SET used_count = used_count + 1
    WHERE code = ${couponCode}
      AND used_count < max_uses
      AND is_active = true
      AND (expires_at IS NULL OR expires_at > NOW())
  `;

  if (result === 0) {
    // 0 rows updated = coupon exhausted or invalid (no race condition possible)
    throw new Error('Coupon not available or already exhausted');
  }

  const coupon = await prisma.coupon.findUnique({ where: { code: couponCode } });
  return applyDiscountToOrder(userId, coupon!.discount);
}

// âœ… GOOD: Prisma atomic increment
async function incrementViewCount_GOOD(articleId: number) {
  // Prisma's increment is atomic (translates to SET views = views + 1)
  return prisma.article.update({
    where: { id: articleId },
    data: { viewCount: { increment: 1 } } // Atomic!
  });
}

// âœ… GOOD: Redis atomic counter vá»›i Lua script
const redis = new Redis();

async function rateLimitCheck(userId: string, limit: number): Promise<boolean> {
  const key = `rate:${userId}:${Math.floor(Date.now() / 60000)}`; // Per minute

  // INCR lÃ  atomic trong Redis
  const count = await redis.incr(key);
  if (count === 1) {
    await redis.expire(key, 60); // Set TTL on first increment
  }

  return count <= limit;
}

// âœ… GOOD: Lua script cho complex atomic operation trong Redis
async function redeemPoints_GOOD(
  redis: Redis,
  userId: string,
  pointsToRedeem: number
): Promise<boolean> {
  const key = `points:${userId}`;

  // Lua script: check vÃ  deduct atomic (EVALSHA)
  const luaScript = `
    local current = tonumber(redis.call('GET', KEYS[1]) or 0)
    local redeem = tonumber(ARGV[1])
    if current >= redeem then
      redis.call('DECRBY', KEYS[1], redeem)
      return 1
    else
      return 0
    end
  `;

  const result = await redis.eval(luaScript, 1, key, pointsToRedeem.toString());
  return result === 1; // 1 = success, 0 = insufficient points
}

// âœ… GOOD: Database-level unique constraint Ä‘á»ƒ prevent duplicate
// schema.prisma:
// model CouponUsage {
//   id       Int    @id @default(autoincrement())
//   userId   Int
//   couponId Int
//   @@unique([userId, couponId])  â† DB constraint prevents duplicate redemption
// }

async function redeemCouponOnce_GOOD(userId: number, couponId: number) {
  try {
    return await prisma.couponUsage.create({
      data: { userId, couponId }
    });
  } catch (error) {
    // Unique constraint violation = already redeemed
    if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === 'P2002') {
      throw new Error('Coupon already redeemed by this user');
    }
    throw error;
  }
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// Code review checklist:
// 1. Má»i counter/balance update pháº£i dÃ¹ng increment/decrement atomic
// 2. Check-then-act pattern pháº£i trong transaction vá»›i proper isolation
// 3. Unique constraints á»Ÿ DB level cho "one per user" operations

// ESLint: warn khi assignment tá»« property cá»§a object (potential RMW)
module.exports = {
  rules: {
    'no-restricted-syntax': [
      'warn',
      {
        // PhÃ¡t hiá»‡n: obj.count = obj.count + n (thay vÃ¬ atomic DB op)
        selector: "AssignmentExpression[right.type='BinaryExpression'][right.left.type='MemberExpression']",
        message: 'Potential race condition. Use atomic DB operations (increment/decrement) instead.'
      }
    ]
  }
};
```

---

## Pattern 08: Migration Rollback Thiáº¿u

### 1. TÃªn
**Migration Database Thiáº¿u Rollback** (Missing Migration Rollback Strategy)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / DevOps
- **Subcategory:** Database Migration, Schema Management, Deployment

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ¡ **MEDIUM** - Khi deploy lá»—i, khÃ´ng thá»ƒ rollback vá» tráº¡ng thÃ¡i trÆ°á»›c â†’ downtime kÃ©o dÃ i, dá»¯ liá»‡u cÃ³ thá»ƒ bá»‹ máº¥t

### 4. Váº¥n Ä‘á»

Nhiá»u migration chá»‰ cÃ³ "up" (apply) mÃ  khÃ´ng cÃ³ "down" (rollback). Destructive operations (DROP COLUMN, DROP TABLE) lÃ  irreversible. Migration khÃ´ng idempotent, cháº¡y 2 láº§n sáº½ fail. KhÃ´ng test migration trÃªn staging trÆ°á»›c production.

```
MIGRATION WITHOUT ROLLBACK RISK:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deploy v2.0.0:                                                â”‚
â”‚    Migration 001_add_user_profile.up:                          â”‚
â”‚      ALTER TABLE users ADD COLUMN profile_data JSONB;         â”‚
â”‚      â† OK                                                      â”‚
â”‚    Migration 002_drop_old_column.up:                           â”‚
â”‚      ALTER TABLE users DROP COLUMN legacy_field; â† RUNS OK    â”‚
â”‚                                                                â”‚
â”‚  v2.0.0 has critical bug â†’ need rollback to v1.9.0!           â”‚
â”‚                                                                â”‚
â”‚  Migration 002_drop_old_column.DOWN:  â† DOES NOT EXIST!       â”‚
â”‚    Cannot restore "legacy_field" data â†’ STUCK!                 â”‚
â”‚                                                                â”‚
â”‚  Result: Cannot rollback. Must hotfix forward. Downtime!       â”‚
â”‚                                                                â”‚
â”‚  SAFE PATTERN: Expand-Contract (Blue-Green Migration)          â”‚
â”‚  Phase 1: ADD new column (backward compatible)                 â”‚
â”‚  Phase 2: Deploy app using both columns                        â”‚
â”‚  Phase 3: Migrate data                                         â”‚
â”‚  Phase 4: Deploy app using only new column                     â”‚
â”‚  Phase 5: DROP old column (only after confirmed stable)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- Migration files chá»‰ cÃ³ `up` function, khÃ´ng cÃ³ `down`
- `DROP COLUMN` / `DROP TABLE` trong migration mÃ  khÃ´ng cÃ³ data backup step
- Migration khÃ´ng kiá»ƒm tra idempotency (`IF EXISTS` / `IF NOT EXISTS`)
- KhÃ´ng cÃ³ migration test trong CI/CD

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m migration files thiáº¿u down function
rg "exports\.up|module\.exports\.up|async up" migrations/ -l | while read f; do
  rg "exports\.down|module\.exports\.down|async down" "$f" -l 2>/dev/null || echo "MISSING DOWN: $f"
done

# TÃ¬m DROP statements trong migrations (nguy hiá»ƒm)
rg --type ts "DROP TABLE|DROP COLUMN|TRUNCATE" migrations/ -n

# TÃ¬m ALTER TABLE khÃ´ng cÃ³ IF EXISTS (khÃ´ng idempotent)
rg "ALTER TABLE" migrations/ -n | grep -v "IF EXISTS\|IF NOT EXISTS"

# TÃ¬m migration files vá»›i Prisma
rg "migration" prisma/migrations/ -l 2>/dev/null
```

### 6. Giáº£i phÃ¡p

```typescript
// âŒ BAD: Migration chá»‰ cÃ³ up, khÃ´ng cÃ³ down
// migrations/001_add_email_verified.ts
import { Knex } from 'knex';

export async function up(knex: Knex): Promise<void> {
  await knex.schema.table('users', (table) => {
    table.boolean('email_verified').defaultTo(false);
    table.timestamp('email_verified_at').nullable();
  });
}
// â† KhÃ´ng cÃ³ down() function!

// âœ… GOOD: Migration vá»›i down rollback Ä‘áº§y Ä‘á»§
// migrations/001_add_email_verified.ts
export async function up(knex: Knex): Promise<void> {
  // Kiá»ƒm tra idempotency trÆ°á»›c
  const hasColumn = await knex.schema.hasColumn('users', 'email_verified');
  if (!hasColumn) {
    await knex.schema.table('users', (table) => {
      table.boolean('email_verified').defaultTo(false).notNullable();
      table.timestamp('email_verified_at').nullable();
    });
  }
}

export async function down(knex: Knex): Promise<void> {
  const hasColumn = await knex.schema.hasColumn('users', 'email_verified');
  if (hasColumn) {
    await knex.schema.table('users', (table) => {
      table.dropColumn('email_verified');
      table.dropColumn('email_verified_at');
    });
  }
}

// âœ… GOOD: Expand-Contract pattern cho breaking changes
// Phase 1 migration: ADD new column (keep old)
// migrations/002_add_full_name_expand.ts
export async function up(knex: Knex): Promise<void> {
  await knex.schema.table('users', (table) => {
    // ADD new columns, keep old 'name' column
    table.string('first_name', 100).nullable();
    table.string('last_name', 100).nullable();
  });

  // Migrate existing data
  await knex.raw(`
    UPDATE users
    SET first_name = SPLIT_PART(name, ' ', 1),
        last_name  = NULLIF(SPLIT_PART(name, ' ', 2), '')
    WHERE first_name IS NULL
  `);

  // Make not-null after data migration
  await knex.schema.table('users', (table) => {
    table.string('first_name', 100).notNullable().alter();
  });
}

export async function down(knex: Knex): Promise<void> {
  // Safe rollback: just drop new columns, old 'name' column still exists
  await knex.schema.table('users', (table) => {
    table.dropColumn('first_name');
    table.dropColumn('last_name');
  });
}

// Phase 2 migration (SEPARATE deploy, after Phase 1 confirmed stable):
// migrations/003_drop_name_contract.ts
export async function up(knex: Knex): Promise<void> {
  await knex.schema.table('users', (table) => {
    table.dropColumn('name'); // Now safe to drop
  });
}

export async function down(knex: Knex): Promise<void> {
  // Restore old column from new ones
  await knex.schema.table('users', (table) => {
    table.string('name', 255).nullable();
  });
  await knex.raw(`
    UPDATE users SET name = CONCAT(first_name, ' ', COALESCE(last_name, ''))
  `);
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// CI/CD: Test migration up + down + up trong pipeline
// package.json scripts:
// "migration:test": "knex migrate:latest && knex migrate:rollback && knex migrate:latest"

// Custom script Ä‘á»ƒ validate táº¥t cáº£ migrations cÃ³ down():
// scripts/validate-migrations.ts
import fs from 'fs';
import path from 'path';

const migrationsDir = path.join(process.cwd(), 'migrations');
const files = fs.readdirSync(migrationsDir).filter((f) => f.endsWith('.ts'));

let hasError = false;
for (const file of files) {
  const content = fs.readFileSync(path.join(migrationsDir, file), 'utf8');
  if (!content.includes('export async function down')) {
    console.error(`MISSING DOWN: ${file}`);
    hasError = true;
  }
}

if (hasError) process.exit(1);
console.log('All migrations have down() functions.');
```

---

## Pattern 09: Index Thiáº¿u Cho Query Patterns

### 1. TÃªn
**Thiáº¿u Index Cho CÃ¡c Patterns Truy Váº¥n** (Missing Database Indexes for Query Patterns)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Performance
- **Subcategory:** Database Indexing, Query Optimization, Full Table Scan

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ  **HIGH** - Full table scan vá»›i N triá»‡u records lÃ m timeout query, database CPU spike, áº£nh hÆ°á»Ÿng toÃ n bá»™ há»‡ thá»‘ng

### 4. Váº¥n Ä‘á»

Index thiáº¿u khiáº¿n database pháº£i scan toÃ n bá»™ báº£ng (Sequential Scan / Full Table Scan) thay vÃ¬ dÃ¹ng index O(log N). Vá»›i 1 triá»‡u records, full scan cÃ³ thá»ƒ máº¥t vÃ i giÃ¢y, lÃ m timeout requests vÃ  exhaust database connection pool.

```
QUERY PERFORMANCE: WITH vs WITHOUT INDEX
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Table: orders (1,000,000 rows)                                â”‚
â”‚  Query: SELECT * FROM orders WHERE user_id = 12345            â”‚
â”‚                                                                â”‚
â”‚  WITHOUT INDEX (Sequential Scan):                              â”‚
â”‚  DB reads ALL 1,000,000 rows one by one                        â”‚
â”‚  â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”        â”‚
â”‚  â”‚r1â”‚r2â”‚r3â”‚r4â”‚r5â”‚r6â”‚... 999,994 more rows ...    â”‚rNâ”‚        â”‚
â”‚  â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”˜        â”‚
â”‚  Time: ~2,000ms  â† Unacceptable!                               â”‚
â”‚                                                                â”‚
â”‚  WITH INDEX (B-Tree Index on user_id):                         â”‚
â”‚  DB navigates tree: O(log 1,000,000) â‰ˆ 20 comparisons         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚  Index Node â”‚â”€â”€â–¶ 3 matching rows found directly            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚  Time: ~2ms  âœ…  (1000x faster!)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `WHERE` clause trÃªn columns khÃ´ng cÃ³ `@index` / `@@index` trong Prisma schema
- `findMany` vá»›i `where` + `orderBy` nhÆ°ng khÃ´ng cÃ³ composite index
- Foreign key columns khÃ´ng cÃ³ index (Prisma khÃ´ng tá»± táº¡o index cho FK trong táº¥t cáº£ DB)
- Query logs show "Seq Scan" hoáº·c "Full Table Scan"

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m Prisma findMany vá»›i where complex (cáº§n kiá»ƒm tra index)
rg --type ts "findMany\s*\(\s*\{[^}]*where" -n -A 10

# TÃ¬m columns thÆ°á»ng dÃ¹ng trong where nhÆ°ng thiáº¿u @index
rg "findMany.*where.*status\|findMany.*where.*type\|findMany.*where.*userId" --type ts -n

# Kiá»ƒm tra Prisma schema cÃ³ Ä‘á»§ index khÃ´ng
rg "@@index\|@unique\|@@unique" prisma/schema.prisma -n

# TÃ¬m orderBy fields (cáº§n index náº¿u káº¿t há»£p vá»›i where)
rg --type ts "orderBy.*createdAt\|orderBy.*updatedAt\|orderBy.*status" -n

# TÃ¬m LIKE query (cáº§n GIN index vá»›i pg_trgm)
rg --type ts "contains\|startsWith\|mode.*insensitive" -n
```

### 6. Giáº£i phÃ¡p

```prisma
// âŒ BAD: Schema thiáº¿u index cho query patterns thá»±c táº¿
// schema.prisma
model Order {
  id        Int      @id @default(autoincrement())
  userId    Int      // â† ThÆ°á»ng query WHERE userId = ? nhÆ°ng khÃ´ng cÃ³ index!
  status    String   // â† ThÆ°á»ng filter WHERE status = 'pending'
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
  // KhÃ´ng cÃ³ @@index nÃ o!
}

// âœ… GOOD: Index phÃ¹ há»£p vá»›i query patterns
model Order {
  id        Int      @id @default(autoincrement())
  userId    Int
  status    String
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // Index Ä‘Æ¡n cho FK lookup
  @@index([userId])

  // Composite index cho query: WHERE userId = ? AND status = ? ORDER BY createdAt DESC
  @@index([userId, status, createdAt(sort: Desc)])

  // Index cho status filtering (náº¿u query riÃªng)
  @@index([status, createdAt(sort: Desc)])
}

model Product {
  id          Int      @id @default(autoincrement())
  name        String
  categoryId  Int
  price       Decimal
  isActive    Boolean  @default(true)
  createdAt   DateTime @default(now())

  // Full-text search cáº§n GIN index (raw SQL migration)
  // @@index([name]) â† B-tree khÃ´ng tá»‘t cho LIKE %keyword%

  // Composite cho listing page: active products by category, sorted by price
  @@index([categoryId, isActive, price])

  // Partial index tÆ°Æ¡ng Ä‘Æ°Æ¡ng cáº§n raw SQL
}
```

```typescript
// TypeScript: ThÃªm index qua Prisma migration
// Sau khi cáº­p nháº­t schema.prisma, cháº¡y:
// npx prisma migrate dev --name add_order_indexes

// âœ… GOOD: Raw SQL Ä‘á»ƒ thÃªm specialized indexes
// migrations/add_specialized_indexes.ts
import { Knex } from 'knex';

export async function up(knex: Knex): Promise<void> {
  // GIN index cho full-text search (PostgreSQL)
  await knex.raw(`
    CREATE EXTENSION IF NOT EXISTS pg_trgm;
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_products_name_trgm
      ON products USING GIN (name gin_trgm_ops);
  `);

  // Partial index: chá»‰ index active orders (tiáº¿t kiá»‡m space)
  await knex.raw(`
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_pending_created
      ON orders (created_at DESC)
      WHERE status = 'pending';
  `);

  // Covering index: index bao gá»“m táº¥t cáº£ columns cáº§n SELECT (trÃ¡nh table lookup)
  await knex.raw(`
    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_user_covering
      ON orders (user_id, status, created_at DESC)
      INCLUDE (total_amount, currency);
  `);
}

export async function down(knex: Knex): Promise<void> {
  await knex.raw('DROP INDEX IF EXISTS idx_products_name_trgm');
  await knex.raw('DROP INDEX IF EXISTS idx_orders_pending_created');
  await knex.raw('DROP INDEX IF EXISTS idx_orders_user_covering');
}

// âœ… GOOD: Detect slow queries vá»›i EXPLAIN ANALYZE
async function debugSlowQuery(prisma: PrismaClient, userId: number) {
  const explain = await prisma.$queryRaw`
    EXPLAIN ANALYZE
    SELECT * FROM orders
    WHERE user_id = ${userId}
      AND status = 'pending'
    ORDER BY created_at DESC
    LIMIT 20
  `;
  console.log('Query plan:', explain);
  // Look for "Seq Scan" â†’ needs index
  // Look for "Index Scan" â†’ index working
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// Prisma: Enable query logging vÃ  detect slow queries
const prisma = new PrismaClient({
  log: [{ level: 'query', emit: 'event' }]
});

prisma.$on('query', (e) => {
  if (e.duration > 100) { // Query > 100ms
    console.warn(`[SLOW QUERY] ${e.duration}ms: ${e.query}`);
  }
});

// PostgreSQL: Báº­t auto_explain Ä‘á»ƒ log slow queries
// postgresql.conf:
// shared_preload_libraries = 'auto_explain'
// auto_explain.log_min_duration = '100ms'
// auto_explain.log_analyze = true
```

---

## Pattern 10: Soft Delete Inconsistency

### 1. TÃªn
**KhÃ´ng Nháº¥t QuÃ¡n Khi XÃ³a Má»m** (Soft Delete Inconsistency)

### 2. PhÃ¢n loáº¡i
- **Domain:** Data Integrity / Data Management
- **Subcategory:** Soft Delete Pattern, Data Consistency, Query Filters

### 3. Má»©c nghiÃªm trá»ng
ğŸŸ¡ **MEDIUM** - Dá»¯ liá»‡u "Ä‘Ã£ xÃ³a" váº«n xuáº¥t hiá»‡n trong queries, unique constraints bá»‹ vi pháº¡m, business logic sai

### 4. Váº¥n Ä‘á»

Soft delete dÃ¹ng `deletedAt` / `isDeleted` field thay vÃ¬ xÃ³a tháº­t. NhÆ°ng náº¿u khÃ´ng filter nháº¥t quÃ¡n trong má»i query, "deleted" records váº«n xuáº¥t hiá»‡n. Unique indexes khÃ´ng hoáº¡t Ä‘á»™ng Ä‘Ãºng cho soft-deleted records. Relations láº¥y vá» cáº£ deleted records.

```
SOFT DELETE INCONSISTENCY SCENARIOS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCENARIO 1: Leaked soft-deleted data                          â”‚
â”‚  users table: [Alice(active), Bob(deleted), Carol(active)]     â”‚
â”‚                                                                â”‚
â”‚  Query: prisma.user.findMany()  â† No filter!                   â”‚
â”‚  Result: [Alice, Bob, Carol]  â† Bob should NOT appear!         â”‚
â”‚                                                                â”‚
â”‚  SCENARIO 2: Unique constraint bypass                          â”‚
â”‚  User "alice@mail.com" soft-deleted (deletedAt = now())       â”‚
â”‚  New user registers with "alice@mail.com"                      â”‚
â”‚  Error: UNIQUE CONSTRAINT VIOLATION!                           â”‚
â”‚  â† Old soft-deleted record blocks new registration            â”‚
â”‚                                                                â”‚
â”‚  SCENARIO 3: Foreign key returns deleted records              â”‚
â”‚  Order.include({ user: true })                                 â”‚
â”‚  â† Returns order even if associated user is soft-deleted       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. PhÃ¡t hiá»‡n trong mÃ£ nguá»“n

**Dáº¥u hiá»‡u nháº­n biáº¿t:**
- `findMany()` khÃ´ng cÃ³ `where: { deletedAt: null }` filter
- Unique index trÃªn email/username khÃ´ng handle soft-deleted records
- `include` relations khÃ´ng filter deleted
- Prisma middleware cho soft delete khÃ´ng Ä‘Æ°á»£c Ã¡p dá»¥ng cho táº¥t cáº£ models

**Ripgrep regex Ä‘á»ƒ tÃ¬m:**
```bash
# TÃ¬m findMany khÃ´ng cÃ³ deletedAt filter (trong project dÃ¹ng soft delete)
rg --type ts "\.findMany\(\s*\)" -n
rg --type ts "\.findMany\(\s*\{[^}]*\}\s*\)" -n | grep -v "deletedAt\|isDeleted"

# TÃ¬m findUnique/findFirst khÃ´ng filter deletedAt
rg --type ts "\.findFirst\(\s*\{[^}]*where[^}]*\}" -n | grep -v "deletedAt"

# TÃ¬m delete operations (nÃªn lÃ  soft delete nhÆ°ng cÃ³ thá»ƒ lÃ  hard delete)
rg --type ts "\.delete\(\|\.deleteMany\(" -n

# Kiá»ƒm tra Prisma schema cÃ³ deletedAt khÃ´ng
rg "deletedAt\|isDeleted\|deleted_at" prisma/schema.prisma -n
```

### 6. Giáº£i phÃ¡p

```typescript
import { PrismaClient, Prisma } from '@prisma/client';

// âŒ BAD: Soft delete khÃ´ng nháº¥t quÃ¡n
const prisma = new PrismaClient();

// Delete tháº­t thay vÃ¬ soft delete
async function deleteUser_BAD(id: number) {
  return prisma.user.delete({ where: { id } }); // Hard delete!
}

// Query khÃ´ng filter deleted records
async function getActiveUsers_BAD() {
  return prisma.user.findMany(); // Tráº£ vá» cáº£ deleted users!
}

// âœ… GOOD: Prisma middleware cho soft delete toÃ n cá»¥c
// prisma/client.ts
const prisma = new PrismaClient();

// Middleware tá»± Ä‘á»™ng:
// 1. Chuyá»ƒn delete â†’ update vá»›i deletedAt
// 2. ThÃªm filter deletedAt = null vÃ o má»i findMany/findFirst
prisma.$use(async (params, next) => {
  const SOFT_DELETE_MODELS = ['User', 'Post', 'Comment'];

  if (!SOFT_DELETE_MODELS.includes(params.model ?? '')) {
    return next(params);
  }

  // Chuyá»ƒn delete â†’ soft delete
  if (params.action === 'delete') {
    params.action = 'update';
    params.args.data = { deletedAt: new Date() };
  }

  if (params.action === 'deleteMany') {
    params.action = 'updateMany';
    params.args.data = { deletedAt: new Date() };
  }

  // Auto-filter: exclude soft-deleted records
  const readActions = ['findUnique', 'findFirst', 'findMany', 'count', 'aggregate'];
  if (readActions.includes(params.action)) {
    if (!params.args) params.args = {};
    if (!params.args.where) params.args.where = {};

    // Chá»‰ filter náº¿u chÆ°a cÃ³ deletedAt condition
    if (params.args.where.deletedAt === undefined) {
      params.args.where.deletedAt = null;
    }
  }

  return next(params);
});

// âœ… GOOD: Utility Ä‘á»ƒ bypass filter (admin use case)
async function getAllUsersIncludingDeleted() {
  // DÃ¹ng $queryRaw Ä‘á»ƒ bypass middleware
  return prisma.$queryRaw<User[]>`
    SELECT * FROM users ORDER BY created_at DESC
  `;
}

// âœ… GOOD: Unique constraint cho soft delete (PostgreSQL partial index)
// migration: add partial unique index
// CREATE UNIQUE INDEX users_email_active_unique
//   ON users (email)
//   WHERE deleted_at IS NULL;
// â† Chá»‰ enforce unique cho non-deleted records!

// migrations/add_soft_delete_unique_indexes.ts
import { Knex } from 'knex';

export async function up(knex: Knex): Promise<void> {
  // XÃ³a unique index cÅ© (náº¿u cÃ³)
  await knex.raw('DROP INDEX IF EXISTS users_email_unique');

  // Partial unique index: unique chá»‰ vá»›i active records
  await knex.raw(`
    CREATE UNIQUE INDEX IF NOT EXISTS users_email_active_unique
      ON users (email)
      WHERE deleted_at IS NULL
  `);
}

export async function down(knex: Knex): Promise<void> {
  await knex.raw('DROP INDEX IF EXISTS users_email_active_unique');
  await knex.schema.table('users', (t) => {
    t.unique(['email']); // Restore original unique
  });
}

// âœ… GOOD: Soft delete vá»›i cascade (cáº­p nháº­t related records)
async function softDeleteUser(userId: number) {
  return prisma.$transaction(async (tx) => {
    const now = new Date();

    // Soft delete user
    await tx.user.update({
      where: { id: userId },
      data: { deletedAt: now }
    });

    // Cascade soft delete related data
    await tx.userSession.updateMany({
      where: { userId, deletedAt: null },
      data: { deletedAt: now }
    });

    await tx.post.updateMany({
      where: { authorId: userId, deletedAt: null },
      data: { deletedAt: now }
    });
  });
}
```

### 7. PhÃ²ng ngá»«a

```javascript
// ESLint: cáº£nh bÃ¡o khi gá»i .delete() trá»±c tiáº¿p trong project dÃ¹ng soft delete
module.exports = {
  rules: {
    'no-restricted-syntax': [
      'warn',
      {
        // PhÃ¡t hiá»‡n prisma.model.delete() call
        selector:
          "CallExpression[callee.type='MemberExpression'][callee.property.name='delete']",
        message:
          'Use soft delete (update with deletedAt) instead of hard delete. If intentional, add // eslint-disable-next-line comment.'
      }
    ]
  }
};

// Test Ä‘á»ƒ Ä‘áº£m báº£o middleware hoáº¡t Ä‘á»™ng
// __tests__/soft-delete.test.ts
describe('Soft Delete Middleware', () => {
  it('should filter deleted records from findMany', async () => {
    await prisma.user.update({
      where: { id: testUserId },
      data: { deletedAt: new Date() }
    });

    const users = await prisma.user.findMany({
      where: { id: testUserId }
    });

    expect(users).toHaveLength(0); // Pháº£i khÃ´ng tháº¥y user Ä‘Ã£ xÃ³a
  });
});
```

---

## TÃ³m Táº¯t Domain 04

| # | Pattern | Má»©c Ä‘á»™ | Impact chÃ­nh |
|---|---------|--------|--------------|
| 01 | ORM N+1 Query | ğŸŸ  HIGH | Database quÃ¡ táº£i, timeout |
| 02 | Transaction Isolation Sai | ğŸ”´ CRITICAL | Lost update, overselling |
| 03 | MongoDB Schema Design Sai | ğŸŸ  HIGH | Document size limit, inconsistency |
| 04 | JSON BigInt Loss | ğŸŸ  HIGH | ID sai Ã¢m tháº§m, 404 errors |
| 05 | Date Timezone Pitfalls | ğŸŸ  HIGH | Appointment sai giá», report sai ngÃ y |
| 06 | Buffer Encoding Mismatch | ğŸŸ¡ MEDIUM | Data corruption, token sai |
| 07 | Race Condition Read-Modify-Write | ğŸŸ  HIGH | Oversell, double-redeem |
| 08 | Migration Rollback Thiáº¿u | ğŸŸ¡ MEDIUM | KhÃ´ng rollback Ä‘Æ°á»£c khi lá»—i |
| 09 | Index Thiáº¿u Cho Query Patterns | ğŸŸ  HIGH | Full table scan, timeout |
| 10 | Soft Delete Inconsistency | ğŸŸ¡ MEDIUM | Dá»¯ liá»‡u "xÃ³a" váº«n xuáº¥t hiá»‡n |

### Thá»‘ng kÃª theo má»©c nghiÃªm trá»ng
- ğŸ”´ **CRITICAL**: 1 pattern (Transaction Isolation)
- ğŸŸ  **HIGH**: 6 patterns
- ğŸŸ¡ **MEDIUM**: 3 patterns

### Checklist PhÃ²ng Ngá»«a Nhanh
```
Database Layer:
  [ ] Má»i FK column cÃ³ @index
  [ ] Composite index cho query patterns thá»±c táº¿
  [ ] Partial unique index cho soft-deleted records
  [ ] PostgreSQL: dÃ¹ng TIMESTAMPTZ, BIGINT Ä‘Ãºng chá»—

ORM Layer:
  [ ] Prisma: include/TypeORM: relations thay vÃ¬ N+1
  [ ] Transaction wrap cho multi-step operations
  [ ] Middleware soft delete Ã¡p dá»¥ng toÃ n cá»¥c
  [ ] Migration cÃ³ down() function

Application Layer:
  [ ] BigInt serialize sang String trong API response
  [ ] Date luÃ´n UTC, parse vá»›i timezone explicit
  [ ] Buffer.from() luÃ´n chá»‰ Ä‘á»‹nh encoding
  [ ] Atomic operations cho counter/balance updates

Process:
  [ ] Test migration up/down/up trong CI
  [ ] EXPLAIN ANALYZE cho queries má»›i
  [ ] Query logging trong development
```
