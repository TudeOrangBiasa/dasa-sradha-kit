# Domain 05: Quáº£n LÃ½ TÃ i NguyÃªn (Resource Management)

> Node.js patterns liÃªn quan Ä‘áº¿n quáº£n lÃ½ tÃ i nguyÃªn: memory, connections, file descriptors, processes.

| Thuá»™c tÃ­nh | GiÃ¡ trá»‹ |
|-----------|---------|
| **LÄ©nh vá»±c** | Quáº£n LÃ½ TÃ i NguyÃªn |
| **Sá»‘ máº«u** | 12 |
| **NgÃ´n ngá»¯** | TypeScript / Node.js |
| **NgÃ y cáº­p nháº­t** | 2026-02-18 |

---

## Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    V8 MEMORY MODEL                          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  New Space    â”‚  â”‚  Old Space    â”‚  â”‚  Large Object    â”‚  â”‚
â”‚  â”‚  (Young Gen)  â”‚  â”‚  (Old Gen)    â”‚  â”‚  Space           â”‚  â”‚
â”‚  â”‚  ~4MB         â”‚  â”‚  ~1.5GB       â”‚  â”‚  >kMaxRegular    â”‚  â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  HeapObjectSize  â”‚  â”‚
â”‚  â”‚  Scavenge GC  â”‚  â”‚  Mark-Sweep   â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚  (frequent)   â”‚  â”‚  Mark-Compact â”‚  â”‚  Never moved     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Code Space   â”‚  â”‚  Map Space    â”‚  â”‚  External Memory â”‚  â”‚
â”‚  â”‚  (JIT code)   â”‚  â”‚  (hidden      â”‚  â”‚  (Buffer, WASM)  â”‚  â”‚
â”‚  â”‚              â”‚  â”‚   classes)    â”‚  â”‚  KhÃ´ng tÃ­nh vÃ o  â”‚  â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  heap limit      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

12 Failure Patterns:
  RM-01  Memory Leak Qua Closure .............. CRITICAL
  RM-02  Connection Pool Exhaustion ........... CRITICAL
  RM-03  File Descriptor Leak ................. HIGH
  RM-04  Global Variable Memory ............... HIGH
  RM-05  Express Middleware Leak .............. MEDIUM
  RM-06  Child Process Zombie ................. HIGH
  RM-07  HTTP Agent Connection ................ MEDIUM
  RM-08  DNS Cache Thiáº¿u ...................... MEDIUM
  RM-09  Large File Memory .................... HIGH
  RM-10  Timeout Thiáº¿u Cho HTTP ............... HIGH
  RM-11  Redis Client Reconnect ............... MEDIUM
  RM-12  Buffer Pool Overflow ................. HIGH
```

---

## Pattern 01: Memory Leak Qua Closure

### TÃªn
Memory Leak Qua Closure (Closure-Based Memory Leak)

### PhÃ¢n loáº¡i
Resource Management / Memory / V8 Heap

### Má»©c nghiÃªm trá»ng
CRITICAL ğŸ”´

> Closure giá»¯ reference tá»›i large object ngay cáº£ khi chá»‰ dÃ¹ng 1 field nhá». V8 GC khÃ´ng thá»ƒ thu há»“i vÃ¬ closure váº«n reachable. Heap grow liÃªn tá»¥c â†’ OOM crash trong production.

### Váº¥n Ä‘á»

```
Luá»“ng thá»±c thi:

  Request Handler
       â”‚
       â–¼
  const bigData = fetchLargePayload()  â† 50MB object
       â”‚
       â–¼
  const callback = () => {
    console.log(bigData.status)  â† Chá»‰ dÃ¹ng 1 field
  }                                â† NhÆ°ng closure capture TOÃ€N Bá»˜ bigData
       â”‚
       â–¼
  eventEmitter.on('check', callback)  â† Listener giá»¯ closure
       â”‚                                â† bigData KHÃ”NG BAO GIá»œ Ä‘Æ°á»£c GC
       â–¼
  1000 requests = 50GB leaked!

  V8 Heap:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Request 1: [bigData 50MB] â† closure   â”‚
  â”‚ Request 2: [bigData 50MB] â† closure   â”‚
  â”‚ Request 3: [bigData 50MB] â† closure   â”‚
  â”‚ ...                                    â”‚
  â”‚ Request N: heap > --max-old-space-size â”‚
  â”‚            â†’ FATAL ERROR: OOM          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Closure trong JavaScript capture toÃ n bá»™ scope chain, khÃ´ng pháº£i chá»‰ biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng. Khi closure Ä‘Æ°á»£c gÃ¡n lÃ m event listener, timer callback, hoáº·c lÆ°u trong cache, táº¥t cáº£ objects trong scope Ä‘á»u bá»‹ giá»¯ láº¡i.

### PhÃ¡t hiá»‡n

Dáº¥u hiá»‡u nháº­n biáº¿t:
- RSS (Resident Set Size) tÄƒng liÃªn tá»¥c theo thá»i gian
- V8 heap snapshot cho tháº¥y "retainers" lÃ  closures
- `process.memoryUsage().heapUsed` tÄƒng dáº§n sau má»—i request

```bash
# TÃ¬m event listener Ä‘Äƒng kÃ½ trong request handler
rg --type js --type ts "\.on\(|\.addEventListener\(" -B 5 | head -40

# TÃ¬m closure capture large object
rg --type js --type ts "const \w+ = \(\) =>" -B 10 | head -40

# TÃ¬m setInterval/setTimeout khÃ´ng clear
rg --type js --type ts "setInterval|setTimeout" --no-filename | head -20

# TÃ¬m module-level cache khÃ´ng cÃ³ eviction
rg --type js --type ts "^const \w+(Map|Cache|Store) = new Map" | head -20
```

### Giáº£i phÃ¡p

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|---------|-----------|
| Closure capture toÃ n bá»™ scope | Extract field trÆ°á»›c khi táº¡o closure |
| Event listener khÃ´ng remove | WeakRef hoáº·c cleanup on disconnect |
| Timer khÃ´ng clear | AbortSignal hoáº·c cleanup pattern |

**BAD â€” Closure capture toÃ n bá»™ large object:**
```typescript
// BAD: closure giá»¯ reference tá»›i toÃ n bá»™ `response` (50MB)
app.get('/api/reports', async (req, res) => {
  const response = await fetchHugeReport(); // 50MB data

  const checkStatus = () => {
    // Chá»‰ dÃ¹ng response.status nhÆ°ng capture TOÃ€N Bá»˜ response
    return response.status === 'ready';
  };

  statusChecker.on('poll', checkStatus);
  // response 50MB KHÃ”NG BAO GIá»œ Ä‘Æ°á»£c GC vÃ¬ checkStatus giá»¯ reference

  res.json({ id: response.id });
});
```

**GOOD â€” Extract field, giáº£i phÃ³ng reference:**
```typescript
// GOOD: Extract field cáº§n thiáº¿t, khÃ´ng capture large object
app.get('/api/reports', async (req, res) => {
  const response = await fetchHugeReport(); // 50MB data

  // Extract CHá»ˆ field cáº§n thiáº¿t
  const { status, id } = response;
  // response giá» cÃ³ thá»ƒ Ä‘Æ°á»£c GC vÃ¬ khÃ´ng cÃ²n reference

  const checkStatus = () => {
    return status === 'ready'; // Chá»‰ capture primitive string
  };

  // ThÃªm cleanup mechanism
  const cleanup = () => {
    statusChecker.off('poll', checkStatus);
  };

  statusChecker.on('poll', checkStatus);

  // Auto-cleanup sau 5 phÃºt
  const timer = setTimeout(cleanup, 5 * 60 * 1000);
  req.on('close', () => {
    cleanup();
    clearTimeout(timer);
  });

  res.json({ id });
});
```

**GOOD â€” WeakRef pattern cho long-lived listeners:**
```typescript
class SafeEventManager {
  private listeners = new Map<string, Set<WeakRef<Function>>>();
  private registry = new FinalizationRegistry<{ event: string; ref: WeakRef<Function> }>(
    ({ event, ref }) => {
      this.listeners.get(event)?.delete(ref);
    }
  );

  on(event: string, callback: Function): void {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, new Set());
    }
    const ref = new WeakRef(callback);
    this.listeners.get(event)!.add(ref);
    this.registry.register(callback, { event, ref });
  }

  emit(event: string, ...args: unknown[]): void {
    const refs = this.listeners.get(event);
    if (!refs) return;

    for (const ref of refs) {
      const fn = ref.deref();
      if (fn) {
        fn(...args);
      } else {
        refs.delete(ref); // Cleanup dead references
      }
    }
  }
}
```

### PhÃ²ng ngá»«a

- [ ] KhÃ´ng capture large object trong closure â€” extract fields trÆ°á»›c
- [ ] Má»i `emitter.on()` pháº£i cÃ³ `emitter.off()` tÆ°Æ¡ng á»©ng
- [ ] Sá»­ dá»¥ng `AbortSignal` Ä‘á»ƒ tá»± Ä‘á»™ng cleanup timers vÃ  listeners
- [ ] Monitor heap growth: `node --inspect` + Chrome DevTools Memory tab
- [ ] Cháº¡y clinic.js doctor Ä‘á»ƒ phÃ¡t hiá»‡n memory leak: `clinic doctor -- node app.js`
- [ ] Set `--max-old-space-size` há»£p lÃ½ vÃ  monitor vá»›i `process.memoryUsage()`

```bash
# Cháº¡y vá»›i heap profiling
node --heap-prof --heap-prof-interval=512 app.js

# clinic.js heap profiling
npx clinic heapprofiler -- node app.js
```

---

## Pattern 02: Connection Pool Exhaustion

### TÃªn
Connection Pool Exhaustion (Cáº¡n Kiá»‡t Connection Pool)

### PhÃ¢n loáº¡i
Resource Management / Database / Connection Pool

### Má»©c nghiÃªm trá»ng
CRITICAL ğŸ”´

> Connections khÃ´ng Ä‘Æ°á»£c release vá» pool sau khi dÃ¹ng. Pool Ä‘áº§y â†’ requests má»›i bá»‹ block â†’ timeout cascade â†’ toÃ n bá»™ service down.

### Váº¥n Ä‘á»

```
Pool Size = 10

  Request 1 â”€â”€â–º acquire() â”€â”€â–º connection 1  â”€â”€â–º query OK
                                                    â”‚
                                              ERROR thrown!
                                                    â”‚
                                              connection 1 KHÃ”NG release
                                              (vÃ¬ error skip qua release code)

  ... láº·p láº¡i 9 láº§n ná»¯a ...

  Request 11 â”€â”€â–º acquire() â”€â”€â–º TIMEOUT (30s)
  Request 12 â”€â”€â–º acquire() â”€â”€â–º TIMEOUT (30s)
  Request 13 â”€â”€â–º acquire() â”€â”€â–º TIMEOUT (30s)

  Pool Status:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ [1] LEAKED  [2] LEAKED          â”‚
  â”‚ [3] LEAKED  [4] LEAKED          â”‚
  â”‚ [5] LEAKED  [6] LEAKED          â”‚
  â”‚ [7] LEAKED  [8] LEAKED          â”‚
  â”‚ [9] LEAKED  [10] LEAKED         â”‚
  â”‚                                  â”‚
  â”‚ Available: 0 / 10               â”‚
  â”‚ Waiting:   247 requests          â”‚
  â”‚ Status:    ğŸ’€ DEADLOCKED        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m pool acquire khÃ´ng cÃ³ release/destroy
rg --type js --type ts "pool\.(acquire|connect|getConnection)\(\)" -A 10 | head -40

# TÃ¬m knex/prisma transaction khÃ´ng commit/rollback
rg --type js --type ts "\.transaction\(" -A 15 | head -40

# TÃ¬m raw query khÃ´ng dÃ¹ng pool correctly
rg --type js --type ts "new (Pool|Client)\(" | head -20

# TÃ¬m connection thiáº¿u error handling
rg --type js --type ts "await.*query\(" -B 3 | grep -v "try\|catch\|finally" | head -20
```

### Giáº£i phÃ¡p

**BAD â€” Connection khÃ´ng release khi error:**
```typescript
// BAD: Náº¿u query throw error, connection KHÃ”NG Ä‘Æ°á»£c release
async function getUser(id: string) {
  const client = await pool.connect();
  const result = await client.query('SELECT * FROM users WHERE id = $1', [id]);
  client.release(); // KHÃ”NG BAO GIá»œ cháº¡y náº¿u query throw!
  return result.rows[0];
}
```

**GOOD â€” LuÃ´n release trong finally:**
```typescript
// GOOD: finally Ä‘áº£m báº£o connection LUÃ”N Ä‘Æ°á»£c release
async function getUser(id: string) {
  const client = await pool.connect();
  try {
    const result = await client.query('SELECT * FROM users WHERE id = $1', [id]);
    return result.rows[0];
  } catch (error) {
    // Destroy connection náº¿u cÃ³ lá»—i nghiÃªm trá»ng (connection corrupted)
    if (isConnectionError(error)) {
      client.release(true); // true = destroy, khÃ´ng return vá» pool
      throw error;
    }
    throw error;
  } finally {
    client.release(); // LUÃ”N release
  }
}
```

**GOOD â€” Pool wrapper vá»›i auto-release:**
```typescript
// GOOD: Helper Ä‘áº£m báº£o connection luÃ´n Ä‘Æ°á»£c release
async function withConnection<T>(
  pool: Pool,
  fn: (client: PoolClient) => Promise<T>
): Promise<T> {
  const client = await pool.connect();
  try {
    return await fn(client);
  } finally {
    client.release();
  }
}

// Sá»­ dá»¥ng
const user = await withConnection(pool, async (client) => {
  const result = await client.query('SELECT * FROM users WHERE id = $1', [id]);
  return result.rows[0];
});
```

**GOOD â€” Pool monitoring:**
```typescript
import { Pool } from 'pg';

const pool = new Pool({
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 5000,
});

// Monitor pool health
setInterval(() => {
  console.log({
    total: pool.totalCount,
    idle: pool.idleCount,
    waiting: pool.waitingCount,
  });

  // Alert náº¿u pool gáº§n Ä‘áº§y
  if (pool.waitingCount > 10) {
    logger.warn('Pool exhaustion warning', {
      waiting: pool.waitingCount,
      total: pool.totalCount,
    });
  }
}, 10000);

// Graceful shutdown
process.on('SIGTERM', async () => {
  await pool.end();
  process.exit(0);
});
```

### PhÃ²ng ngá»«a

- [ ] Má»i `pool.connect()` PHáº¢I cÃ³ `finally { client.release() }`
- [ ] Sá»­ dá»¥ng helper wrapper `withConnection()` Ä‘á»ƒ tá»± Ä‘á»™ng release
- [ ] Set `connectionTimeoutMillis` há»£p lÃ½ (5-10s, khÃ´ng Ä‘á»ƒ máº·c Ä‘á»‹nh)
- [ ] Monitor pool metrics: `totalCount`, `idleCount`, `waitingCount`
- [ ] Set `max` pool size phÃ¹ há»£p (thÆ°á»ng 10-20 cho Node.js single-thread)
- [ ] Graceful shutdown: `pool.end()` trÆ°á»›c khi process exit

---

## Pattern 03: File Descriptor Leak

### TÃªn
File Descriptor Leak (RÃ² Rá»‰ File Descriptor)

### PhÃ¢n loáº¡i
Resource Management / OS / File Descriptors

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> Stream hoáº·c socket má»Ÿ mÃ  khÃ´ng close. OS cÃ³ giá»›i háº¡n file descriptors (thÆ°á»ng 1024 máº·c Ä‘á»‹nh). Khi háº¿t â†’ `EMFILE: too many open files`.

### Váº¥n Ä‘á»

```
Má»—i láº§n má»Ÿ file/socket/pipe:
  fd count: 1 â†’ 2 â†’ 3 â†’ ... â†’ 1024
                                  â”‚
                                  â–¼
                         EMFILE error!
                         KhÃ´ng má»Ÿ Ä‘Æ°á»£c file nÃ o ná»¯a
                         HTTP server KHÃ”NG accept Ä‘Æ°á»£c connection má»›i

  ulimit -n = 1024 (default)

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ fd 0: stdin                         â”‚
  â”‚ fd 1: stdout                        â”‚
  â”‚ fd 2: stderr                        â”‚
  â”‚ fd 3: server socket                 â”‚
  â”‚ fd 4: leaked read stream            â”‚
  â”‚ fd 5: leaked read stream            â”‚
  â”‚ ...                                 â”‚
  â”‚ fd 1023: leaked read stream         â”‚
  â”‚ fd 1024: EMFILE! âŒ                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m createReadStream/createWriteStream khÃ´ng close
rg --type js --type ts "createReadStream|createWriteStream" -A 10 | head -40

# TÃ¬m fs.open khÃ´ng cÃ³ fs.close
rg --type js --type ts "fs\.open\(|fs\.promises\.open\(" -A 10 | head -30

# TÃ¬m net.createServer/net.connect khÃ´ng handle close
rg --type js --type ts "net\.create|new net\.Socket" -A 10 | head -30

# Kiá»ƒm tra fd count cá»§a process Ä‘ang cháº¡y
# lsof -p $(pgrep -f "node app") | wc -l
```

### Giáº£i phÃ¡p

**BAD â€” Stream khÃ´ng close khi error:**
```typescript
// BAD: Náº¿u pipeline fail, readStream cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c close
app.get('/download/:file', (req, res) => {
  const stream = fs.createReadStream(`/uploads/${req.params.file}`);
  stream.pipe(res);
  // Náº¿u client disconnect giá»¯a chá»«ng â†’ stream váº«n má»Ÿ!
});
```

**GOOD â€” Proper stream cleanup:**
```typescript
import { pipeline } from 'node:stream/promises';

// GOOD: pipeline tá»± Ä‘á»™ng cleanup táº¥t cáº£ streams khi error hoáº·c complete
app.get('/download/:file', async (req, res) => {
  const filePath = path.join(UPLOAD_DIR, path.basename(req.params.file));

  // Validate path
  if (!filePath.startsWith(UPLOAD_DIR)) {
    return res.status(403).send('Forbidden');
  }

  const stream = fs.createReadStream(filePath);

  try {
    await pipeline(stream, res);
  } catch (error) {
    // pipeline Ä‘Ã£ cleanup stream, chá»‰ cáº§n log
    if ((error as NodeJS.ErrnoException).code !== 'ERR_STREAM_PREMATURE_CLOSE') {
      logger.error('Download failed', { error, file: req.params.file });
    }
  }
});
```

**GOOD â€” File handle vá»›i using (Node.js 22+):**
```typescript
// GOOD: Symbol.asyncDispose tá»± Ä‘á»™ng close file handle
async function processFile(filePath: string): Promise<string[]> {
  await using handle = await fs.promises.open(filePath, 'r');
  const content = await handle.readFile('utf-8');
  return content.split('\n');
  // handle tá»± Ä‘á»™ng close á»Ÿ Ä‘Ã¢y, ká»ƒ cáº£ khi throw error
}
```

### PhÃ²ng ngá»«a

- [ ] Sá»­ dá»¥ng `pipeline()` thay vÃ¬ `.pipe()` â€” tá»± Ä‘á»™ng cleanup
- [ ] Sá»­ dá»¥ng `await using` (Node.js 22+) cho file handles
- [ ] Má»i `createReadStream` pháº£i handle event `error` vÃ  `close`
- [ ] Set ulimit cao hÆ¡n cho production: `ulimit -n 65536`
- [ ] Monitor fd count: `process.getActiveResourcesInfo()`

```bash
# ESLint rule: no-floating-promises (stream operations)
# clinic.js: npx clinic bubbleprof -- node app.js
```

---

## Pattern 04: Global Variable Memory

### TÃªn
Global Variable Memory Growth (Module-Level Cache TÄƒng VÃ´ Háº¡n)

### PhÃ¢n loáº¡i
Resource Management / Memory / Cache

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> Module-level Map/Object dÃ¹ng lÃ m cache nhÆ°ng khÃ´ng cÃ³ eviction policy. Cache grow vÃ´ háº¡n â†’ heap exhaustion.

### Váº¥n Ä‘á»

```
Module loaded (singleton):
  const cache = new Map()

  Request 1: cache.set(key1, data1)    size: 1
  Request 2: cache.set(key2, data2)    size: 2
  ...
  Request 1M: cache.set(keyN, dataN)   size: 1,000,000
                                            â”‚
                                            â–¼
                                       OOM CRASH!

  Heap Usage Over Time:

  Memory â”‚         â•±
         â”‚        â•±
         â”‚       â•±
         â”‚      â•±
         â”‚     â•±
         â”‚    â•±  â† Linear growth = LEAK
         â”‚   â•±
         â”‚  â•±
         â”‚ â•±
         â”‚â•±
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m module-level Map/Set/Object cache
rg --type js --type ts "^(export )?(const|let|var) \w+ = new (Map|Set|WeakMap)\(" | head -20

# TÃ¬m module-level object literal cache
rg --type js --type ts "^(export )?(const|let|var) \w+(Cache|Store|Registry|Map) = \{" | head -20

# TÃ¬m cache.set khÃ´ng cÃ³ cache.delete / clear / eviction
rg --type js --type ts "\.set\(" --no-filename | head -30
```

### Giáº£i phÃ¡p

**BAD â€” Unbounded cache:**
```typescript
// BAD: Cache grow vÃ´ háº¡n, khÃ´ng cÃ³ eviction
const userCache = new Map<string, User>();

export async function getUser(id: string): Promise<User> {
  if (userCache.has(id)) {
    return userCache.get(id)!;
  }
  const user = await db.users.findById(id);
  userCache.set(id, user); // Chá»‰ thÃªm, KHÃ”NG BAO GIá»œ xÃ³a!
  return user;
}
```

**GOOD â€” LRU cache vá»›i giá»›i háº¡n:**
```typescript
import { LRUCache } from 'lru-cache';

const userCache = new LRUCache<string, User>({
  max: 1000,               // Tá»‘i Ä‘a 1000 entries
  ttl: 5 * 60 * 1000,      // TTL 5 phÃºt
  maxSize: 50 * 1024 * 1024, // Max 50MB tá»•ng
  sizeCalculation: (value) => JSON.stringify(value).length,
  dispose: (value, key, reason) => {
    logger.debug('Cache evicted', { key, reason });
  },
});

export async function getUser(id: string): Promise<User> {
  const cached = userCache.get(id);
  if (cached) return cached;

  const user = await db.users.findById(id);
  userCache.set(id, user);
  return user;
}

// Monitor cache health
setInterval(() => {
  logger.info('Cache stats', {
    size: userCache.size,
    calculatedSize: userCache.calculatedSize,
  });
}, 60000);
```

### PhÃ²ng ngá»«a

- [ ] KHÃ”NG dÃ¹ng bare `Map`/`Set` lÃ m cache â€” luÃ´n dÃ¹ng `lru-cache`
- [ ] Set `max` entries vÃ  `ttl` cho má»i cache
- [ ] Monitor cache size qua metrics
- [ ] Sá»­ dá»¥ng external cache (Redis) cho data lá»›n
- [ ] WeakMap chá»‰ dÃ¹ng khi key lÃ  object vÃ  lifecycle gáº¯n vá»›i key

---

## Pattern 05: Express Middleware Leak

### TÃªn
Express Middleware Memory Leak (Middleware Gáº¯n Data VÃ o Request)

### PhÃ¢n loáº¡i
Resource Management / Memory / Framework

### Má»©c nghiÃªm trá»ng
MEDIUM ğŸŸ¡

> Middleware thÃªm large data vÃ o `req` object. Náº¿u response cháº­m hoáº·c long-polling, data tá»“n táº¡i suá»‘t lifetime cá»§a request.

### Váº¥n Ä‘á»

```
Middleware chain:
  req â”€â”€â–º authMiddleware: req.user = {...}        +2KB
      â”€â”€â–º dataMiddleware: req.fullReport = {...}  +5MB  â† PROBLEM!
      â”€â”€â–º logMiddleware:  req.auditLog = [...]    +1MB  â† PROBLEM!
      â”€â”€â–º handler:        res.json(small)

  Náº¿u 100 concurrent requests:
  100 Ã— (5MB + 1MB) = 600MB chá»‰ cho middleware data!
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m middleware gÃ¡n data lá»›n vÃ o req
rg --type js --type ts "req\.\w+ = " --no-filename | head -30

# TÃ¬m middleware fetch data vÃ  gÃ¡n vÃ o req
rg --type js --type ts "req\.\w+ = await" | head -20
```

### Giáº£i phÃ¡p

**BAD â€” Fetch large data trong middleware:**
```typescript
// BAD: Má»—i request load 5MB vÃ o memory qua middleware
app.use(async (req, res, next) => {
  req.fullPermissions = await loadAllPermissions(req.user.id); // 5MB
  req.companyData = await loadCompanyTree(req.user.companyId); // 3MB
  next();
});
```

**GOOD â€” Lazy loading, chá»‰ fetch khi cáº§n:**
```typescript
// GOOD: Lazy getter, chá»‰ load khi handler thá»±c sá»± cáº§n
app.use((req, res, next) => {
  let permissions: Permission[] | null = null;
  let companyData: CompanyTree | null = null;

  Object.defineProperty(req, 'fullPermissions', {
    get: async () => {
      if (!permissions) {
        permissions = await loadAllPermissions(req.user.id);
      }
      return permissions;
    },
  });

  Object.defineProperty(req, 'companyData', {
    get: async () => {
      if (!companyData) {
        companyData = await loadCompanyTree(req.user.companyId);
      }
      return companyData;
    },
  });

  next();
});
```

### PhÃ²ng ngá»«a

- [ ] KhÃ´ng gÃ¡n large objects vÃ o `req` trong middleware
- [ ] Sá»­ dá»¥ng lazy loading pattern cho data lá»›n
- [ ] Chá»‰ gÃ¡n IDs/references nhá» vÃ o `req`, fetch data trong handler khi cáº§n
- [ ] Set request timeout Ä‘á»ƒ trÃ¡nh request tá»“n táº¡i quÃ¡ lÃ¢u

---

## Pattern 06: Child Process Zombie

### TÃªn
Child Process Zombie (Process Con Trá»Ÿ ThÃ nh Zombie)

### PhÃ¢n loáº¡i
Resource Management / OS / Process

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> `child_process.spawn()` hoáº·c `exec()` táº¡o process con nhÆ°ng khÃ´ng handle event `exit`, `error`, `close`. Process con káº¿t thÃºc nhÆ°ng entry váº«n tá»“n táº¡i trong process table â†’ zombie accumulation.

### Váº¥n Ä‘á»

```
Parent (Node.js)
    â”‚
    â”œâ”€â”€ spawn('ffmpeg', [...]) â†’ PID 1234
    â”‚       â”‚
    â”‚       â–¼
    â”‚   ffmpeg finishes (exit code 0)
    â”‚   NhÆ°ng parent KHÃ”NG gá»i wait()
    â”‚   â†’ PID 1234 trá»Ÿ thÃ nh ZOMBIE
    â”‚
    â”œâ”€â”€ spawn('ffmpeg', [...]) â†’ PID 1235  â† zombie
    â”œâ”€â”€ spawn('ffmpeg', [...]) â†’ PID 1236  â† zombie
    â”‚   ...
    â””â”€â”€ PID limit reached â†’ Cannot fork!

  $ ps aux | grep Z
  USER  PID  STAT COMMAND
  node  1234  Z   [ffmpeg] <defunct>
  node  1235  Z   [ffmpeg] <defunct>
  node  1236  Z   [ffmpeg] <defunct>
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m spawn/exec khÃ´ng handle exit/error events
rg --type js --type ts "spawn\(|exec\(|execFile\(" -A 10 | head -40

# TÃ¬m child process khÃ´ng cÃ³ .on('exit') hoáº·c .on('error')
rg --type js --type ts "child_process" | head -20

# Kiá»ƒm tra zombie processes
# ps aux | awk '$8 ~ /Z/ {print}'
```

### Giáº£i phÃ¡p

**BAD â€” Spawn khÃ´ng handle lifecycle:**
```typescript
// BAD: KhÃ´ng handle exit, error, close events
import { spawn } from 'node:child_process';

app.post('/convert', async (req, res) => {
  const proc = spawn('ffmpeg', ['-i', inputPath, '-f', 'mp4', outputPath]);
  res.json({ status: 'processing' });
  // proc trá»Ÿ thÃ nh zombie khi ffmpeg káº¿t thÃºc!
});
```

**GOOD â€” Proper child process management:**
```typescript
import { spawn } from 'node:child_process';

function runCommand(
  cmd: string,
  args: string[],
  options: { timeout?: number; signal?: AbortSignal } = {}
): Promise<{ code: number; stdout: string; stderr: string }> {
  return new Promise((resolve, reject) => {
    const proc = spawn(cmd, args, {
      signal: options.signal,
      timeout: options.timeout ?? 30000,
      stdio: ['ignore', 'pipe', 'pipe'],
    });

    const stdout: Buffer[] = [];
    const stderr: Buffer[] = [];

    proc.stdout.on('data', (chunk) => stdout.push(chunk));
    proc.stderr.on('data', (chunk) => stderr.push(chunk));

    proc.on('error', (error) => {
      reject(new Error(`Process error: ${error.message}`));
    });

    proc.on('close', (code, signal) => {
      resolve({
        code: code ?? -1,
        stdout: Buffer.concat(stdout).toString(),
        stderr: Buffer.concat(stderr).toString(),
      });
    });
  });
}

// Sá»­ dá»¥ng vá»›i AbortController
app.post('/convert', async (req, res) => {
  const controller = new AbortController();

  // Cancel náº¿u client disconnect
  req.on('close', () => controller.abort());

  try {
    const result = await runCommand('ffmpeg', ['-i', inputPath, '-f', 'mp4', outputPath], {
      timeout: 60000,
      signal: controller.signal,
    });

    if (result.code !== 0) {
      return res.status(500).json({ error: result.stderr });
    }
    res.json({ status: 'done' });
  } catch (error) {
    res.status(500).json({ error: 'Conversion failed' });
  }
});
```

### PhÃ²ng ngá»«a

- [ ] Má»i `spawn()`/`exec()` PHáº¢I handle `error` vÃ  `close` events
- [ ] Set `timeout` cho child processes
- [ ] Sá»­ dá»¥ng `AbortSignal` Ä‘á»ƒ cancel khi khÃ´ng cáº§n ná»¯a
- [ ] Limit concurrent child processes (semaphore pattern)
- [ ] Monitor zombie count: `ps aux | awk '$8 ~ /Z/'`

---

## Pattern 07: HTTP Agent Connection

### TÃªn
HTTP Agent Connection Flood (Agent Connection KhÃ´ng Kiá»ƒm SoÃ¡t)

### PhÃ¢n loáº¡i
Resource Management / Network / HTTP Agent

### Má»©c nghiÃªm trá»ng
MEDIUM ğŸŸ¡

> Node.js HTTP Agent máº·c Ä‘á»‹nh cÃ³ `maxSockets = Infinity` (tá»« Node 12+). Khi gá»i external API dÆ°á»›i táº£i cao â†’ má»Ÿ quÃ¡ nhiá»u TCP connections â†’ overwhelm target server hoáº·c exhaust local ports.

### Váº¥n Ä‘á»

```
Node.js app (100 concurrent requests to API)
    â”‚
    â”œâ”€â”€ TCP connection 1 â†’ api.example.com:443
    â”œâ”€â”€ TCP connection 2 â†’ api.example.com:443
    â”œâ”€â”€ TCP connection 3 â†’ api.example.com:443
    â”‚   ...
    â”œâ”€â”€ TCP connection 100 â†’ api.example.com:443
    â”‚
    â””â”€â”€ maxSockets = Infinity (default!)
        â†’ 100 TCP connections má»Ÿ cÃ¹ng lÃºc
        â†’ Target server reject/rate-limit
        â†’ Local ephemeral ports exhaustion (>65535)
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m HTTP/HTTPS requests khÃ´ng set agent options
rg --type js --type ts "https?\.request\(|https?\.get\(" | head -20

# TÃ¬m fetch/axios khÃ´ng giá»›i háº¡n concurrency
rg --type js --type ts "axios\.(get|post|put)|fetch\(" | head -30

# TÃ¬m custom agent configuration
rg --type js --type ts "new https?\.Agent\(" | head -10
```

### Giáº£i phÃ¡p

**BAD â€” Default agent, khÃ´ng giá»›i háº¡n:**
```typescript
// BAD: maxSockets = Infinity, má»—i request táº¡o TCP connection má»›i
import https from 'node:https';

async function callExternalAPI(data: unknown): Promise<unknown> {
  const response = await fetch('https://api.example.com/endpoint', {
    method: 'POST',
    body: JSON.stringify(data),
  });
  return response.json();
}
```

**GOOD â€” Custom agent vá»›i giá»›i háº¡n:**
```typescript
import https from 'node:https';
import http from 'node:http';

// GOOD: Shared agent vá»›i connection limits
const httpsAgent = new https.Agent({
  maxSockets: 50,           // Max 50 concurrent connections per host
  maxTotalSockets: 200,     // Max 200 total connections
  maxFreeSockets: 10,       // Keep 10 idle connections
  keepAlive: true,          // Reuse connections
  keepAliveMsecs: 30000,    // Keep-alive ping interval
  timeout: 10000,           // Socket timeout
});

const httpAgent = new http.Agent({
  maxSockets: 50,
  maxTotalSockets: 200,
  keepAlive: true,
});

// Sá»­ dá»¥ng vá»›i fetch (Node.js 18+)
async function callExternalAPI(data: unknown): Promise<unknown> {
  const response = await fetch('https://api.example.com/endpoint', {
    method: 'POST',
    body: JSON.stringify(data),
    // @ts-expect-error -- Node.js specific option
    dispatcher: httpsAgent,
    signal: AbortSignal.timeout(10000),
  });
  return response.json();
}
```

### PhÃ²ng ngá»«a

- [ ] Táº¡o shared HTTP Agent vá»›i `maxSockets` há»£p lÃ½ (20-100)
- [ ] Enable `keepAlive: true` Ä‘á»ƒ reuse connections
- [ ] Set socket `timeout` cho má»i request
- [ ] Sá»­ dá»¥ng `undici` Pool cho high-performance use cases
- [ ] Monitor open socket count

---

## Pattern 08: DNS Cache Thiáº¿u

### TÃªn
DNS Cache Thiáº¿u (Missing DNS Caching)

### PhÃ¢n loáº¡i
Resource Management / Network / DNS

### Má»©c nghiÃªm trá»ng
MEDIUM ğŸŸ¡

> Node.js máº·c Ä‘á»‹nh KHÃ”NG cache DNS lookups. Má»—i HTTP request trigger DNS resolution â†’ tÄƒng latency 5-50ms má»—i request, tÄƒng load lÃªn DNS server.

### Váº¥n Ä‘á»

```
Má»—i fetch('https://api.example.com/...'):
  1. DNS lookup: api.example.com â†’ 203.0.113.5  (5-50ms)
  2. TCP handshake                               (10ms)
  3. TLS handshake                               (20ms)
  4. HTTP request/response                       (50ms)

  KhÃ´ng cache DNS:
  Request 1: DNS(50ms) + TCP + TLS + HTTP = 130ms
  Request 2: DNS(50ms) + TCP + TLS + HTTP = 130ms  â† DNS láº·p láº¡i!
  Request 3: DNS(50ms) + TCP + TLS + HTTP = 130ms  â† DNS láº·p láº¡i!

  Vá»›i cache DNS:
  Request 1: DNS(50ms) + TCP + TLS + HTTP = 130ms
  Request 2: cache(0ms) + TCP + TLS + HTTP = 80ms  â† 38% nhanh hÆ¡n
  Request 3: cache(0ms) + TCP + TLS + HTTP = 80ms
```

### PhÃ¡t hiá»‡n

```bash
# Kiá»ƒm tra xem cÃ³ dns caching package khÃ´ng
rg --type js --type ts "cacheable-lookup|dns-cache" | head -10

# TÃ¬m http agent configuration
rg --type js --type ts "lookup:|dns\.resolve|dns\.lookup" | head -10
```

### Giáº£i phÃ¡p

**BAD â€” KhÃ´ng DNS cache:**
```typescript
// BAD: Má»—i request trigger DNS lookup
const response = await fetch('https://api.example.com/data');
```

**GOOD â€” DNS caching vá»›i cacheable-lookup:**
```typescript
import CacheableLookup from 'cacheable-lookup';
import https from 'node:https';

const cacheable = new CacheableLookup({
  maxTtl: 300,      // Cache 5 phÃºt
  fallbackDuration: 60, // Fallback cache 1 phÃºt khi DNS fail
});

// Install globally cho táº¥t cáº£ requests
cacheable.install(https.globalAgent);

// Hoáº·c cáº¥u hÃ¬nh per-agent
const agent = new https.Agent({
  keepAlive: true,
  maxSockets: 50,
  lookup: cacheable.lookup,
});
```

### PhÃ²ng ngá»«a

- [ ] Install `cacheable-lookup` hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- [ ] Set DNS TTL phÃ¹ há»£p (thÆ°á»ng 60-300 giÃ¢y)
- [ ] Káº¿t há»£p vá»›i `keepAlive: true` Ä‘á»ƒ giáº£m DNS lookups
- [ ] Monitor DNS resolution time qua metrics

---

## Pattern 09: Large File Memory

### TÃªn
Large File Memory Load (Äá»c File Lá»›n VÃ o Memory)

### PhÃ¢n loáº¡i
Resource Management / Memory / File I/O

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> Sá»­ dá»¥ng `fs.readFile()` cho file lá»›n load toÃ n bá»™ vÃ o memory. File 500MB â†’ V8 heap cáº§n 500MB+ â†’ OOM cho process.

### Váº¥n Ä‘á»

```
fs.readFile('large-export.csv')
       â”‚
       â–¼
  Allocate Buffer 500MB trong V8 heap
       â”‚
       â–¼
  V8 Old Space: 1.5GB (default limit)
  500MB file + 500MB processing = OOM!

  Concurrent requests:
  User 1: readFile(200MB) â”€â”
  User 2: readFile(200MB) â”€â”¼â”€â”€ Total: 600MB+ heap usage
  User 3: readFile(200MB) â”€â”˜   â†’ FATAL ERROR: OOM
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m readFile/readFileSync (potential large file)
rg --type js --type ts "readFile(Sync)?\(" | head -20

# TÃ¬m Buffer.from vá»›i large data sources
rg --type js --type ts "Buffer\.(from|alloc)\(" | head -20

# TÃ¬m response.data (axios) cho large responses
rg --type js --type ts "response\.data" -B 5 | head -30
```

### Giáº£i phÃ¡p

**BAD â€” Load toÃ n bá»™ file vÃ o memory:**
```typescript
// BAD: 500MB file â†’ 500MB+ trong V8 heap
app.get('/export/:id', async (req, res) => {
  const data = await fs.promises.readFile(`/exports/${req.params.id}.csv`);
  res.setHeader('Content-Type', 'text/csv');
  res.send(data);
});
```

**GOOD â€” Stream processing:**
```typescript
import { pipeline } from 'node:stream/promises';
import { createReadStream } from 'node:fs';
import { Transform } from 'node:stream';

// GOOD: Stream file, memory usage = buffer size (~64KB)
app.get('/export/:id', async (req, res) => {
  const filePath = path.join(EXPORT_DIR, `${req.params.id}.csv`);

  // Kiá»ƒm tra file tá»“n táº¡i
  try {
    await fs.promises.access(filePath);
  } catch {
    return res.status(404).json({ error: 'Export not found' });
  }

  const stat = await fs.promises.stat(filePath);

  res.setHeader('Content-Type', 'text/csv');
  res.setHeader('Content-Length', stat.size);
  res.setHeader('Content-Disposition', `attachment; filename="${req.params.id}.csv"`);

  const readStream = createReadStream(filePath, {
    highWaterMark: 64 * 1024, // 64KB chunks
  });

  try {
    await pipeline(readStream, res);
  } catch (error) {
    if ((error as NodeJS.ErrnoException).code !== 'ERR_STREAM_PREMATURE_CLOSE') {
      logger.error('Stream error', { error });
    }
  }
});
```

**GOOD â€” Stream processing cho CSV transformation:**
```typescript
import { createReadStream } from 'node:fs';
import { Transform } from 'node:stream';
import { pipeline } from 'node:stream/promises';
import csv from 'csv-parse';

// GOOD: Process CSV row by row, memory = 1 row at a time
async function processLargeCSV(filePath: string): Promise<number> {
  let processedCount = 0;

  const parser = csv.parse({ columns: true });

  const processor = new Transform({
    objectMode: true,
    transform(row, _encoding, callback) {
      processedCount++;
      // Process tá»«ng row, khÃ´ng giá»¯ táº¥t cáº£ trong memory
      processRow(row)
        .then(() => callback())
        .catch(callback);
    },
  });

  await pipeline(
    createReadStream(filePath),
    parser,
    processor
  );

  return processedCount;
}
```

### PhÃ²ng ngá»«a

- [ ] KHÃ”NG dÃ¹ng `readFile` cho file > 10MB â€” dÃ¹ng `createReadStream`
- [ ] Sá»­ dá»¥ng `pipeline()` cho stream chaining
- [ ] Set `highWaterMark` phÃ¹ há»£p (16KB - 256KB)
- [ ] Limit upload size trong middleware
- [ ] Monitor heap usage: `process.memoryUsage().heapUsed`

---

## Pattern 10: Timeout Thiáº¿u Cho HTTP

### TÃªn
Timeout Thiáº¿u Cho HTTP Request (Missing HTTP Timeout)

### PhÃ¢n loáº¡i
Resource Management / Network / Timeout

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> HTTP request gá»i external service khÃ´ng set timeout. Náº¿u service treo â†’ request chá» vÃ´ háº¡n â†’ connection pool cáº¡n kiá»‡t â†’ toÃ n bá»™ app bá»‹ block.

### Váº¥n Ä‘á»

```
Node.js app â”€â”€â”€â”€â”€â”€â”€â”€ fetch('https://slow-api.com/data') â”€â”€â”€â”€â”€â”€â–º
                     â”‚
                     â”‚  KhÃ´ng cÃ³ timeout
                     â”‚  slow-api.com treo / khÃ´ng respond
                     â”‚
                     â–¼
              Chá»... 1 phÃºt
              Chá»... 5 phÃºt
              Chá»... 30 phÃºt
              Chá»... vÄ©nh viá»…n!

  Connection pool:
  [WAITING] [WAITING] [WAITING] [WAITING] [WAITING]
  All connections waiting â†’ New requests BLOCKED
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m fetch khÃ´ng cÃ³ timeout/signal
rg --type js --type ts "fetch\(" -A 5 | grep -v "timeout\|signal\|AbortSignal" | head -20

# TÃ¬m axios khÃ´ng cÃ³ timeout config
rg --type js --type ts "axios\.(get|post|put|delete)\(" -A 5 | grep -v "timeout" | head -20

# TÃ¬m http.request khÃ´ng cÃ³ timeout
rg --type js --type ts "http\.request\(|https\.request\(" -A 10 | grep -v "timeout" | head -20
```

### Giáº£i phÃ¡p

**BAD â€” Fetch khÃ´ng timeout:**
```typescript
// BAD: Náº¿u API treo, request chá» vÄ©nh viá»…n
async function getExternalData(id: string) {
  const response = await fetch(`https://api.example.com/data/${id}`);
  return response.json();
}
```

**GOOD â€” AbortSignal.timeout:**
```typescript
// GOOD: Timeout 10 giÃ¢y, tá»± Ä‘á»™ng abort
async function getExternalData(id: string): Promise<ExternalData> {
  const response = await fetch(`https://api.example.com/data/${id}`, {
    signal: AbortSignal.timeout(10_000), // 10 giÃ¢y
    headers: { 'Accept': 'application/json' },
  });

  if (!response.ok) {
    throw new Error(`API error: ${response.status}`);
  }

  return response.json();
}
```

**GOOD â€” Multi-level timeout:**
```typescript
// GOOD: Connection timeout + response timeout + total timeout
import { Agent } from 'undici';

const apiAgent = new Agent({
  connect: {
    timeout: 5_000,    // Connection timeout: 5s
  },
  bodyTimeout: 30_000,  // Body download timeout: 30s
  headersTimeout: 10_000, // Headers timeout: 10s
});

async function getExternalData(id: string): Promise<ExternalData> {
  const controller = new AbortController();

  // Total timeout: 45 giÃ¢y
  const totalTimeout = setTimeout(() => controller.abort(), 45_000);

  try {
    const response = await fetch(`https://api.example.com/data/${id}`, {
      signal: controller.signal,
      // @ts-expect-error -- undici dispatcher
      dispatcher: apiAgent,
    });

    if (!response.ok) {
      throw new Error(`API error: ${response.status}`);
    }

    return await response.json();
  } finally {
    clearTimeout(totalTimeout);
  }
}
```

### PhÃ²ng ngá»«a

- [ ] Má»i HTTP request PHáº¢I cÃ³ timeout (connection + total)
- [ ] Sá»­ dá»¥ng `AbortSignal.timeout()` cho fetch
- [ ] Set default timeout trong axios instance: `axios.create({ timeout: 10000 })`
- [ ] Multi-level timeout: connect < headers < body < total
- [ ] Circuit breaker cho external dependencies

---

## Pattern 11: Redis Client Reconnect

### TÃªn
Redis Client Reconnect Thiáº¿u (Missing Redis Auto-Reconnect)

### PhÃ¢n loáº¡i
Resource Management / Cache / Connection

### Má»©c nghiÃªm trá»ng
MEDIUM ğŸŸ¡

> Redis client disconnect (network blip, Redis restart) nhÆ°ng khÃ´ng cÃ³ auto-reconnect strategy. App tiáº¿p tá»¥c gá»i Redis â†’ errors â†’ cache miss storm â†’ DB overload.

### Váº¥n Ä‘á»

```
App â”€â”€â”€â”€ Redis Client â”€â”€â”€â”€ Redis Server
              â”‚
              â”‚  Network blip / Redis restart
              â”‚
              â–¼
         DISCONNECTED
              â”‚
              â”‚  App tiáº¿p tá»¥c gá»i Redis
              â”‚
              â–¼
         Error: Connection closed
         Error: Connection closed
         Error: Connection closed
              â”‚
              â–¼
         Cache miss â†’ DB query
         Cache miss â†’ DB query    â† Storm!
         Cache miss â†’ DB query
              â”‚
              â–¼
         DB OVERLOADED
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m Redis client creation
rg --type js --type ts "new Redis\(|createClient\(|ioredis" | head -10

# TÃ¬m thiáº¿u reconnect config
rg --type js --type ts "retryStrategy|reconnectOnError|retry_strategy" | head -10

# TÃ¬m thiáº¿u error handler cho Redis
rg --type js --type ts "redis.*\.on\('error'" | head -10
```

### Giáº£i phÃ¡p

**BAD â€” Redis client khÃ´ng handle disconnect:**
```typescript
// BAD: KhÃ´ng retry, khÃ´ng error handling
import Redis from 'ioredis';

const redis = new Redis({
  host: 'redis.example.com',
  port: 6379,
});

// KhÃ´ng handle connection errors
// KhÃ´ng cÃ³ reconnect strategy
```

**GOOD â€” Resilient Redis client:**
```typescript
import Redis from 'ioredis';

const redis = new Redis({
  host: process.env.REDIS_HOST ?? 'localhost',
  port: Number(process.env.REDIS_PORT ?? 6379),
  password: process.env.REDIS_PASSWORD,

  // Reconnect strategy
  retryStrategy: (times: number) => {
    if (times > 10) {
      logger.error('Redis: max retries reached, giving up');
      return null; // Stop retrying
    }
    // Exponential backoff: 100ms, 200ms, 400ms, ..., max 30s
    const delay = Math.min(100 * Math.pow(2, times - 1), 30000);
    logger.warn(`Redis: reconnecting in ${delay}ms (attempt ${times})`);
    return delay;
  },

  // Auto-reconnect on specific errors
  reconnectOnError: (err: Error) => {
    const targetErrors = ['READONLY', 'ECONNRESET', 'ETIMEDOUT'];
    return targetErrors.some((e) => err.message.includes(e));
  },

  maxRetriesPerRequest: 3,
  enableReadyCheck: true,
  lazyConnect: false,
});

// Event handlers
redis.on('connect', () => logger.info('Redis: connected'));
redis.on('ready', () => logger.info('Redis: ready'));
redis.on('error', (err) => logger.error('Redis: error', { error: err.message }));
redis.on('close', () => logger.warn('Redis: connection closed'));
redis.on('reconnecting', (delay: number) => {
  logger.info(`Redis: reconnecting in ${delay}ms`);
});

// Graceful cache fallback
async function getCached<T>(
  key: string,
  fallback: () => Promise<T>,
  ttl = 300
): Promise<T> {
  try {
    const cached = await redis.get(key);
    if (cached) return JSON.parse(cached);
  } catch (error) {
    // Redis down â†’ fallback to source, khÃ´ng crash
    logger.warn('Redis get failed, using fallback', { key, error });
  }

  const data = await fallback();

  // Try to cache, nhÆ°ng khÃ´ng fail náº¿u Redis down
  try {
    await redis.setex(key, ttl, JSON.stringify(data));
  } catch {
    // Silent fail â€” cache miss acceptable
  }

  return data;
}
```

### PhÃ²ng ngá»«a

- [ ] Cáº¥u hÃ¬nh `retryStrategy` vá»›i exponential backoff
- [ ] Handle táº¥t cáº£ Redis events: `connect`, `ready`, `error`, `close`
- [ ] Implement cache fallback â€” app váº«n hoáº¡t Ä‘á»™ng khi Redis down
- [ ] Set `maxRetriesPerRequest` Ä‘á»ƒ trÃ¡nh request chá» quÃ¡ lÃ¢u
- [ ] Health check endpoint kiá»ƒm tra Redis connection status

---

## Pattern 12: Buffer Pool Overflow

### TÃªn
Buffer Pool Overflow (V8 Heap Grow Do Buffer Allocation)

### PhÃ¢n loáº¡i
Resource Management / Memory / Buffer

### Má»©c nghiÃªm trá»ng
HIGH ğŸŸ 

> Táº¡o Buffer lá»›n liÃªn tá»¥c (image processing, file upload, crypto operations). Buffer > 8KB allocated trong V8 Old Space, khÃ´ng dá»… GC. Heap grow dáº§n â†’ OOM.

### Váº¥n Ä‘á»

```
Image processing service:

  Request 1: Buffer.alloc(10MB)  â†’ Old Space
  Request 2: Buffer.alloc(10MB)  â†’ Old Space
  ...
  V8 Old Space keeps growing

  V8 Heap:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Old Space                         â”‚
  â”‚ â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”         â”‚
  â”‚ â”‚10MB â”‚ â”‚10MB â”‚ â”‚10MB â”‚ ...      â”‚
  â”‚ â”‚Buf1 â”‚ â”‚Buf2 â”‚ â”‚Buf3 â”‚         â”‚
  â”‚ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜         â”‚
  â”‚                                   â”‚
  â”‚ GC cháº¡y nhÆ°ng Buffers váº«n        â”‚
  â”‚ reachable (trong processing)      â”‚
  â”‚                                   â”‚
  â”‚ Concurrent processing =           â”‚
  â”‚ N Ã— 10MB simultaneously!          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PhÃ¡t hiá»‡n

```bash
# TÃ¬m large Buffer allocation
rg --type js --type ts "Buffer\.(alloc|allocUnsafe|from)\(" | head -20

# TÃ¬m accumulation pattern (push to array)
rg --type js --type ts "\.push\(.*[Bb]uffer\|chunks\.push\|buffers\.push" | head -20

# TÃ¬m Buffer.concat (potential large allocation)
rg --type js --type ts "Buffer\.concat\(" | head -20
```

### Giáº£i phÃ¡p

**BAD â€” Accumulate buffers trong memory:**
```typescript
// BAD: Collect táº¥t cáº£ chunks vÃ o memory rá»“i process
app.post('/upload', async (req, res) => {
  const chunks: Buffer[] = [];

  req.on('data', (chunk: Buffer) => {
    chunks.push(chunk); // Accumulate táº¥t cáº£ vÃ o memory
  });

  req.on('end', () => {
    const fullBuffer = Buffer.concat(chunks); // Duplicate toÃ n bá»™!
    processImage(fullBuffer); // ThÃªm 1 copy ná»¯a
    // 3x memory: chunks + concat + processing
  });
});
```

**GOOD â€” Stream processing, limit concurrency:**
```typescript
import { pipeline } from 'node:stream/promises';
import { Transform } from 'node:stream';
import pLimit from 'p-limit';

// Limit concurrent heavy operations
const processLimit = pLimit(3); // Max 3 concurrent image processes

app.post('/upload', async (req, res) => {
  // Limit upload size
  const MAX_SIZE = 10 * 1024 * 1024; // 10MB
  let receivedBytes = 0;

  const sizeChecker = new Transform({
    transform(chunk: Buffer, _encoding, callback) {
      receivedBytes += chunk.length;
      if (receivedBytes > MAX_SIZE) {
        callback(new Error('File too large'));
        return;
      }
      callback(null, chunk);
    },
  });

  try {
    // Stream to temp file instead of memory
    const tempPath = path.join(TEMP_DIR, `upload-${Date.now()}`);
    const writeStream = fs.createWriteStream(tempPath);

    await pipeline(req, sizeChecker, writeStream);

    // Process with concurrency limit
    const result = await processLimit(() => processImageFile(tempPath));

    res.json(result);
  } catch (error) {
    if ((error as Error).message === 'File too large') {
      return res.status(413).json({ error: 'File exceeds 10MB limit' });
    }
    res.status(500).json({ error: 'Upload failed' });
  }
});
```

**GOOD â€” ObjectPool cho reusable buffers:**
```typescript
class BufferPool {
  private pool: Buffer[] = [];
  private readonly bufferSize: number;
  private readonly maxPoolSize: number;

  constructor(bufferSize: number, maxPoolSize = 10) {
    this.bufferSize = bufferSize;
    this.maxPoolSize = maxPoolSize;
  }

  acquire(): Buffer {
    const buf = this.pool.pop();
    if (buf) {
      buf.fill(0); // Clear previous data
      return buf;
    }
    return Buffer.alloc(this.bufferSize);
  }

  release(buf: Buffer): void {
    if (buf.length === this.bufferSize && this.pool.length < this.maxPoolSize) {
      this.pool.push(buf);
    }
    // Náº¿u pool Ä‘áº§y, buffer sáº½ Ä‘Æ°á»£c GC bÃ¬nh thÆ°á»ng
  }
}

// Sá»­ dá»¥ng
const imageBufferPool = new BufferPool(1024 * 1024); // 1MB buffers

async function processChunk(data: Buffer): Promise<void> {
  const workBuffer = imageBufferPool.acquire();
  try {
    data.copy(workBuffer);
    await doProcessing(workBuffer);
  } finally {
    imageBufferPool.release(workBuffer); // Tráº£ láº¡i pool
  }
}
```

### PhÃ²ng ngá»«a

- [ ] Stream processing thay vÃ¬ accumulate toÃ n bá»™ vÃ o memory
- [ ] Limit concurrent heavy operations vá»›i `p-limit`
- [ ] Limit upload/download size trong middleware
- [ ] Sá»­ dá»¥ng Buffer pool cho repeated allocations
- [ ] Monitor V8 heap: `process.memoryUsage()` metrics
- [ ] Set `--max-old-space-size` phÃ¹ há»£p vá»›i available RAM

```bash
# Monitor memory usage
node --max-old-space-size=2048 --expose-gc app.js

# Heap snapshot
node --inspect app.js
# Chrome DevTools â†’ Memory â†’ Take Heap Snapshot
```

---

## Báº£ng TÃ³m Táº¯t

| Code | Pattern | Má»©c Ä‘á»™ | TÃ¡c Ä‘á»™ng chÃ­nh |
|------|---------|--------|----------------|
| RM-01 | Memory Leak Qua Closure | ğŸ”´ CRITICAL | OOM crash, heap exhaustion |
| RM-02 | Connection Pool Exhaustion | ğŸ”´ CRITICAL | Service down, request timeout |
| RM-03 | File Descriptor Leak | ğŸŸ  HIGH | EMFILE error, cannot accept connections |
| RM-04 | Global Variable Memory | ğŸŸ  HIGH | Gradual heap growth â†’ OOM |
| RM-05 | Express Middleware Leak | ğŸŸ¡ MEDIUM | High memory per request |
| RM-06 | Child Process Zombie | ğŸŸ  HIGH | PID exhaustion, resource waste |
| RM-07 | HTTP Agent Connection | ğŸŸ¡ MEDIUM | Port exhaustion, target overload |
| RM-08 | DNS Cache Thiáº¿u | ğŸŸ¡ MEDIUM | Unnecessary latency per request |
| RM-09 | Large File Memory | ğŸŸ  HIGH | OOM on large file processing |
| RM-10 | Timeout Thiáº¿u Cho HTTP | ğŸŸ  HIGH | Connection pool exhaustion, cascade failure |
| RM-11 | Redis Client Reconnect | ğŸŸ¡ MEDIUM | Cache miss storm â†’ DB overload |
| RM-12 | Buffer Pool Overflow | ğŸŸ  HIGH | V8 heap growth â†’ OOM |

## Quick Scan Script

```bash
#!/bin/bash
echo "=== Node.js Resource Management Audit ==="

echo -e "\n--- RM-01: Closure Memory Leak ---"
rg --type js --type ts "\.on\(|\.addEventListener\(" -c 2>/dev/null | sort -t: -k2 -rn | head -5

echo -e "\n--- RM-02: Connection Pool ---"
rg --type js --type ts "pool\.(acquire|connect|getConnection)\(\)" -c 2>/dev/null

echo -e "\n--- RM-03: File Descriptor ---"
rg --type js --type ts "createReadStream|createWriteStream" -c 2>/dev/null

echo -e "\n--- RM-04: Global Cache ---"
rg --type js --type ts "^(export )?(const|let) \w+ = new (Map|Set)\(" 2>/dev/null

echo -e "\n--- RM-06: Child Process ---"
rg --type js --type ts "spawn\(|exec\(|execFile\(" -c 2>/dev/null

echo -e "\n--- RM-09: Large File Read ---"
rg --type js --type ts "readFile(Sync)?\(" 2>/dev/null | grep -v node_modules

echo -e "\n--- RM-10: HTTP Timeout ---"
rg --type js --type ts "fetch\(" -A 5 2>/dev/null | grep -v "timeout\|signal\|AbortSignal" | head -10

echo -e "\n--- RM-12: Buffer Accumulation ---"
rg --type js --type ts "\.push\(.*[Bb]uffer\|Buffer\.concat\(" 2>/dev/null

echo -e "\n=== Scan Complete ==="
```
