# Domain 12: Gi√°m S√°t (Monitoring & Observability)

> Java/Spring Boot patterns: Micrometer, OpenTelemetry, structured logging, health indicators, metrics.

---

## Pattern 01: Logging Kh√¥ng Structured

### Ph√¢n lo·∫°i
Monitoring / Logging / Observability ‚Äî HIGH üü†

### V·∫•n ƒë·ªÅ
```java
log.info("Processing order " + orderId + " for user " + userId);
// Not structured ‚Üí can't search/filter/aggregate in ELK/Grafana
// String concatenation even when log level disabled
```

### Ph√°t hi·ªán
```bash
rg --type java "log\\.(info|debug|error)\\(.*\\+" -n
rg --type java "System\\.out\\.print" -n --glob "!*Test*"
```

### Gi·∫£i ph√°p
```java
// GOOD: SLF4J parameterized logging
log.info("Processing order orderId={} userId={}", orderId, userId);

// GOOD: Structured logging with Logback JSON
// logback-spring.xml:
// <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>

// GOOD: MDC for request context
MDC.put("requestId", requestId);
MDC.put("userId", userId);
log.info("Processing order orderId={}", orderId);
// JSON output includes requestId and userId automatically
```

### Ph√≤ng ng·ª´a
- [ ] SLF4J `{}` placeholders (not string concat)
- [ ] JSON log format for production (Logstash encoder)
- [ ] MDC for cross-cutting context (requestId, userId)
- Tool: Logback, Logstash Encoder, MDC

---

## Pattern 02: Metrics Cardinality Explosion

### Ph√¢n lo·∫°i
Monitoring / Metrics / Prometheus ‚Äî HIGH üü†

### V·∫•n ƒë·ªÅ
```java
// user_id as tag ‚Üí millions of unique time series!
Metrics.counter("http.requests", "userId", userId).increment();
// Prometheus OOM, slow queries, high storage cost
```

### Ph√°t hi·ªán
```bash
rg --type java "Metrics\\.|Counter\\.|Timer\\.|Gauge\\." -n
rg --type java "tag\\(.*[Ii]d|tag\\(.*email|tag\\(.*ip" -n
```

### Gi·∫£i ph√°p
```java
// BAD: High-cardinality tags
Metrics.counter("requests", "userId", userId); // Millions of series

// GOOD: Low-cardinality tags only
Metrics.counter("http.server.requests",
    "method", request.getMethod(),
    "status", String.valueOf(response.getStatus()),
    "uri", "/api/users/{id}" // Template, not actual path!
).increment();

// Spring Boot auto-configures this via Micrometer
// Just use @Timed or ObservationRegistry
```

### Ph√≤ng ng·ª´a
- [ ] Never use IDs/emails/IPs as metric tags
- [ ] URI templates, not actual paths
- [ ] < 10 unique values per tag
- Tool: Micrometer, Prometheus

---

## Pattern 03: Health Check Superficial

### Ph√¢n lo·∫°i
Monitoring / Health / Kubernetes ‚Äî HIGH üü†

### V·∫•n ƒë·ªÅ
```java
// Default /actuator/health returns {"status":"UP"} even if:
// - Database connection pool exhausted
// - Redis unreachable
// - Disk full
// K8s thinks pod is healthy ‚Üí routes traffic ‚Üí errors
```

### Ph√°t hi·ªán
```bash
rg "health" -n --glob "application*.yml"
rg --type java "HealthIndicator|AbstractHealthIndicator" -n
```

### Gi·∫£i ph√°p
```java
// Custom health indicator:
@Component
public class ExternalApiHealthIndicator extends AbstractHealthIndicator {
    private final RestClient restClient;
    @Override
    protected void doHealthCheck(Health.Builder builder) {
        try {
            restClient.get().uri("/health").retrieve().body(String.class);
            builder.up().withDetail("externalApi", "reachable");
        } catch (Exception e) {
            builder.down(e).withDetail("externalApi", "unreachable");
        }
    }
}
```

```yaml
management:
  endpoint:
    health:
      show-details: always
      group:
        liveness:
          include: livenessState
        readiness:
          include: readinessState,db,redis,externalApi
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
```

### Ph√≤ng ng·ª´a
- [ ] Separate liveness (app alive) and readiness (can serve)
- [ ] Custom `HealthIndicator` for external dependencies
- [ ] K8s probes: `/actuator/health/liveness` + `/actuator/health/readiness`
- Tool: Spring Actuator Health Groups

---

## Pattern 04: OpenTelemetry Kh√¥ng C·∫•u H√¨nh

### Ph√¢n lo·∫°i
Monitoring / Tracing / Distributed ‚Äî HIGH üü†

### V·∫•n ƒë·ªÅ
```
// Microservices: Service A ‚Üí B ‚Üí C
// No distributed tracing ‚Üí can't follow request flow
// Debugging latency issues requires checking logs of each service manually
```

### Ph√°t hi·ªán
```bash
rg "opentelemetry|micrometer-tracing" -n --glob "pom.xml" --glob "build.gradle*"
rg "tracing|otel" -n --glob "application*.yml"
```

### Gi·∫£i ph√°p
```xml
<!-- pom.xml: Spring Boot 3.x + Micrometer Tracing -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-exporter-otlp</artifactId>
</dependency>
```

```yaml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% in dev, 10% in prod
  otlp:
    tracing:
      endpoint: http://otel-collector:4318/v1/traces
```

### Ph√≤ng ng·ª´a
- [ ] Micrometer Tracing + OTLP exporter
- [ ] Trace context auto-propagated via Spring
- [ ] Sample rate: 100% dev, 1-10% production
- Tool: Micrometer Tracing, OpenTelemetry, Jaeger/Tempo

---

## Pattern 05: Custom Metrics Thi·∫øu

### Ph√¢n lo·∫°i
Monitoring / Business / Metrics ‚Äî MEDIUM üü°

### V·∫•n ƒë·ªÅ
```
// Only infrastructure metrics (CPU, memory, HTTP status)
// No business metrics ‚Üí can't answer:
// - How many orders processed per minute?
// - What's the payment success rate?
// - How long does report generation take?
```

### Ph√°t hi·ªán
```bash
rg --type java "@Timed|@Counted|MeterRegistry" -n
rg --type java "Observation|ObservationRegistry" -n
```

### Gi·∫£i ph√°p
```java
@Service
public class OrderService {
    private final MeterRegistry meterRegistry;
    private final Counter ordersCreated;
    private final Timer orderProcessingTime;

    public OrderService(MeterRegistry registry) {
        this.meterRegistry = registry;
        this.ordersCreated = Counter.builder("orders.created")
            .tag("type", "online").register(registry);
        this.orderProcessingTime = Timer.builder("orders.processing.time")
            .register(registry);
    }

    public Order createOrder(OrderRequest req) {
        return orderProcessingTime.record(() -> {
            Order order = processOrder(req);
            ordersCreated.increment();
            return order;
        });
    }
}

// Or use @Timed annotation:
@Timed(value = "orders.create", description = "Time to create order")
public Order createOrder(OrderRequest req) { /* ... */ }
```

### Ph√≤ng ng·ª´a
- [ ] Business metrics (orders, payments, errors by type)
- [ ] `@Timed` for method-level timing
- [ ] Dashboards for business KPIs
- Tool: Micrometer, Prometheus, Grafana

---

## Pattern 06: Log Level Sai Production

### Ph√¢n lo·∫°i
Monitoring / Logging / Performance ‚Äî MEDIUM üü°

### V·∫•n ƒë·ªÅ
```yaml
logging:
  level:
    root: DEBUG  # DEBUG in production ‚Üí massive log volume
    org.hibernate.SQL: DEBUG  # Every SQL query logged
    org.springframework: TRACE  # Framework internals
# Result: 100GB/day logs, high I/O, slow performance
```

### Ph√°t hi·ªán
```bash
rg "level.*DEBUG|level.*TRACE" -n --glob "application*.yml" --glob "application-prod*"
rg "show-sql.*true|show_sql.*true" -n --glob "application*.yml"
```

### Gi·∫£i ph√°p
```yaml
# application-prod.yml:
logging:
  level:
    root: WARN
    com.myapp: INFO         # App code at INFO
    org.springframework: WARN
    org.hibernate: WARN
    org.hibernate.SQL: OFF  # No SQL logging in prod

# Dynamic level change via actuator:
# POST /actuator/loggers/com.myapp {"configuredLevel":"DEBUG"}
```

```yaml
management:
  endpoint:
    loggers:
      enabled: true  # Enable runtime log level changes
```

### Ph√≤ng ng·ª´a
- [ ] `WARN` for frameworks, `INFO` for app code in prod
- [ ] `show-sql: false` in production
- [ ] Actuator `/loggers` for dynamic level changes
- Tool: Logback, Spring Actuator loggers endpoint

---

## Pattern 07: Error Rate Alerting Thi·∫øu

### Ph√¢n lo·∫°i
Monitoring / Alerting / SRE ‚Äî HIGH üü†

### V·∫•n ƒë·ªÅ
```
// Errors increasing but no one knows
// 5xx rate goes from 0.1% to 10% ‚Üí users report issues
// No automated alerting ‚Üí issues discovered by customers
```

### Ph√°t hi·ªán
```bash
rg "alert" -n --glob "*.yml" --glob "prometheus*"
rg --type java "ErrorController|@ExceptionHandler" -n
```

### Gi·∫£i ph√°p
```java
// Spring Boot auto-exposes http.server.requests metric
// Configure Prometheus alerting rules:
```

```yaml
# prometheus-rules.yml:
groups:
  - name: spring-boot-alerts
    rules:
      - alert: HighErrorRate
        expr: >
          sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
          / sum(rate(http_server_requests_seconds_count[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Error rate > 5% for 5 minutes"

      - alert: HighLatency
        expr: >
          histogram_quantile(0.99, rate(http_server_requests_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "P99 latency > 2 seconds"
```

### Ph√≤ng ng·ª´a
- [ ] Error rate alerting (> 5% = critical)
- [ ] Latency alerting (P99 > threshold)
- [ ] PagerDuty/Slack integration
- Tool: Prometheus Alertmanager, Grafana Alerts
